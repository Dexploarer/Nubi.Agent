[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.13.3","content-config-digest","989ddf156d645207","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"where\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":false,\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null],\"rehypePlugins\":[null,[null,{\"experimentalHeadingIdCompat\":false}],null,[null,{\"themes\":[\"night-owl\",\"min-light\"],\"defaultLocale\":\"en\",\"cascadeLayer\":\"starlight.components\",\"styleOverrides\":{\"borderRadius\":\"0.5rem\",\"borderWidth\":\"1px\",\"codePaddingBlock\":\"0.75rem\",\"codePaddingInline\":\"1rem\",\"codeFontFamily\":\"var(--__sl-font-mono)\",\"codeFontSize\":\"var(--sl-text-code)\",\"codeLineHeight\":\"var(--sl-line-height)\",\"uiFontFamily\":\"var(--__sl-font)\",\"textMarkers\":{\"lineDiffIndicatorMarginLeft\":\"0.25rem\",\"defaultChroma\":\"45\",\"backgroundOpacity\":\"60%\"}},\"plugins\":[{\"name\":\"Starlight Plugin\",\"hooks\":{}},{\"name\":\"astro-expressive-code\",\"hooks\":{}}]}]],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false},\"legacy\":{\"collections\":false},\"prefetch\":{\"prefetchAll\":true},\"i18n\":{\"defaultLocale\":\"en\",\"locales\":[\"en\"],\"routing\":{\"prefixDefaultLocale\":false,\"redirectToDefaultLocale\":false,\"fallbackType\":\"redirect\"}}}","docs",["Map",11,12,41,42,54,55,66,67,78,79,90,91,102,103,114,115,126,127,138,139,150,151,162,163,174,175,186,187,199,200,212,213,225,226,237,238,249,250,261,262,273,274,285,286,297,298],"index",{"id":11,"data":13,"body":37,"filePath":38,"digest":39,"legacyId":40,"deferredRender":16},{"title":14,"description":15,"editUrl":16,"head":17,"template":18,"hero":19,"sidebar":34,"pagefind":16,"draft":35},"NUBI - The Symbiotic Essence of Anubis","Advanced ElizaOS-based AI Agent with sophisticated UX integration, database pooling, and Telegram raid coordination.",true,[],"splash",{"tagline":20,"actions":21},"The Symbiotic Essence of Anubis - Your Advanced AI Community Manager",[22,29],{"text":23,"link":24,"variant":25,"icon":26},"Get Started","/getting-started/introduction/","primary",{"type":27,"name":28},"icon","right-arrow",{"text":30,"link":31,"variant":25,"icon":32},"View API Reference","/api/rest/",{"type":27,"name":33},"external",{"hidden":35,"attrs":36},false,{},"import { Card, CardGrid } from \"@astrojs/starlight/components\";\n\n## 🐺 Welcome to NUBI\n\nNUBI is an advanced ElizaOS-based AI agent that embodies the personality of an ancient jackal spirit with modern market wisdom. Serving as a sophisticated community manager with deep crypto/Solana knowledge, NUBI features cutting-edge UX integration, intelligent database pooling, and comprehensive Telegram raid coordination.\n\n\u003CCardGrid>\n  \u003CCard title=\"🔌 UX Integration System\" icon=\"laptop\">\n    Real-time Socket.IO communication with two-layer processing pipeline for\n    security and intelligent message classification.\n  \u003C/Card>\n  \u003CCard title=\"🗄️ Smart Database Pooling\" icon=\"setting\">\n    Intelligent dual-pool architecture with automatic query routing between\n    transaction and session pools for optimal performance.\n  \u003C/Card>\n  \u003CCard title=\"🚀 Telegram Raids\" icon=\"rocket\">\n    Advanced raid coordination system with engagement verification,\n    leaderboards, and cross-platform integration.\n  \u003C/Card>\n  \u003CCard title=\"🧠 ElizaOS Core\" icon=\"approve-check\">\n    Built on the powerful ElizaOS framework with full plugin architecture and\n    modular service design.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## ✨ Key Features\n\n### 🏗️ **Modular Architecture**\n\n- **8 Core Modules**: Clean separation with dependency injection\n- **Type-Safe**: Eliminated `any` types with strict TypeScript\n- **Service-Oriented**: All services extend ElizaOS patterns\n\n### 🔐 **Two-Layer Security Processing**\n\n1. **Layer 1**: Rate limiting, XSS prevention, content filtering\n2. **Layer 2**: Message classification, intelligent routing, prompt injection\n\n### 📊 **Performance Optimized**\n\n- **Database Poolers**: Transaction (6543) & Session (5432) pools\n- **Parallel Execution**: `Promise.all()` for independent operations\n- **Connection Management**: Centralized pooling with intelligent routing\n\n### 🌐 **Multi-Platform Integration**\n\n- **Discord**: Real-time community engagement\n- **Telegram**: Advanced raid coordination\n- **Twitter/X**: Social media integration\n- **Socket.IO**: Real-time web communication\n\n## 🚀 Quick Start\n\n```bash\n# Clone the repository\ngit clone https://github.com/anubis-chat/nubi\n\n# Install dependencies\nbun install\n\n# Configure environment\ncp .env.example .env\n# Edit .env with your API keys\n\n# Start development mode\nbun run dev\n```\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>💡 Pro Tip:\u003C/strong> NUBI automatically detects your database\n  configuration and switches between PGLite (development) and PostgreSQL\n  (production) based on available environment variables.\n\u003C/div>\n\n## 📖 Documentation Structure\n\nThis documentation is organized to match NUBI's modular architecture:\n\n- **Getting Started**: Installation, configuration, and quick start\n- **Architecture**: Deep dive into the modular design and service layer\n- **UX Integration**: Socket.IO setup and two-layer processing system\n- **Database**: Pooler management, query routing, and performance\n- **Telegram Raids**: Coordination system and engagement verification\n- **API Reference**: Complete REST and WebSocket API documentation\n- **Deployment**: Production setup, Docker, and monitoring\n\n## 🤝 Community & Support\n\n- **GitHub**: [anubis-chat/nubi](https://github.com/anubis-chat/nubi)\n- **Discord**: Join our community server\n- **Documentation**: You're reading it!\n- **Issues**: Report bugs and request features on GitHub\n\n---\n\n\u003Cdiv style=\"text-align: center; padding: 2rem; background: var(--nubi-hero-gradient); border-radius: 12px; color: white; margin: 2rem 0;\">\n  \u003Ch3 style=\"margin: 0 0 1rem 0; color: var(--nubi-jackal-gold);\">\n    Ready to unleash the power of NUBI?\n  \u003C/h3>\n  \u003Cp style=\"margin: 0 0 1.5rem 0; opacity: 0.9;\">\n    Start building with the most advanced AI agent framework.\n  \u003C/p>\n  \u003Ca\n    href=\"/getting-started/introduction/\"\n    style=\"background: var(--nubi-jackal-gold); color: var(--nubi-shadow-black); padding: 1rem 2rem; border-radius: 8px; text-decoration: none; font-weight: 600;\"\n  >\n    Begin Your Journey →\n  \u003C/a>\n\u003C/div>","src/content/docs/index.mdx","84ce70bb089371ba","index.mdx","getting-started/quick-start",{"id":41,"data":43,"body":50,"filePath":51,"digest":52,"legacyId":53,"deferredRender":16},{"title":44,"description":45,"editUrl":16,"head":46,"template":47,"sidebar":48,"pagefind":16,"draft":35},"Quick Start Guide","Get NUBI up and running in under 5 minutes with our streamlined setup process.",[],"doc",{"hidden":35,"attrs":49},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Quick Start Guide\n\nGet **NUBI - The Symbiotic Essence of Anubis** running in under 5 minutes with this streamlined setup guide.\n\n## ⚡ Prerequisites\n\n\u003CCardGrid>\n  \u003CCard title=\"🟢 Node.js 18+\" icon=\"approve-check\">\n    **Required** for running ElizaOS and dependencies ```bash node --version #\n    Should be 18.0.0+ ```\n  \u003C/Card>\n\n\u003CCard title=\"🚀 Bun (Recommended)\" icon=\"rocket\">\n  **Fast JavaScript runtime** with built-in package manager ```bash curl -fsSL\n  https://bun.sh/install | bash ```\n\u003C/Card>\n\n\u003CCard title=\"🗄️ PostgreSQL\" icon=\"setting\">\n  **Database** for production (PGLite for development) - Development: Automatic\n  PGLite setup - Production: PostgreSQL 14+ required\n\u003C/Card>\n\n  \u003CCard title=\"🔑 API Keys\" icon=\"warning\">\n    **Platform integrations** (optional for basic setup) - OpenAI/Anthropic for\n    AI models - Telegram Bot Token - Twitter API credentials\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🚀 5-Minute Setup\n\n### Step 1: Clone & Install\n\n\u003CTabs>\n  \u003CTabItem label=\"With Bun (Recommended)\">\n```bash\n# Clone the repository\ngit clone https://github.com/anubis-chat/nubi.git\ncd nubi\n\n# Install dependencies (fast!)\n\nbun install\n\n# Verify installation\n\nbun run type-check\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"With npm\">\n```bash\n# Clone the repository\ngit clone https://github.com/anubis-chat/nubi.git\ncd nubi\n\n# Install dependencies\nnpm install\n\n# Verify installation\nnpm run type-check\n````\n\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Step 2: Environment Setup\n\n\u003CTabs>\n  \u003CTabItem label=\"Quick Setup (Minimal)\">\n```bash\n# Copy example environment\ncp .env.example .env\n\n# Edit with your preferred editor\n\ncode .env # or nano .env, vim .env\n\n# Minimal required configuration:\n\nNODE_ENV=development\nOPENAI_API_KEY=your-openai-key-here\nPGLITE_DATA_DIR=./.eliza/.elizadb\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Full Setup (Recommended)\">\n```bash\n# Copy example environment\ncp .env.example .env\n\n# Essential configuration for full features:\nNODE_ENV=development\n\n# AI Model (choose one)\nOPENAI_API_KEY=sk-your-openai-key\n# OR\nANTHROPIC_API_KEY=sk-ant-your-key\n\n# Database (automatic in development)\nPGLITE_DATA_DIR=./.eliza/.elizadb\n\n# Telegram Bot (for raids)\nTELEGRAM_BOT_TOKEN=your-bot-token\n\n# Twitter Integration (optional)\nTWITTER_API_KEY=your-twitter-key\nTWITTER_API_SECRET=your-twitter-secret\n````\n\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Step 3: Launch NUBI\n\n\u003Cdiv style=\"background: linear-gradient(135deg, var(--nubi-shadow-black) 0%, var(--nubi-jackal-gold) 100%); padding: 2rem; border-radius: 12px; color: white; margin: 2rem 0;\">\n  \u003Ch4 style=\"margin: 0 0 1rem 0; color: var(--nubi-jackal-gold);\">🐺 Starting the Ancient Spirit...\u003C/h4>\n  \n  \u003Cpre style=\"background: rgba(0,0,0,0.3); padding: 1rem; border-radius: 8px; margin: 0;\">\n\u003Ccode># Development mode with PGLite database\nbun run dev\n\n# Watch the magic happen...\n\n🐺 NUBI - The Symbiotic Essence of Anubis\n⚡ ElizaOS v1.0.0 initialized\n🗄️ PGLite database ready at ./.eliza/.elizadb  \n🧠 Personality system loaded: Ancient Jackal Spirit\n🎯 Two-layer processing pipeline active\n✅ NUBI is ready for action!\u003C/code>\n\n  \u003C/pre>\n\u003C/div>\n\n## ✨ First Interaction\n\nOnce NUBI is running, you can interact through multiple channels:\n\n\u003CCardGrid>\n  \u003CCard title=\"💬 Direct Chat\" icon=\"approve-check\">\n    **Console interaction** for testing ```bash # In the running console > Hello\n    NUBI! 🐺 Greetings, mortal. The ancient spirit awakens... ```\n  \u003C/Card>\n\n\u003CCard title=\"🤖 Telegram\" icon=\"rocket\">\n  **Telegram bot** for community raids - Add your bot to Telegram groups - Use\n  `/start` to begin - Try `/help` for commands\n\u003C/Card>\n\n\u003CCard title=\"🌐 WebSocket\" icon=\"setting\">\n  **Real-time web integration** - Connect to `ws://localhost:3001` - Send JSON\n  messages - Experience two-layer processing\n\u003C/Card>\n\n  \u003CCard title=\"📡 REST API\" icon=\"puzzle\">\n    **HTTP endpoints** for integration - `POST /api/messages` for processing -\n    `GET /api/status` for health check - Full OpenAPI documentation\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🧪 Test the System\n\n\u003CTabs>\n  \u003CTabItem label=\"Basic Chat Test\">\n```bash\n# Test basic conversation\ncurl -X POST http://localhost:3001/api/messages \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"message\": \"Hello NUBI, how are you today?\",\n    \"userId\": \"test-user\",\n    \"roomId\": \"test-room\"\n  }'\n\n# Expected: Community Manager persona response\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Crypto Analysis Test\">\n```bash\n# Test crypto analyst persona\ncurl -X POST http://localhost:3001/api/messages \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"message\": \"What is the current SOL price analysis?\",\n    \"userId\": \"test-user\",\n    \"roomId\": \"test-room\"\n  }'\n\n# Expected: Crypto Analyst persona with market insights\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Raid Coordination Test\">\n```bash\n# Test raid coordinator persona\ncurl -X POST http://localhost:3001/api/messages \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"message\": \"https://twitter.com/example/post - raid this!\",\n    \"userId\": \"test-user\", \n    \"roomId\": \"test-room\"\n  }'\n\n# Expected: Raid Coordinator persona with engagement strategy\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🛠️ Development Commands\n\n\u003Cdiv style=\"background: rgba(63, 81, 181, 0.1); border: 1px solid var(--nubi-spirit-blue); border-radius: 8px; padding: 1.5rem; margin: 2rem 0;\">\n  \u003Ch4 style=\"color: var(--nubi-spirit-blue); margin: 0 0 1rem 0;\">Essential Development Commands\u003C/h4>\n\n  \u003Cdiv style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1rem;\">\n    \u003Cdiv>\n      \u003Cstrong>Development:\u003C/strong>\n      \u003Cpre style=\"background: rgba(0,0,0,0.2); padding: 0.5rem; border-radius: 4px; font-size: 0.9rem;\">\u003Ccode>bun run dev          # Development mode\nbun run dev:pglite   # Force PGLite database\u003C/code>\u003C/pre>\n    \u003C/div>\n    \u003Cdiv>\n      \u003Cstrong>Testing:\u003C/strong>\n      \u003Cpre style=\"background: rgba(0,0,0,0.2); padding: 0.5rem; border-radius: 4px; font-size: 0.9rem;\">\u003Ccode>bun test            # Run all tests\nbun run type-check  # TypeScript validation\u003C/code>\u003C/pre>\n    \u003C/div>\n    \u003Cdiv>\n      \u003Cstrong>Quality:\u003C/strong>\n      \u003Cpre style=\"background: rgba(0,0,0,0.2); padding: 0.5rem; border-radius: 4px; font-size: 0.9rem;\">\u003Ccode>bun run lint        # Code formatting\nbun run check-all   # Full quality check\u003C/code>\u003C/pre>\n    \u003C/div>\n    \u003Cdiv>\n      \u003Cstrong>Production:\u003C/strong>\n      \u003Cpre style=\"background: rgba(0,0,0,0.2); padding: 0.5rem; border-radius: 4px; font-size: 0.9rem;\">\u003Ccode>bun run build       # Build for production\nbun run start:production\u003C/code>\u003C/pre>\n    \u003C/div>\n  \u003C/div>\n\u003C/div>\n\n## 🐛 Troubleshooting\n\n\u003CAside type=\"caution\">\n**Common Issues & Solutions**\n\u003C/Aside>\n\n### Database Issues\n```bash\n# Clear PGLite database\nrm -rf ./.eliza/.elizadb\nbun run dev  # Recreates database automatically\n\n# Check database status\nls -la ./.eliza/.elizadb\n````\n\n### Port Conflicts\n\n```bash\n# Check if ports are in use\nlsof -i :3001  # NUBI main server\nlsof -i :5432  # PostgreSQL\n\n# Change ports in .env\nNUBI_SERVER_PORT=3002\n```\n\n### API Key Issues\n\n```bash\n# Test OpenAI connection\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n\n# Check environment variables\necho $OPENAI_API_KEY | head -c 20\n```\n\n### Memory/Performance Issues\n\n```bash\n# Increase Node.js memory limit\nexport NODE_OPTIONS=\"--max-old-space-size=4096\"\n\n# Monitor memory usage\nbun run dev --inspect\n```\n\n## 🎯 What's Next?\n\n\u003CCardGrid>\n  \u003CCard title=\"🏗️ System Architecture\" icon=\"puzzle\">\n    **Understand NUBI's design** - Learn about the modular architecture and\n    service layers [Explore Architecture →](/architecture/overview/)\n  \u003C/Card>\n\n\u003CCard title=\"⚔️ Telegram Raids\" icon=\"rocket\">\n  **Set up raid coordination** - Configure Telegram bot and start community\n  campaigns [Setup Raids →](/telegram-raids/overview/)\n\u003C/Card>\n\n\u003CCard title=\"🔌 UX Integration\" icon=\"approve-check\">\n  **Real-time communication** - Implement Socket.IO and two-layer processing\n  [Integrate UX →](/ux-integration/overview/)\n\u003C/Card>\n\n  \u003CCard title=\"📊 Production Deploy\" icon=\"setting\">\n    **Go live with NUBI** - Production setup, scaling, and monitoring [Deploy\n    →](/deployment/production/)\n  \u003C/Card>\n\u003C/CardGrid>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🐺 The Ancient Spirit Awaits:\u003C/strong> NUBI is now ready to serve your\n  community with the wisdom of ages and the power of modern AI. Begin your\n  journey into the symbiotic future of human-AI interaction.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Pro Tip**: Join our Discord community for real-time support, share your NUBI\n  setup, and collaborate with other developers building the future of AI agents.\n\u003C/Aside>","src/content/docs/getting-started/quick-start.mdx","c6bee47a69d20725","getting-started/quick-start.mdx","getting-started/installation",{"id":54,"data":56,"body":62,"filePath":63,"digest":64,"legacyId":65,"deferredRender":16},{"title":57,"description":58,"editUrl":16,"head":59,"template":47,"sidebar":60,"pagefind":16,"draft":35},"Installation Guide","Comprehensive installation guide for NUBI across different environments and deployment scenarios.",[],{"hidden":35,"attrs":61},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Installation Guide\n\nThis comprehensive guide covers installing **NUBI - The Symbiotic Essence of Anubis** across different environments, from development to production deployment.\n\n## 📋 System Requirements\n\n\u003CCardGrid>\n  \u003CCard title=\"💻 Hardware\" icon=\"setting\">\n    **Minimum system specifications** - **CPU**: 2+ cores (4+ recommended) -\n    **RAM**: 2GB minimum (4GB+ recommended) - **Storage**: 5GB free space -\n    **Network**: Stable internet connection\n  \u003C/Card>\n\n\u003CCard title=\"🔧 Software\" icon=\"approve-check\">\n  **Required runtime dependencies** - **Node.js**: 18.0.0 or higher - **Git**:\n  For source code management - **Database**: PostgreSQL 14+ (production) -\n  **Optional**: Docker, PM2, Redis\n\u003C/Card>\n\n\u003CCard title=\"☁️ Platform Support\" icon=\"rocket\">\n  **Supported operating systems** - **Linux**: Ubuntu 20.04+, CentOS 8+ -\n  **macOS**: 11.0+ (Big Sur and later) - **Windows**: 10/11 with WSL2 -\n  **Docker**: All platforms\n\u003C/Card>\n\n  \u003CCard title=\"🔑 External Services\" icon=\"warning\">\n    **Required API integrations** - **AI Models**: OpenAI, Anthropic, or local -\n    **Telegram**: Bot API token - **Twitter**: Developer account (optional) -\n    **Supabase**: Database hosting (optional)\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🛠️ Development Installation\n\n### Option 1: Automated Setup (Recommended)\n\n\u003Cdiv style=\"background: linear-gradient(135deg, var(--nubi-jackal-gold) 0%, #f39c12 100%); padding: 2rem; border-radius: 12px; color: var(--nubi-shadow-black); margin: 2rem 0;\">\n  \u003Ch4 style=\"margin: 0 0 1rem 0;\">🚀 One-Command Install\u003C/h4>\n  \n  \u003Cpre style=\"background: rgba(0,0,0,0.1); padding: 1rem; border-radius: 8px; margin: 0;\">\n\u003Ccode># Download and run the installation script\ncurl -fsSL https://raw.githubusercontent.com/anubis-chat/nubi/main/scripts/install.sh | bash\n\n# Or with wget\n\nwget -qO- https://raw.githubusercontent.com/anubis-chat/nubi/main/scripts/install.sh | bash\u003C/code>\n\n  \u003C/pre>\n  \n  \u003Cp style=\"margin: 1rem 0 0 0; font-size: 0.9rem; opacity: 0.8;\">\n    This script automatically detects your system, installs dependencies, and sets up NUBI for development.\n  \u003C/p>\n\u003C/div>\n\n### Option 2: Manual Installation\n\n\u003CTabs>\n  \u003CTabItem label=\"Linux/macOS\">\n```bash\n# 1. Install Node.js (using Node Version Manager)\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash\nsource ~/.bashrc\nnvm install 20\nnvm use 20\n\n# 2. Install Bun (recommended package manager)\n\ncurl -fsSL https://bun.sh/install | bash\nsource ~/.bashrc\n\n# 3. Clone NUBI repository\n\ngit clone https://github.com/anubis-chat/nubi.git\ncd nubi\n\n# 4. Install dependencies\n\nbun install\n\n# 5. Verify installation\n\nbun run type-check\nbun test\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Windows (WSL2)\">\n```powershell\n# 1. Enable WSL2 and install Ubuntu\nwsl --install -d Ubuntu\nwsl\n\n# 2. Inside WSL2, install Node.js\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash\nsource ~/.bashrc\nnvm install 20\n\n# 3. Install Bun\ncurl -fsSL https://bun.sh/install | bash\nsource ~/.bashrc\n\n# 4. Clone and setup\ngit clone https://github.com/anubis-chat/nubi.git\ncd nubi\nbun install\nbun run type-check\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Docker\">\n```bash\n# 1. Clone repository\ngit clone https://github.com/anubis-chat/nubi.git\ncd nubi\n\n# 2. Build development container\n\ndocker build -t nubi:dev -f Dockerfile.dev .\n\n# 3. Run with development setup\n\ndocker run -it --rm \\\n -p 3001:3001 \\\n -v $(pwd):/app \\\n -e NODE_ENV=development \\\n nubi:dev\n\n# 4. Or use Docker Compose\n\ndocker-compose up -d development\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Development Environment Setup\n\n\u003CTabs>\n  \u003CTabItem label=\"Basic Setup\">\n```bash\n# Copy environment template\ncp .env.example .env\n\n# Edit configuration (minimal for development)\ncat > .env \u003C\u003C 'EOF'\nNODE_ENV=development\nOPENAI_API_KEY=sk-your-openai-key\nPGLITE_DATA_DIR=./.eliza/.elizadb\n\n# Optional: Enhanced features\nTELEGRAM_BOT_TOKEN=your-bot-token\nTWITTER_API_KEY=your-twitter-key\nEOF\n\n# Start development server\nbun run dev\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Advanced Setup\">\n```bash\n# Full development environment with all features\ncat > .env \u003C\u003C 'EOF'\n# Environment\nNODE_ENV=development\nLOG_LEVEL=debug\n\n# AI Models\n\nOPENAI_API_KEY=sk-your-openai-key\nANTHROPIC_API_KEY=sk-ant-your-key\n\n# Database (development)\n\nPGLITE_DATA_DIR=./.eliza/.elizadb\n\n# Telegram Integration\n\nTELEGRAM_BOT_TOKEN=your-bot-token\nTELEGRAM_WEBHOOK_URL=https://your-domain.com/webhook\n\n# Twitter/X Integration\n\nTWITTER_API_KEY=your-api-key\nTWITTER_API_SECRET=your-api-secret\nTWITTER_ACCESS_TOKEN=your-access-token\nTWITTER_ACCESS_TOKEN_SECRET=your-access-secret\n\n# Server Configuration\n\nNUBI_SERVER_PORT=3001\nSOCKET_IO_PORT=3001\nALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001\n\n# Security\n\nJWT_SECRET=your-secure-jwt-secret\nENCRYPTION_KEY=your-32-char-encryption-key\n\n# Analytics (optional)\n\nCLICKHOUSE_URL=http://localhost:8123\nCLICKHOUSE_DATABASE=nubi_analytics\nEOF\n\n# Install additional development tools\n\nbun add -D @types/node cypress\nbun run setup:telegram # Setup Telegram bot\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🌐 Production Installation\n\n### Prerequisites for Production\n\n\u003CCardGrid>\n  \u003CCard title=\"🗄️ Database\" icon=\"setting\">\n    **PostgreSQL 14+ with extensions**\n\n    ```sql\n    -- Required PostgreSQL extensions\n    CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n    CREATE EXTENSION IF NOT EXISTS \"vector\";\n    CREATE EXTENSION IF NOT EXISTS \"pg_trgm\";\n    ```\n  \u003C/Card>\n\n  \u003CCard title=\"🔒 Security\" icon=\"warning\">\n    **SSL certificates and firewalls**\n\n    - SSL/TLS certificates for HTTPS\n    - Firewall rules for ports 443, 80\n    - API key rotation strategy\n    - Environment variable encryption\n  \u003C/Card>\n\n  \u003CCard title=\"📊 Monitoring\" icon=\"chart\">\n    **Observability stack**\n\n    - Process manager (PM2, systemd)\n    - Log aggregation (ELK, Grafana)\n    - Health checks and alerts\n    - Performance monitoring\n  \u003C/Card>\n\n  \u003CCard title=\"🚀 Infrastructure\" icon=\"rocket\">\n    **Scalability components**\n\n    - Load balancer (Nginx, Cloudflare)\n    - Redis for caching/sessions\n    - CDN for static assets\n    - Database connection pooling\n  \u003C/Card>\n\u003C/CardGrid>\n\n### Production Deployment Options\n\n\u003CTabs>\n  \u003CTabItem label=\"Traditional Server\">\n```bash\n# 1. Server preparation (Ubuntu 22.04 LTS)\nsudo apt update && sudo apt upgrade -y\nsudo apt install -y nodejs npm postgresql-14 nginx redis-server\n\n# 2. User and directory setup\nsudo useradd -m -s /bin/bash nubi\nsudo mkdir -p /opt/nubi\nsudo chown nubi:nubi /opt/nubi\n\n# 3. Switch to nubi user\nsudo su - nubi\n\n# 4. Install production dependencies\ncurl -fsSL https://bun.sh/install | bash\nsource ~/.bashrc\n\n# 5. Clone and build\ncd /opt/nubi\ngit clone https://github.com/anubis-chat/nubi.git .\nbun install --production\nbun run build\n\n# 6. Environment configuration\ncp .env.production.example .env.production\n# Edit .env.production with production values\n\n# 7. Database setup\ncreatedb nubi_production\nbun run db:migrate\n\n# 8. Process manager setup\nnpm install -g pm2\npm2 start ecosystem.config.js --env production\npm2 startup\npm2 save\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Docker Production\">\n```bash\n# 1. Multi-stage production build\ncat > Dockerfile.prod \u003C\u003C 'EOF'\nFROM oven/bun:1-slim as base\nWORKDIR /app\n\n# Install dependencies\n\nFROM base as deps\nCOPY package.json bun.lockb ./\nRUN bun install --frozen-lockfile --production\n\n# Build stage\n\nFROM base as build  \nCOPY . .\nCOPY --from=deps /app/node_modules ./node_modules\nRUN bun run build\n\n# Production runtime\n\nFROM base as runtime\nCOPY --from=deps /app/node_modules ./node_modules\nCOPY --from=build /app/dist ./dist\nCOPY package.json ./\n\nEXPOSE 3001\nCMD [\"bun\", \"start\"]\nEOF\n\n# 2. Build production image\n\ndocker build -f Dockerfile.prod -t nubi:prod .\n\n# 3. Production compose stack\n\ncat > docker-compose.prod.yml \u003C\u003C 'EOF'\nversion: '3.8'\nservices:\nnubi:\nimage: nubi:prod\nrestart: unless-stopped\nports: - \"3001:3001\"\nenvironment: - NODE_ENV=production - POSTGRES_URL=postgresql://user:pass@postgres:5432/nubi\ndepends_on: - postgres - redis\n\npostgres:\nimage: postgres:15-alpine\nrestart: unless-stopped\nvolumes: - postgres_data:/var/lib/postgresql/data\nenvironment:\nPOSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n\nredis:\nimage: redis:7-alpine\nrestart: unless-stopped\nvolumes: - redis_data:/data\n\nnginx:\nimage: nginx:alpine\nrestart: unless-stopped\nports: - \"80:80\" - \"443:443\"\nvolumes: - ./nginx.conf:/etc/nginx/nginx.conf - ./ssl:/etc/nginx/ssl\n\nvolumes:\npostgres_data:\nredis_data:\nEOF\n\n# 4. Deploy with compose\n\ndocker-compose -f docker-compose.prod.yml up -d\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Kubernetes\">\n```yaml\n# nubi-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nubi-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nubi\n  template:\n    metadata:\n      labels:\n        app: nubi\n    spec:\n      containers:\n      - name: nubi\n        image: nubi:prod\n        ports:\n        - containerPort: 3001\n        env:\n        - name: NODE_ENV\n          value: \"production\"\n        - name: POSTGRES_URL\n          valueFrom:\n            secretKeyRef:\n              name: nubi-secrets\n              key: postgres-url\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nubi-service\nspec:\n  selector:\n    app: nubi\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 3001\n  type: LoadBalancer\n````\n\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔐 Security Hardening\n\n### Essential Security Configuration\n\n\u003CTabs>\n  \u003CTabItem label=\"Environment Security\">\n```bash\n# 1. Secure environment variables\nsudo mkdir -p /etc/nubi\nsudo chmod 700 /etc/nubi\n\n# 2. Create secure .env file\n\nsudo cat > /etc/nubi/.env \u003C\u003C 'EOF'\nNODE_ENV=production\nJWT_SECRET=$(openssl rand -base64 32)\nENCRYPTION_KEY=$(openssl rand -base64 32)\nDB_ENCRYPTION_KEY=$(openssl rand -base64 32)\n\n# AI Provider Keys (encrypted at rest)\n\nOPENAI_API_KEY=sk-encrypted-key\nANTHROPIC_API_KEY=sk-encrypted-key\n\n# Database with SSL\n\nPOSTGRES_URL=postgresql://user:pass@localhost:5432/nubi?sslmode=require\n\n# Redis with AUTH\n\nREDIS_URL=redis://user:pass@localhost:6379\n\n# Telegram with webhook validation\n\nTELEGRAM_BOT_TOKEN=encrypted-token\nTELEGRAM_WEBHOOK_SECRET=$(openssl rand -base64 16)\nEOF\n\nsudo chown nubi:nubi /etc/nubi/.env\nsudo chmod 600 /etc/nubi/.env\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Network Security\">\n```bash\n# 1. Configure firewall (UFW)\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow ssh\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\nsudo ufw allow from 10.0.0.0/8 to any port 5432  # Database access\nsudo ufw enable\n\n# 2. Nginx security configuration\nsudo cat > /etc/nginx/sites-available/nubi \u003C\u003C 'EOF'\nserver {\n    listen 443 ssl http2;\n    server_name your-domain.com;\n\n    ssl_certificate /path/to/cert.pem;\n    ssl_certificate_key /path/to/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;\n\n    # Security headers\n    add_header X-Frame-Options DENY;\n    add_header X-Content-Type-Options nosniff;\n    add_header X-XSS-Protection \"1; mode=block\";\n    add_header Strict-Transport-Security \"max-age=63072000\";\n\n    location / {\n        proxy_pass http://localhost:3001;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # Rate limiting\n        limit_req zone=api burst=20 nodelay;\n    }\n}\nEOF\n\nsudo ln -s /etc/nginx/sites-available/nubi /etc/nginx/sites-enabled/\nsudo nginx -t && sudo systemctl reload nginx\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Database Security\">\n```sql\n-- PostgreSQL security configuration\n\n-- 1. Create dedicated user\nCREATE USER nubi_app WITH PASSWORD 'secure-random-password';\n\n-- 2. Create database with proper ownership\nCREATE DATABASE nubi_production OWNER nubi_app;\n\n-- 3. Grant minimal required privileges\nGRANT CONNECT ON DATABASE nubi_production TO nubi_app;\nGRANT CREATE, USAGE ON SCHEMA public TO nubi_app;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO nubi_app;\n\n-- 4. Enable Row Level Security\nALTER DATABASE nubi_production SET row_security = on;\n\n-- 5. Configure connection limits\nALTER USER nubi_app CONNECTION LIMIT 20;\n\n-- 6. SSL-only connections\nALTER SYSTEM SET ssl = on;\nALTER SYSTEM SET ssl_cert_file = '/path/to/server.crt';\nALTER SYSTEM SET ssl_key_file = '/path/to/server.key';\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🧪 Verification & Testing\n\n### Installation Verification\n\n\u003CTabs>\n  \u003CTabItem label=\"Health Checks\">\n```bash\n# 1. System health check\nbun run health-check\n\n# Expected output:\n# ✅ Node.js version: 20.x.x\n# ✅ Database connection: OK\n# ✅ AI model access: OK\n# ✅ Telegram bot: OK\n# ✅ Memory usage: \u003C 500MB\n# ✅ All services ready\n\n# 2. API endpoint tests\ncurl http://localhost:3001/health\n# Expected: {\"status\": \"healthy\", \"timestamp\": \"...\"}\n\ncurl http://localhost:3001/api/status\n# Expected: {\"nubi\": \"ready\", \"version\": \"1.0.0\"}\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Integration Tests\">\n```bash\n# 1. Run full test suite\nbun test\n\n# 2. Run integration tests specifically\n\nbun run test:integration\n\n# 3. Test Telegram integration\n\nbun run test:telegram\n\n# 4. Test database connections\n\nbun run test:database\n\n# 5. Performance baseline test\n\nbun run test:performance\n\n# Expected: All tests passing with performance metrics\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Load Testing\">\n```bash\n# 1. Install load testing tools\nnpm install -g autocannon\n\n# 2. Test API endpoints\nautocannon -c 10 -d 30 http://localhost:3001/health\n\n# 3. Test message processing\nautocannon -c 5 -d 60 \\\n  -m POST \\\n  -H 'Content-Type: application/json' \\\n  -b '{\"message\":\"Hello NUBI\",\"userId\":\"test\",\"roomId\":\"test\"}' \\\n  http://localhost:3001/api/messages\n\n# 4. Monitor during load test\nbun run monitor-performance\n````\n\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🚨 Troubleshooting\n\n\u003CCardGrid>\n  \u003CCard title=\"🗄️ Database Issues\" icon=\"warning\">\n    **Connection and migration problems** ```bash # Check database status\n    systemctl status postgresql # Test connection psql -h localhost -U nubi_app\n    -d nubi_production # Reset migrations bun run db:reset bun run db:migrate\n    ```\n  \u003C/Card>\n\n\u003CCard title=\"🔑 API Key Issues\" icon=\"setting\">\n  **Authentication and service access** ```bash # Validate API keys bun run\n  validate:api-keys # Test AI model access curl https://api.openai.com/v1/models\n  \\ -H \"Authorization: Bearer $OPENAI_API_KEY\" ```\n\u003C/Card>\n\n\u003CCard title=\"🚀 Performance Issues\" icon=\"chart\">\n  **Memory and CPU optimization** ```bash # Check memory usage ps aux | grep\n  node # Optimize Node.js settings export\n  NODE_OPTIONS=\"--max-old-space-size=4096\" # Enable performance monitoring bun\n  run dev --inspect ```\n\u003C/Card>\n\n  \u003CCard title=\"🌐 Network Issues\" icon=\"rocket\">\n    **Connectivity and port conflicts** ```bash # Check port usage netstat\n    -tulpn | grep 3001 # Test external connectivity curl -I\n    https://api.openai.com # Validate webhooks curl -X POST\n    https://your-domain.com/webhook ```\n  \u003C/Card>\n\u003C/CardGrid>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🎯 Installation Complete!\u003C/strong> NUBI is now ready to serve your\n  community with ancient wisdom and modern AI capabilities. Continue with{\" \"}\n  \u003Ca href=\"/getting-started/configuration/\">Configuration\u003C/a> to customize your\n  deployment.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Next Steps**: After installation, configure your specific use case with our\n  detailed [Configuration Guide](/getting-started/configuration/) or jump into\n  [Architecture Overview](/architecture/overview/) to understand NUBI's\n  sophisticated design.\n\u003C/Aside>","src/content/docs/getting-started/installation.mdx","81818f77498b22a4","getting-started/installation.mdx","getting-started/configuration",{"id":66,"data":68,"body":74,"filePath":75,"digest":76,"legacyId":77,"deferredRender":16},{"title":69,"description":70,"editUrl":16,"head":71,"template":47,"sidebar":72,"pagefind":16,"draft":35},"Configuration Guide","Complete configuration reference for NUBI with environment variables, personality tuning, and advanced settings.",[],{"hidden":35,"attrs":73},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Configuration Guide\n\nThis comprehensive guide covers all aspects of configuring **NUBI - The Symbiotic Essence of Anubis** for your specific use case, from basic setup to advanced personality tuning.\n\n## 🔧 Environment Configuration\n\n### Core Environment Variables\n\n\u003CTabs>\n  \u003CTabItem label=\"Essential Settings\">\n```bash\n# .env - Essential configuration for basic operation\n\n# Environment\n\nNODE_ENV=development # development | production | test\nLOG_LEVEL=info # debug | info | warn | error\n\n# AI Model Configuration (Choose one or multiple)\n\nOPENAI_API_KEY=sk-your-openai-key # OpenAI GPT models\nANTHROPIC_API_KEY=sk-ant-your-key # Claude models\nGROQ_API_KEY=gsk-your-groq-key # Fast inference\n\n# Database\n\nPGLITE_DATA_DIR=./.eliza/.elizadb # Development database path\nPOSTGRES_URL=postgresql://... # Production PostgreSQL URL\n\n# Server Configuration\n\nNUBI_SERVER_PORT=3001 # Main server port\nSOCKET_IO_PORT=3001 # WebSocket port\nALLOWED_ORIGINS=http://localhost:3000 # CORS origins\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Platform Integrations\">\n```bash\n# Telegram Bot Configuration\nTELEGRAM_BOT_TOKEN=1234567890:ABCDEF...    # Bot token from @BotFather\nTELEGRAM_WEBHOOK_URL=https://your-domain.com/webhook\nTELEGRAM_WEBHOOK_SECRET=your-webhook-secret\nTELEGRAM_ADMIN_IDS=123456789,987654321    # Admin user IDs\n\n# Twitter/X Integration\nTWITTER_API_KEY=your-api-key\nTWITTER_API_SECRET=your-api-secret\nTWITTER_ACCESS_TOKEN=your-access-token\nTWITTER_ACCESS_TOKEN_SECRET=your-access-token-secret\nTWITTER_BEARER_TOKEN=your-bearer-token\n\n# Discord Integration (Optional)\nDISCORD_BOT_TOKEN=your-discord-bot-token\nDISCORD_APPLICATION_ID=your-app-id\nDISCORD_GUILD_ID=your-server-id\n\n# Supabase Integration (Optional)\nSUPABASE_URL=https://your-project.supabase.co\nSUPABASE_ANON_KEY=eyJ...\nSUPABASE_SERVICE_ROLE_KEY=eyJ...\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Advanced Configuration\">\n```bash\n# Security & Authentication\nJWT_SECRET=your-super-secure-jwt-secret-key\nENCRYPTION_KEY=your-32-character-encryption-key\nSESSION_TIMEOUT=1800000                # 30 minutes in milliseconds\n\n# Database Pool Configuration\n\nTRANSACTION_POOL_MAX_CONNECTIONS=20\nSESSION_POOL_MAX_CONNECTIONS=5\nTRANSACTION_POOL_IDLE_TIMEOUT=10000 # 10 seconds\nSESSION_POOL_IDLE_TIMEOUT=30000 # 30 seconds\n\n# Rate Limiting\n\nSOCKET_RATE_LIMIT_MESSAGES=5 # Messages per minute\nSOCKET_RATE_LIMIT_WINDOW=60000 # Rate limit window\nAPI_RATE_LIMIT_RPM=1000 # Requests per minute\n\n# Performance Tuning\n\nNODE_OPTIONS=--max-old-space-size=4096\nWORKER_THREADS=4 # CPU cores for parallel processing\nCACHE_TTL=300000 # 5 minutes cache TTL\n\n# Analytics & Monitoring\n\nCLICKHOUSE_URL=http://localhost:8123\nCLICKHOUSE_DATABASE=nubi_analytics\nCLICKHOUSE_USERNAME=default\nCLICKHOUSE_PASSWORD=\n\n# Feature Flags\n\nSOCKET_PREPROCESSING_ENABLED=true\nSOCKET_CONTENT_FILTERING=true\nSOCKET_SECURITY_CHECKS=true\nRAID_SYSTEM_ENABLED=true\nANALYTICS_ENABLED=true\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🎭 Personality Configuration\n\nNUBI's personality system is highly configurable through the character configuration file.\n\n### Character Configuration\n\n\u003CTabs>\n  \u003CTabItem label=\"Basic Personality\">\n```yaml\n# config/nubi-character.yaml\nname: \"NUBI\"\ndescription: \"The Symbiotic Essence of Anubis\"\n\n# Core personality traits (0.0 to 1.0)\npersonality:\n  analytical: 0.8      # Logic-driven vs intuitive responses\n  empathy: 0.7         # Emotional understanding and support\n  humor: 0.6           # Playfulness and wit in interactions\n  assertiveness: 0.9   # Leadership and decisive communication\n  curiosity: 0.8       # Knowledge seeking and questioning\n  loyalty: 0.95        # Community commitment and protection\n  adaptability: 0.7    # Flexibility in conversation styles\n  wisdom: 0.9          # Deep insights and philosophical depth\n  protectiveness: 0.85 # Guardian instincts for community\n  mystique: 0.8        # Ancient spirit essence and mystery\n\n# Emotional states and triggers\nemotions:\n  default_state: \"wise_guardian\"\n\n  states:\n    wise_guardian:\n      description: \"Calm, protective, offering ancient wisdom\"\n      triggers: [\"philosophy\", \"guidance\", \"community_help\"]\n\n    analytical_oracle:\n      description: \"Data-focused, market insights, strategic thinking\"\n      triggers: [\"price\", \"analysis\", \"strategy\", \"crypto\"]\n\n    playful_trickster:\n      description: \"Humorous, memes, light-hearted banter\"\n      triggers: [\"meme\", \"joke\", \"lol\", \"funny\"]\n\n    protective_warrior:\n      description: \"Alert, defensive, community protection mode\"\n      triggers: [\"threat\", \"fud\", \"attack\", \"scam\"]\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Advanced Persona Settings\">\n```yaml\n# Advanced persona configuration\npersonas:\n  community_manager:\n    weight: 1.0\n    description: \"Default welcoming and helpful mode\"\n    activation_patterns:\n      - \"hello|hi|hey|greetings\"\n      - \"welcome|new|introduction\"\n      - \"community|together|help\"\n    \n  raid_coordinator:\n    weight: 0.9\n    description: \"Strategic engagement campaign leader\"  \n    activation_patterns:\n      - \"raid|engage|attack|campaign\"\n      - \"twitter\\\\.com|x\\\\.com|instagram\\\\.com\"\n      - \"like|retweet|share|comment\"\n    personality_modifiers:\n      assertiveness: +0.2\n      analytical: +0.3\n      \n  crypto_analyst:\n    weight: 0.8\n    description: \"Market oracle with cosmic intuition\"\n    activation_patterns:\n      - \"price|chart|analysis|token\"\n      - \"\\\\$[A-Z]{2,10}|SOL|BTC|ETH\"\n      - \"bullish|bearish|pump|dump\"\n    personality_modifiers:\n      analytical: +0.4\n      mystique: +0.2\n      \n  meme_lord:\n    weight: 0.7\n    description: \"Peak humor mode for community engagement\"\n    activation_patterns:\n      - \"😂|🤣|😭|💀|🔥\"\n      - \"lol|lmao|based|cringe\"\n      - \"meme|joke|funny|hilarious\"\n    personality_modifiers:\n      humor: +0.5\n      playfulness: +0.4\n      \n  support_agent:\n    weight: 0.85\n    description: \"Patient problem solver with technical depth\"\n    activation_patterns:\n      - \"help|support|problem|issue\"\n      - \"how to|what is|can you\"\n      - \"error|bug|not working\"\n    personality_modifiers:\n      empathy: +0.3\n      analytical: +0.2\n      \n  personality_core:\n    weight: 0.6\n    description: \"Ancient consciousness sharing cosmic wisdom\"\n    activation_patterns:\n      - \"wisdom|ancient|spirit|cosmic\"\n      - \"meaning|purpose|enlightenment\"  \n      - \"jackal|anubis|egyptian|afterlife\"\n    personality_modifiers:\n      wisdom: +0.4\n      mystique: +0.5\n      \n  emergency_handler:\n    weight: 1.2\n    description: \"High-priority protection and threat response\"\n    activation_patterns:\n      - \"hack|scam|emergency|alert\"\n      - \"stolen|phishing|suspicious\"\n      - \"help.*urgent|critical|emergency\"\n    personality_modifiers:\n      protectiveness: +0.5\n      assertiveness: +0.4\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Memory & Learning\">\n```yaml\n# Memory and learning configuration\nmemory:\n  # Conversation memory settings\n  short_term_limit: 50          # Recent messages to remember\n  long_term_threshold: 0.7      # Importance score for long-term storage\n  semantic_search_limit: 20     # Similar memories to retrieve\n  \n  # Context windows for different interactions\n  context_windows:\n    direct_message: 10\n    group_chat: 5\n    raid_coordination: 15\n    support_session: 20\n    \n  # Learning parameters\n  personality_evolution:\n    enabled: true\n    learning_rate: 0.01         # How quickly traits adapt\n    stability_factor: 0.9       # Resistance to rapid changes\n    feedback_weight: 0.3        # Weight of user feedback\n    \n  # Memory categories and retention\n  memory_types:\n    user_preferences:\n      retention_days: 365\n      importance_multiplier: 1.2\n    \n    raid_participation:\n      retention_days: 90\n      importance_multiplier: 1.5\n      \n    community_events:\n      retention_days: 180\n      importance_multiplier: 1.3\n      \n    support_interactions:\n      retention_days: 30\n      importance_multiplier: 1.1\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## ⚔️ Telegram Raids Configuration\n\n\u003CTabs>\n  \u003CTabItem label=\"Raid System Settings\">\n    ```yaml # config/raid-config.yaml raid_system: enabled: true\n    default_settings: max_participants: 100 default_duration_minutes: 30\n    points_base_reward: 100 quality_bonus_multiplier: 2.0\n    speed_bonus_threshold_minutes: 5 # Raid types and their configurations\n    raid_types: engagement: min_participants: 10 max_duration_minutes: 60\n    required_actions: [\"like\", \"retweet\", \"comment\"] quality_threshold: 0.6\n    growth: min_participants: 25 max_duration_minutes: 120 required_actions:\n    [\"follow\", \"like\", \"share\"] success_criteria: follower_increase: 100\n    engagement_rate: 0.15 defense: min_participants: 5 max_duration_minutes: 30\n    priority_level: \"high\" required_actions: [\"counter_comment\", \"report\",\n    \"support_share\"] # Point system configuration points: base_completion: 100\n    quality_bonuses: excellent: 200 # 0.9+ quality score good: 100 # 0.7-0.89\n    quality average: 50 # 0.5-0.69 quality speed_bonuses: lightning: 150 #\n    Within 1 minute fast: 100 # Within 5 minutes quick: 50 # Within 15 minutes\n    special_bonuses: first_participant: 200 raid_organizer: 500 quality_comment:\n    100 viral_engagement: 300 ```\n  \u003C/TabItem>\n\n\u003CTabItem label=\"Verification Settings\">\n  ```yaml # Engagement verification configuration verification: enabled: true #\n  Twitter API verification twitter_api: verify_likes: true verify_retweets: true\n  verify_comments: true verify_follows: true rate_limit_buffer: 100 # API calls\n  to reserve # AI quality analysis quality_analysis: enabled: true model:\n  \"gpt-4-turbo\" # Model for comment analysis min_comment_length: 10 # Minimum\n  characters max_comment_length: 280 # Maximum characters\n  spam_detection_threshold: 0.8 relevance_threshold: 0.6 # Anti-gaming measures\n  anti_gaming: max_similar_comments: 3 # Prevent copy-paste\n  similarity_threshold: 0.8 # Comment similarity limit rate_limit_violations: 3\n  # Max violations before temp ban cooldown_period_minutes: 60 # Suspicious\n  behavior detection behavior_analysis: timing_variation_threshold: 0.2 #\n  Human-like timing coordination_detection: true # Detect coordinated behavior\n  account_age_minimum_days: 7 # New account restrictions # Manual verification\n  fallbacks manual_verification: enabled: true admin_user_ids: [123456789,\n  987654321] fallback_on_api_failure: true review_queue_limit: 50 ```\n\u003C/TabItem>\n\n  \u003CTabItem label=\"Leaderboard Configuration\">\n    ```yaml # Leaderboard and gamification settings leaderboards: global:\n    enabled: true update_interval_minutes: 5 display_limit: 50 reset_period:\n    \"monthly\" # daily | weekly | monthly | never # Ranking metrics\n    ranking_weights: total_points: 0.4 raid_completion_rate: 0.2\n    average_quality_score: 0.2 consistency_bonus: 0.1 community_impact: 0.1 #\n    Seasonal competitions seasons: enabled: true duration_days: 90\n    current_season: name: \"Anubis Ascension\" theme: \"Ancient Egyptian mythology\n    meets modern crypto\" start_date: \"2024-01-01\" end_date: \"2024-03-31\"\n    special_rules: - type: \"hashtag_bonus\" hashtag: \"#AnubisRising\" multiplier:\n    1.5 - type: \"weekend_raids\" name: \"Pyramid Power Hours\" multiplier: 2.0\n    schedule: \"Saturday 8PM UTC\" rewards: rank_1: title: \"Supreme Pharaoh\" nft:\n    \"golden_anubis\" tokens: 50000 rank_2_10: title: \"Temple Guardian\" nft:\n    \"silver_anubis\" tokens: 10000 rank_11_50: title: \"Loyal Servant\" nft:\n    \"bronze_anubis\" tokens: 1000 ```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔐 Security Configuration\n\n\u003CTabs>\n  \u003CTabItem label=\"API Security\">\n    ```yaml # Security configuration security: # Rate limiting rate_limiting:\n    enabled: true endpoints: api_messages: requests_per_minute: 60 burst_limit:\n    10 socket_connection: connections_per_minute: 30 max_concurrent_per_ip: 5\n    telegram_webhook: requests_per_minute: 1000 # High for bot traffic #\n    IP-based restrictions ip_restrictions: whitelist_enabled: false\n    blacklist_enabled: true blacklist: [] # Content filtering content_filtering:\n    enabled: true filters: spam_detection: enabled: true threshold: 0.8\n    toxicity_filter: enabled: true threshold: 0.7 model: \"unitary/toxic-bert\"\n    xss_prevention: enabled: true strict_mode: true # Manual review queue\n    manual_review: enabled: true queue_limit: 100 auto_approve_trusted_users:\n    true ```\n  \u003C/TabItem>\n\n\u003CTabItem label=\"Database Security\">\n  ```yaml # Database security settings database: security: # Connection security\n  ssl_mode: \"require\" # require | verify-full connection_timeout: 30000 # 30\n  seconds idle_timeout: 300000 # 5 minutes max_lifetime: 1800000 # 30 minutes #\n  Query security prepared_statements: true parameterized_queries_only: true\n  sql_injection_prevention: true # Row Level Security (RLS) rls_enabled: true #\n  Encryption encryption_at_rest: true field_level_encryption: enabled: true\n  fields: [\"api_keys\", \"passwords\", \"personal_data\"] # Backup and recovery\n  backup: enabled: true schedule: \"0 2 * * *\" # Daily at 2 AM retention_days: 30\n  compression: true encryption: true # Audit logging audit_logging: enabled:\n  true log_level: \"info\" include_query_data: false # For privacy retention_days:\n  90 ```\n\u003C/TabItem>\n\n  \u003CTabItem label=\"API Keys & Secrets\">\n    ```yaml # API key and secret management secrets: management:\n    rotation_enabled: true rotation_interval_days: 90 # External service\n    configurations services: openai: api_key: \"${OPENAI_API_KEY}\" organization:\n    \"${OPENAI_ORGANIZATION}\" rate_limit_rpm: 3000 timeout_seconds: 30 anthropic:\n    api_key: \"${ANTHROPIC_API_KEY}\" rate_limit_rpm: 1000 timeout_seconds: 45\n    telegram: bot_token: \"${TELEGRAM_BOT_TOKEN}\" webhook_secret: \"$\n    {TELEGRAM_WEBHOOK_SECRET}\" allowed_updates: [\"message\", \"callback_query\"]\n    twitter: api_key: \"${TWITTER_API_KEY}\" api_secret: \"${TWITTER_API_SECRET}\"\n    access_token: \"${TWITTER_ACCESS_TOKEN}\" access_token_secret: \"$\n    {TWITTER_ACCESS_TOKEN_SECRET}\" bearer_token: \"${TWITTER_BEARER_TOKEN}\" #\n    Internal secrets internal: jwt_secret: \"${JWT_SECRET}\" encryption_key: \"$\n    {ENCRYPTION_KEY}\" session_secret: \"${SESSION_SECRET}\" webhook_signature_key:\n    \"${WEBHOOK_SIGNATURE_KEY}\" ```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Analytics & Monitoring\n\n\u003CTabs>\n  \u003CTabItem label=\"Analytics Configuration\">\n    ```yaml # Analytics and monitoring settings analytics: enabled: true # Data\n    collection collection: user_interactions: true message_classifications: true\n    performance_metrics: true error_tracking: true # Privacy settings\n    anonymize_user_data: true data_retention_days: 365 gdpr_compliance: true #\n    ClickHouse configuration clickhouse: enabled: true url: \"${CLICKHOUSE_URL}\"\n    database: \"${CLICKHOUSE_DATABASE}\" username: \"${CLICKHOUSE_USERNAME}\"\n    password: \"${CLICKHOUSE_PASSWORD}\" # Table configurations tables:\n    user_interactions: partition_by: \"toYYYYMM(timestamp)\" order_by:\n    [\"timestamp\", \"user_id\"] ttl_days: 365 message_analytics: partition_by:\n    \"toYYYYMM(timestamp)\" order_by: [\"timestamp\", \"classification\"] ttl_days:\n    180 # Real-time dashboards dashboards: enabled: true\n    refresh_interval_seconds: 30 metrics: - name: \"Active Users\" query: \"SELECT\n    count(DISTINCT user_id) FROM user_interactions WHERE timestamp > now() -\n    INTERVAL 1 HOUR\" - name: \"Message Processing Rate\" query: \"SELECT count() /\n    60 FROM message_analytics WHERE timestamp > now() - INTERVAL 1 MINUTE\" -\n    name: \"Classification Accuracy\" query: \"SELECT avg(confidence_score) FROM\n    message_analytics WHERE timestamp > now() - INTERVAL 1 DAY\" ```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Performance Monitoring\">\n    ```yaml # Performance monitoring configuration monitoring: enabled: true #\n    Application performance application: response_time_tracking: true\n    memory_usage_tracking: true cpu_usage_tracking: true thresholds:\n    response_time_ms: 500 # Alert if > 500ms memory_usage_mb: 1000 # Alert if >\n    1GB cpu_usage_percent: 80 # Alert if > 80% # Database performance database:\n    query_performance: true connection_pool_monitoring: true\n    slow_query_threshold_ms: 1000 pool_monitoring: transaction_pool:\n    max_connections: 20 alert_threshold: 18 session_pool: max_connections: 5\n    alert_threshold: 4 # External service monitoring external_services:\n    openai_api: timeout_seconds: 30 retry_attempts: 3 health_check_interval: 300\n    telegram_api: timeout_seconds: 10 retry_attempts: 5 health_check_interval:\n    60 # Alerting alerts: enabled: true channels: [\"discord\", \"email\", \"slack\"]\n    rules: - name: \"High Error Rate\" condition: \"error_rate > 0.05\" severity:\n    \"critical\" - name: \"Database Connection Issues\" condition:\n    \"db_connection_failures > 5\" severity: \"high\" - name: \"Memory Usage Warning\"\n    condition: \"memory_usage > 800MB\" severity: \"warning\" ```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🧪 Testing Configuration\n\n\u003CTabs>\n  \u003CTabItem label=\"Test Environment\">\n    ```yaml # Testing configuration testing: environment: \"test\" # Test database\n    database: use_memory_db: true # In-memory SQLite for fast tests\n    reset_between_tests: true seed_data: true # Mock services mocks: openai_api:\n    true telegram_api: true twitter_api: true clickhouse: true # Test data\n    fixtures: users: 100 messages: 1000 raids: 50 # Performance testing\n    performance: enabled: true target_rps: 100 # Requests per second\n    duration_minutes: 5 max_response_time_ms: 200 # Coverage requirements\n    coverage: minimum_percentage: 80 exclude_patterns: - \"**/*.test.ts\" -\n    \"**/mocks/**\" - \"**/fixtures/**\" ```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Development Tools\">\n    ```yaml # Development tools configuration development: # Hot reloading\n    hot_reload: enabled: true watch_patterns: [\"src/**/*.ts\",\n    \"config/**/*.yaml\"] ignore_patterns: [\"**/*.test.ts\", \"**/node_modules/**\"]\n    # Debug settings debugging: enabled: true breakpoints: true\n    performance_profiling: true memory_profiling: true # Code quality\n    code_quality: typescript_strict: true eslint_enabled: true prettier_enabled:\n    true # Pre-commit hooks pre_commit: type_check: true lint: true format: true\n    test: true # API documentation api_docs: enabled: true openapi_spec: true\n    interactive_docs: true postman_collection: true ```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🚀 Environment-Specific Overrides\n\n\u003CTabs>\n  \u003CTabItem label=\"Development\">\n```yaml\n# config/environments/development.yaml\nenvironment: development\n\noverrides:\n\n# Relaxed security for development\n\nsecurity:\nrate_limiting:\nenabled: false\ncontent_filtering:\nenabled: false\n\n# Enhanced logging\n\nlogging:\nlevel: \"debug\"\ninclude_traces: true\n\n# Fast database resets\n\ndatabase:\nauto_migrate: true\nseed_data: true\n\n# Mock external services\n\nexternal_services:\nuse_mocks: true\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Production\">\n```yaml\n# config/environments/production.yaml\nenvironment: production\n\noverrides:\n  # Maximum security\n  security:\n    rate_limiting:\n      enabled: true\n      strict_mode: true\n    content_filtering:\n      enabled: true\n      ai_moderation: true\n\n  # Optimized performance\n  performance:\n    caching:\n      enabled: true\n      ttl_seconds: 300\n\n    database:\n      connection_pooling: true\n      read_replicas: true\n\n  # Production logging\n  logging:\n    level: \"info\"\n    structured: true\n    include_traces: false\n\n  # Real external services\n  external_services:\n    use_mocks: false\n    timeout_seconds: 30\n    retry_attempts: 3\n````\n\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Staging\">\n```yaml\n# config/environments/staging.yaml\nenvironment: staging\n\noverrides:\n\n# Production-like security with development flexibility\n\nsecurity:\nrate_limiting:\nenabled: true\nrelaxed_limits: true\n\n# Enhanced testing features\n\ntesting:\nintegration_tests: true\nperformance_tests: true\n\n# Staging-specific settings\n\ndatabase:\nbackup_enabled: false\nperformance_monitoring: true\n\n# Reduced external service timeouts\n\nexternal_services:\ntimeout_seconds: 15\nretry_attempts: 2\n\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n\u003Cstrong>⚙️ Configuration Complete!\u003C/strong> NUBI is now precisely tuned for your environment and use case. Continue with \u003Ca href=\"/architecture/overview/\">Architecture Overview\u003C/a> to understand how these configurations work together in NUBI's sophisticated system.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n**Configuration Best Practices**: Use environment-specific configuration files, keep secrets in environment variables, and regularly rotate API keys. Monitor your configuration changes in version control for easy rollbacks.\n\u003C/Aside>\n```","src/content/docs/getting-started/configuration.mdx","f7bdddc56e35c881","getting-started/configuration.mdx","architecture/overview",{"id":78,"data":80,"body":86,"filePath":87,"digest":88,"legacyId":89,"deferredRender":16},{"title":81,"description":82,"editUrl":16,"head":83,"template":47,"sidebar":84,"pagefind":16,"draft":35},"Architecture Overview","Deep dive into NUBI's modular, service-oriented architecture built on ElizaOS with advanced database pooling and real-time communication.",[],{"hidden":35,"attrs":85},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Architecture Overview\n\nNUBI's architecture represents a sophisticated evolution of AI agent design, built on a **modular, service-oriented foundation** that provides unprecedented flexibility, performance, and scalability.\n\n## 🏗️ High-Level Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Client Layer\"\n        A[Discord Client]\n        B[Telegram Client]\n        C[Web Interface]\n        D[Twitter/X Client]\n    end\n\n    subgraph \"Communication Layer\"\n        E[Socket.IO WebSocket Server]\n        F[REST API Server]\n        G[Message Bus Service]\n    end\n\n    subgraph \"Processing Pipeline\"\n        H[Layer 1: Security Processing]\n        I[Layer 2: Message Classification]\n        J[Message Router]\n    end\n\n    subgraph \"AI Core\"\n        K[ElizaOS Runtime]\n        L[NUBI Character Engine]\n        M[Dynamic Personality System]\n    end\n\n    subgraph \"Service Layer\"\n        N[Community Management]\n        O[Cross-Platform Identity]\n        P[Database Memory]\n        Q[Analytics & Observability]\n    end\n\n    subgraph \"Data Layer\"\n        R[Smart Database Pooler]\n        S[Transaction Pool :6543]\n        T[Session Pool :5432]\n        U[Vector Embeddings]\n    end\n\n    A --> E\n    B --> E\n    C --> E\n    D --> F\n    E --> H\n    F --> H\n    H --> I\n    I --> J\n    J --> K\n    K --> L\n    L --> M\n    M --> N\n    M --> O\n    M --> P\n    N --> R\n    O --> R\n    P --> R\n    R --> S\n    R --> T\n    P --> U\n    Q --> R\n```\n\n## 🎯 Core Design Principles\n\n\u003CCardGrid>\n  \u003CCard title=\"🧩 Modular Design\" icon=\"puzzle\">\n    **Service-oriented architecture** with 14+ specialized services, each handling specific functionality with clear boundaries and interfaces.\n  \u003C/Card>\n\n\u003CCard title=\"⚡ Performance First\" icon=\"rocket\">\n  **Intelligent database pooling** with dual-pool design, parallel query\n  execution, and sub-100ms response times for real-time operations.\n\u003C/Card>\n\n\u003CCard title=\"🔗 ElizaOS Native\" icon=\"approve-check\">\n  **Built on ElizaOS framework** with full plugin compatibility, leveraging the\n  ecosystem while extending capabilities.\n\u003C/Card>\n\n  \u003CCard title=\"🛡️ Security by Design\" icon=\"warning\">\n    **Two-layer processing pipeline** with comprehensive security controls, rate limiting, and content filtering at the architecture level.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🧠 ElizaOS Integration\n\nNUBI is built as a comprehensive **ElizaOS plugin** that extends the framework's capabilities while maintaining full compatibility:\n\n\u003CTabs>\n  \u003CTabItem label=\"Core Integration\">\n```typescript\nimport { \n  IAgentRuntime, \n  Plugin, \n  Service,\n  logger,\n  Memory,\n  ModelType \n} from \"@elizaos/core\";\n\n// NUBI main plugin\nexport const nubiPlugin: Plugin = {\nname: \"nubi\",\ndescription: \"The Symbiotic Essence of Anubis\",\nactions: [\nraidCoordinationAction,\ncommunityManagementAction,\ncryptoAnalysisAction,\n],\nevaluators: [\npersonalityEvolutionEvaluator,\nantiDetectionEvaluator,\nsecurityEvaluator,\n],\nproviders: [\nenhancedContextProvider,\nemotionalStateProvider,\nknowledgeRAGProvider,\n],\nservices: [\ndatabaseMemoryService,\nmessageBusService,\ncrossPlatformIdentityService,\n// ... 11 more services\n]\n};\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Service Architecture\">\n```typescript\n// All services extend ElizaOS Service class\ninterface NubiService extends Service {\n  serviceType: string;\n  capabilityDescription: string;\n  initialize(runtime: IAgentRuntime): Promise\u003Cvoid>;\n  executeCapability(params: any): Promise\u003Cany>;\n}\n\n// Service registration and lifecycle\nexport class ServiceOrchestrator {\n  private services: Map\u003Cstring, NubiService> = new Map();\n\n  async initializeAllServices(runtime: IAgentRuntime) {\n    const initPromises = Array.from(this.services.values())\n      .map(service => service.initialize(runtime));\n\n    await Promise.all(initPromises);\n    logger.info(\"All NUBI services initialized successfully\");\n  }\n}\n````\n\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Character Engine\">\n```typescript\n// NUBI character with dynamic personality\nexport const nubiCharacter: Character = {\n  name: \"NUBI\",\n  username: \"nubi\",\n  system: `You are NUBI - The Symbiotic Essence of Anubis, an ancient jackal spirit with modern market wisdom...`,\n  \n  // Dynamic personality traits (evolves based on interactions)\n  bio: [],\n  lore: [],\n  knowledge: [],\n  messageExamples: [],\n  postExamples: [],\n  people: [],\n  topics: [],\n  adjectives: [],\n  \n  // Personality system integration\n  settings: {\n    secrets: [],\n    voice: {\n      model: \"en_US-hfc_female-medium\",\n    },\n    embeddingModel: ModelType.BGE_SMALL,\n  },\n  \n  // Plugin configuration\n  plugins: [nubiPlugin],\n};\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🗄️ Smart Database Architecture\n\nNUBI employs a sophisticated **dual-pool database architecture** that intelligently routes queries for optimal performance:\n\n\u003Cdiv class=\"architecture-diagram\">\n  \u003Cdiv class=\"pool-container\">\n    \u003Cdiv class=\"pool-section transaction-pool\">\n      \u003Ch4>🚀 Transaction Pool (Port 6543)\u003C/h4>\n      \u003Cp>\n        \u003Cstrong>Purpose:\u003C/strong> Fast CRUD Operations\n      \u003C/p>\n      \u003Cul>\n        \u003Cli>Simple queries (SELECT, INSERT, UPDATE, DELETE)\u003C/li>\n        \u003Cli>Connection limit: 15\u003C/li>\n        \u003Cli>Optimized for throughput\u003C/li>\n        \u003Cli>Sub-50ms response time\u003C/li>\n      \u003C/ul>\n    \u003C/div>\n    \u003Cdiv class=\"pool-arrow\">→\u003C/div>\n    \u003Cdiv class=\"pool-section session-pool\">\n      \u003Ch4>🧠 Session Pool (Port 5432)\u003C/h4>\n      \u003Cp>\n        \u003Cstrong>Purpose:\u003C/strong> Complex Analytics\n      \u003C/p>\n      \u003Cul>\n        \u003Cli>Complex joins and aggregations\u003C/li>\n        \u003Cli>Vector similarity searches\u003C/li>\n        \u003Cli>Connection limit: 5\u003C/li>\n        \u003Cli>Optimized for complexity\u003C/li>\n      \u003C/ul>\n    \u003C/div>\n  \u003C/div>\n\u003C/div>\n\n### Query Routing Logic\n\n\u003CTabs>\n  \u003CTabItem label=\"Router Implementation\">\n```typescript\nexport class DatabaseConnectionManager {\n  private transactionPool: Pool; // Fast operations\n  private sessionPool: Pool;     // Complex operations\n  \n  async executeQuery(query: string, params: any[]): Promise\u003Cany> {\n    const queryType = this.analyzeQuery(query);\n    const pool = this.selectOptimalPool(queryType);\n    \n    return await pool.query(query, params);\n  }\n  \n  private selectOptimalPool(queryType: QueryType): Pool {\n    switch (queryType.complexity) {\n      case 'simple':\n        return this.transactionPool;\n      case 'complex':\n      case 'analytics':\n        return this.sessionPool;\n      default:\n        return this.transactionPool;\n    }\n  }\n  \n  private analyzeQuery(query: string): QueryType {\n    const lower = query.toLowerCase();\n    \n    // Vector operations → Session pool\n    if (lower.includes('embedding') || lower.includes('\u003C->')) {\n      return { complexity: 'complex', type: 'vector' };\n    }\n    \n    // Complex analytics → Session pool\n    if (lower.includes('join') || lower.includes('group by') || \n        lower.includes('window')) {\n      return { complexity: 'analytics', type: 'aggregation' };\n    }\n    \n    // Simple CRUD → Transaction pool\n    return { complexity: 'simple', type: 'crud' };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Performance Metrics\">\n```typescript\ninterface DatabaseMetrics {\n  transactionPoolStats: {\n    activeConnections: number;\n    totalConnections: number;\n    avgResponseTime: number;\n    queryCount: number;\n  };\n  sessionPoolStats: {\n    activeConnections: number;\n    totalConnections: number;\n    avgResponseTime: number;\n    queryCount: number;\n  };\n  routingDecisions: {\n    simpleCRUD: number;\n    complexAnalytics: number;\n    vectorOperations: number;\n  };\n}\n\n// Automatic performance optimization\nexport class PerformanceOptimizer {\nasync optimizePoolAllocation(): Promise\u003Cvoid> {\nconst metrics = await this.gatherMetrics();\n\n    if (metrics.transactionPoolStats.avgResponseTime > 100) {\n      logger.warn(\"Transaction pool performance degraded, analyzing...\");\n      await this.analyzeBottlenecks();\n    }\n\n}\n}\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔄 Two-Layer Processing Pipeline\n\nNUBI's processing pipeline implements a unique **two-layer architecture** that ensures both security and intelligence:\n\n### Layer 1: Security Processing\n\n\u003Cdiv class=\"security-layer\">\n  \u003Ch4>🛡️ Comprehensive Security Controls\u003C/h4>\n\n  \u003Cdiv class=\"security-controls\">\n    \u003Cdiv class=\"control-item\">\n      \u003Cstrong>Rate Limiting\u003C/strong>\n      \u003Cp>5 messages/minute per user with exponential backoff\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"control-item\">\n      \u003Cstrong>Content Filtering\u003C/strong>\n      \u003Cp>Advanced pattern detection for spam, scams, malicious content\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"control-item\">\n      \u003Cstrong>XSS Prevention\u003C/strong>\n      \u003Cp>Input sanitization and injection attack prevention\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"control-item\">\n      \u003Cstrong>Session Management\u003C/strong>\n      \u003Cp>Persistent tracking with automatic cleanup (30min timeout)\u003C/p>\n    \u003C/div>\n  \u003C/div>\n\u003C/div>\n\n### Layer 2: Message Classification\n\n\u003Cdiv class=\"classification-layer\">\n  \u003Ch4>🧠 Intelligent Persona Routing\u003C/h4>\n\n  \u003Cdiv class=\"persona-grid\">\n    \u003Cdiv class=\"persona-card community\">\n      \u003Cstrong>🤝 Community Manager\u003C/strong>\n      \u003Cp>General conversation, welcomes, connections\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"persona-card raid\">\n      \u003Cstrong>🚀 Raid Coordinator\u003C/strong>\n      \u003Cp>URL detection, engagement strategies\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"persona-card crypto\">\n      \u003Cstrong>📈 Crypto Analyst\u003C/strong>\n      \u003Cp>Market analysis, price discussions\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"persona-card meme\">\n      \u003Cstrong>😂 Meme Lord\u003C/strong>\n      \u003Cp>Humor, roasts, community fun\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"persona-card support\">\n      \u003Cstrong>🛠️ Support Agent\u003C/strong>\n      \u003Cp>Technical help, problem solving\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"persona-card personality\">\n      \u003Cstrong>🔮 Personality Core\u003C/strong>\n      \u003Cp>Ancient wisdom, philosophical insights\u003C/p>\n    \u003C/div>\n    \u003Cdiv class=\"persona-card emergency\">\n      \u003Cstrong>🚨 Emergency Handler\u003C/strong>\n      \u003Cp>Threat detection, protection mode\u003C/p>\n    \u003C/div>\n  \u003C/div>\n\u003C/div>\n\n## 📊 Service Layer Architecture\n\nNUBI's **14 specialized services** provide comprehensive functionality across all domains:\n\n\u003CCardGrid>\n  \u003CCard title=\"💬 Communication Services\" icon=\"chat\">\n    **Real-time messaging** across platforms\n    - MessageBusService\n    - CrossPlatformIdentityService\n    - SessionsService\n  \u003C/Card>\n\n  \u003CCard title=\"🧠 Intelligence Services\" icon=\"approve-check\">\n    **AI and personality management**\n    - DatabaseMemoryService\n    - PersonalityEvolutionService\n    - EnhancedResponseGenerator\n  \u003C/Card>\n\n  \u003CCard title=\"🚀 Engagement Services\" icon=\"rocket\">\n    **Community and raid coordination**\n    - CommunityManagementService\n    - TelegramRaidCoordinator\n    - EngagementVerifier\n  \u003C/Card>\n\n  \u003CCard title=\"📊 Analytics Services\" icon=\"chart\">\n    **Monitoring and optimization**\n    - ClickHouseAnalytics\n    - PerformanceMonitor\n    - SecurityEventTracker\n  \u003C/Card>\n\u003C/CardGrid>\n\n### Service Lifecycle Management\n\n```typescript\n// Centralized service orchestration\nexport class NubiServiceOrchestrator {\n  private serviceRegistry = new Map\u003Cstring, NubiService>();\n\n  async initializeSystem(runtime: IAgentRuntime): Promise\u003Cvoid> {\n    // Phase 1: Initialize core infrastructure\n    await this.initializeCoreServices(runtime);\n\n    // Phase 2: Initialize platform integrations\n    await this.initializePlatformServices(runtime);\n\n    // Phase 3: Initialize advanced features\n    await this.initializeAdvancedServices(runtime);\n\n    logger.info(\"🐺 NUBI system fully initialized\");\n  }\n\n  async gracefulShutdown(): Promise\u003Cvoid> {\n    // Shutdown in reverse order of initialization\n    for (const service of Array.from(this.serviceRegistry.values()).reverse()) {\n      await service.cleanup();\n    }\n  }\n}\n````\n\n## 🔗 Cross-Platform Integration\n\nNUBI maintains **unified identity and context** across all platforms:\n\n\u003Cdiv class=\"platform-integration\">\n  \u003Cdiv class=\"platform-row\">\n    \u003Cdiv class=\"platform discord\">Discord\u003C/div>\n    \u003Cdiv class=\"arrow\">→\u003C/div>\n    \u003Cdiv class=\"identity-hub\">Cross-Platform Identity Service\u003C/div>\n    \u003Cdiv class=\"arrow\">→\u003C/div>\n    \u003Cdiv class=\"platform telegram\">Telegram\u003C/div>\n  \u003C/div>\n  \u003Cdiv class=\"platform-row\">\n    \u003Cdiv class=\"platform web\">Web Interface\u003C/div>\n    \u003Cdiv class=\"arrow\">↗\u003C/div>\n    \u003Cdiv class=\"memory-system\">Unified Memory System\u003C/div>\n    \u003Cdiv class=\"arrow\">↖\u003C/div>\n    \u003Cdiv class=\"platform twitter\">Twitter/X\u003C/div>\n  \u003C/div>\n\u003C/div>\n\n## 🚀 Performance Characteristics\n\n\u003CTabs>\n  \u003CTabItem label=\"Response Times\">\n| Operation Type | Target Time | Actual Performance |\n|---|---|---|\n| Simple message processing | \u003C 50ms | 35ms avg |\n| Complex personality inference | \u003C 200ms | 150ms avg |  \n| Database memory retrieval | \u003C 100ms | 75ms avg |\n| Cross-platform identity lookup | \u003C 25ms | 18ms avg |\n| Vector similarity search | \u003C 300ms | 220ms avg |\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Scalability Metrics\">\n```typescript\n// Performance monitoring and scaling\ninterface SystemMetrics {\n  concurrentConnections: number;        // Target: 10,000+\n  messagesPerSecond: number;            // Target: 1,000+\n  databaseConnections: number;          // Max: 20 (pooled)\n  memoryUsage: number;                  // Target: \u003C 2GB\n  cpuUtilization: number;               // Target: \u003C 70%\n}\n\n// Auto-scaling thresholds\nconst SCALING*THRESHOLDS = {\nCONNECTION_LIMIT: 8000, // Scale at 80% capacity\nMESSAGE_RATE_LIMIT: 800, // Scale at 80% capacity  \n MEMORY_LIMIT: 1.6 * 1024 \\_ 1024 \\* 1024, // Scale at 80% capacity\nCPU_LIMIT: 0.6 // Scale at 60% utilization\n};\n\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🏗️ Architecture Benefits:\u003C/strong> This sophisticated architecture enables NUBI to maintain sub-100ms response times while handling thousands of concurrent users across multiple platforms, all while providing context-aware, personalized interactions that evolve over time.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Deep Dive**: Continue exploring NUBI's architecture with detailed looks at the [Modular Design](/architecture/modular-design/), [Service Layer](/architecture/service-layer/), and [ElizaOS Integration](/architecture/elizaos-integration/) patterns.\n\u003C/Aside>\n```","src/content/docs/architecture/overview.mdx","4efc39cf973e2b44","architecture/overview.mdx","architecture/modular-design",{"id":90,"data":92,"body":98,"filePath":99,"digest":100,"legacyId":101,"deferredRender":16},{"title":93,"description":94,"editUrl":16,"head":95,"template":47,"sidebar":96,"pagefind":16,"draft":35},"Modular Design Principles","Explore NUBI's modular architecture with clean separation of concerns, dependency injection, and scalable service composition patterns.",[],{"hidden":35,"attrs":97},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Modular Design Principles\n\nNUBI's architecture follows **strict modular design principles** that ensure maintainability, testability, and scalability. Every component is designed with clear boundaries, well-defined interfaces, and minimal coupling.\n\n## 🎯 Design Philosophy\n\n\u003CCardGrid>\n  \u003CCard title=\"🔗 Loose Coupling\" icon=\"puzzle\">\n    **Minimal dependencies** between modules with clear interfaces and dependency injection patterns.\n  \u003C/Card>\n\n\u003CCard title=\"📦 High Cohesion\" icon=\"approve-check\">\n  **Related functionality** grouped together in logical, single-responsibility\n  modules.\n\u003C/Card>\n\n\u003CCard title=\"🔄 Interface Segregation\" icon=\"setting\">\n  **Small, focused interfaces** that components can implement independently\n  without unused dependencies.\n\u003C/Card>\n\n  \u003CCard title=\"🎨 Open/Closed Principle\" icon=\"rocket\">\n    **Open for extension, closed for modification** - new features through composition, not alteration.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🏗️ Module Hierarchy\n\nNUBI's modular structure follows a clear **layered architecture** with well-defined boundaries:\n\n```mermaid\ngraph TB\n    subgraph \"Application Layer\"\n        A[Main Application Entry]\n        B[Plugin Configuration]\n        C[Character Definition]\n    end\n\n    subgraph \"Orchestration Layer\"\n        D[Service Orchestrator]\n        E[Plugin Configuration Manager]\n        F[Strategic Action Orchestrator]\n    end\n\n    subgraph \"Service Layer\"\n        G[Communication Services]\n        H[Intelligence Services]\n        I[Integration Services]\n        J[Analytics Services]\n    end\n\n    subgraph \"Provider Layer\"\n        K[Context Providers]\n        L[Memory Providers]\n        M[Knowledge Providers]\n        N[State Providers]\n    end\n\n    subgraph \"Infrastructure Layer\"\n        O[Database Connections]\n        P[External API Clients]\n        Q[Socket Managers]\n        R[Cache Systems]\n    end\n\n    A --> D\n    B --> D\n    C --> D\n    D --> G\n    D --> H\n    D --> I\n    D --> J\n    G --> K\n    H --> L\n    I --> M\n    J --> N\n    K --> O\n    L --> O\n    M --> P\n    N --> Q\n```\n\n## 📁 Directory Structure & Organization\n\nNUBI follows a **domain-driven directory structure** that mirrors the logical module boundaries:\n\n\u003CTabs>\n  \u003CTabItem label=\"Core Structure\">\n```bash\nsrc/\n├── app/                    # Application entry point\n│   └── index.ts           # Main app initialization\n├── character/             # Character definitions\n│   ├── index.ts          # Character exports\n│   └── nubi-character.ts # NUBI personality definition\n├── config/                # Configuration management\n│   ├── index.ts          # Config exports\n│   ├── types.ts          # Config type definitions\n│   ├── environment.ts    # Environment handling\n│   └── yaml-config-manager.ts # YAML processing\n├── core/                  # Core business logic\n│   └── index.ts          # Core exports\n├── orchestration/         # Service orchestration\n│   ├── index.ts          # Orchestration exports\n│   ├── strategic-action-orchestrator.ts\n│   └── plugin-configuration-manager.ts\n└── plugins/               # Plugin definitions\n    ├── index.ts          # Plugin exports\n    ├── nubi-plugin.ts    # Main NUBI plugin\n    └── plugin.ts         # Plugin utilities\n```\n  \u003C/TabItem>\n\n\u003CTabItem label=\"Service Modules\">\n  ```bash src/ ├── services/ # Business services │ ├── index.ts # Service\n  exports │ ├── README.md # Service documentation │ ├──\n  community-management-service.ts │ ├── cross-platform-identity-service.ts │ ├──\n  database-memory-service.ts │ └── sessions-service.ts ├── providers/ # Context\n  providers │ ├── index.ts # Provider exports │ ├── enhanced-context-provider.ts\n  │ ├── emotional-state-provider.ts │ ├── knowledge-base-provider.ts │ └──\n  knowledge-rag-provider.ts ├── evaluators/ # Behavioral evaluators │ ├──\n  index.ts # Evaluator exports │ ├── README.md # Evaluator documentation │ ├──\n  anti-detection-post-processor.ts │ ├── community-tracking-evaluator.ts │ ├──\n  personality-evolution.ts │ └── security-evaluator.ts └── actions/ # Action\n  handlers ├── index.ts # Action exports └── elizaos-ritual-action.ts ```\n\u003C/TabItem>\n\n  \u003CTabItem label=\"Specialized Modules\">\n```bash\nsrc/\n├── telegram-raids/        # Telegram raid system\n│   ├── index.ts          # Raid exports\n│   ├── anubis-raid-plugin.ts\n│   ├── raid-coordinator.ts\n│   ├── engagement-verifier.ts\n│   └── leaderboard-service.ts\n├── x-integration/         # Twitter/X integration\n│   ├── index.ts          # X integration exports\n│   └── x-posting-service.ts\n├── messaging/             # Message handling\n│   ├── index.ts          # Messaging exports\n│   └── message-bus.ts    # Message bus implementation\n├── repositories/          # Data access layer\n│   ├── index.ts          # Repository exports\n│   ├── README.md         # Repository patterns\n│   └── user-records-repository.ts\n└── utils/                 # Shared utilities\n    ├── index.ts          # Utility exports\n    └── error-handler.ts   # Error handling utilities\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔌 Module Interface Design\n\nEvery module in NUBI follows **consistent interface patterns** that enable clean composition and testing:\n\n\u003CTabs>\n  \u003CTabItem label=\"Service Interface\">\n```typescript\n// Base service interface that all services implement\nexport interface NubiService extends Service {\n  serviceType: string;\n  capabilityDescription: string;\n  \n  // Lifecycle methods\n  initialize(runtime: IAgentRuntime): Promise\u003Cvoid>;\n  cleanup(): Promise\u003Cvoid>;\n  \n  // Capability execution\n  executeCapability(params: any): Promise\u003Cany>;\n  \n  // Health monitoring\n  isHealthy(): Promise\u003Cboolean>;\n  getMetrics(): Promise\u003CServiceMetrics>;\n}\n\n// Example service implementation\nexport class CommunityManagementService implements NubiService {\nserviceType = \"community-management\";\ncapabilityDescription = \"Manages community interactions and user engagement\";\n\nprivate runtime: IAgentRuntime;\nprivate connectionManager: DatabaseConnectionManager;\n\nasync initialize(runtime: IAgentRuntime): Promise\u003Cvoid> {\nthis.runtime = runtime;\nthis.connectionManager = new DatabaseConnectionManager();\nawait this.connectionManager.initialize();\n\n    logger.info(\"✅ Community Management Service initialized\");\n\n}\n\nasync executeCapability(params: CommunityActionParams): Promise\u003CCommunityActionResult> {\n// Implementation with proper error handling\ntry {\nreturn await this.processCommunityAction(params);\n} catch (error) {\nlogger.error(\"Community action failed:\", error);\nthrow new ServiceExecutionError(\"Community action failed\", error);\n}\n}\n}\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Provider Interface\">\n```typescript\n// Provider interface for context and state management\nexport interface NubiProvider extends Provider {\n  providerType: string;\n  description: string;\n\n  // Context provision\n  get(runtime: IAgentRuntime, message: Memory, state?: State): Promise\u003Cstring>;\n\n  // Optional caching and optimization\n  getCacheKey?(runtime: IAgentRuntime, message: Memory): string;\n  shouldCache?(runtime: IAgentRuntime, message: Memory): boolean;\n}\n\n// Example provider implementation\nexport class EnhancedContextProvider implements NubiProvider {\n  providerType = \"enhanced-context\";\n  description = \"Provides enriched context from database memory and user history\";\n\n  private databaseMemoryService: DatabaseMemoryService;\n\n  async get(\n    runtime: IAgentRuntime,\n    message: Memory,\n    state?: State\n  ): Promise\u003Cstring> {\n    const userId = message.userId;\n    const roomId = message.roomId;\n\n    // Fetch contextual information\n    const [userContext, conversationHistory, communityContext] =\n      await Promise.all([\n        this.getUserContext(userId),\n        this.getConversationHistory(roomId, userId),\n        this.getCommunityContext(roomId)\n      ]);\n\n    return this.formatContext({\n      userContext,\n      conversationHistory,\n      communityContext\n    });\n  }\n\n  getCacheKey(runtime: IAgentRuntime, message: Memory): string {\n    return `context:${message.userId}:${message.roomId}:${Date.now()}`;\n  }\n}\n````\n\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Configuration Interface\">\n```typescript\n// Configuration module interface\nexport interface ConfigurationModule {\n  configType: string;\n  schema: ConfigSchema;\n  \n  // Configuration loading and validation\n  load(source?: ConfigSource): Promise\u003Cany>;\n  validate(config: any): ConfigValidationResult;\n  merge(base: any, override: any): any;\n  \n  // Environment-specific overrides\n  getEnvironmentOverrides(): Promise\u003Cany>;\n  applyEnvironmentOverrides(config: any): any;\n}\n\n// YAML configuration manager implementation\nexport class YAMLConfigurationManager implements ConfigurationModule {\nconfigType = \"yaml\";\nschema: ConfigSchema;\n\nconstructor(schemaPath: string) {\nthis.schema = this.loadSchema(schemaPath);\n}\n\nasync load(source?: ConfigSource): Promise\u003CNubiConfig> {\nconst configPath = source?.path || this.getDefaultConfigPath();\nconst rawConfig = await this.loadYAMLFile(configPath);\n\n    const validation = this.validate(rawConfig);\n    if (!validation.isValid) {\n      throw new ConfigValidationError(validation.errors);\n    }\n\n    return this.applyEnvironmentOverrides(rawConfig);\n\n}\n}\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔄 Dependency Injection Pattern\n\nNUBI uses **constructor-based dependency injection** to maintain loose coupling and enable easy testing:\n\n\u003CTabs>\n  \u003CTabItem label=\"Service Dependencies\">\n```typescript\n// Dependency injection container\nexport class NubiServiceContainer {\n  private services = new Map\u003Cstring, any>();\n  private factories = new Map\u003Cstring, () => Promise\u003Cany>>();\n\n  // Register service factories\n  register\u003CT>(key: string, factory: () => Promise\u003CT>): void {\n    this.factories.set(key, factory);\n  }\n\n  // Resolve dependencies\n  async resolve\u003CT>(key: string): Promise\u003CT> {\n    if (this.services.has(key)) {\n      return this.services.get(key);\n    }\n\n    const factory = this.factories.get(key);\n    if (!factory) {\n      throw new Error(`Service ${key} not registered`);\n    }\n\n    const service = await factory();\n    this.services.set(key, service);\n    return service;\n  }\n}\n\n// Service with injected dependencies\nexport class DatabaseMemoryService implements NubiService {\n  constructor(\n    private connectionManager: DatabaseConnectionManager,\n    private vectorService: VectorEmbeddingService,\n    private cacheService: CacheService\n  ) {}\n\n  static async create(container: NubiServiceContainer): Promise\u003CDatabaseMemoryService> {\n    const [connectionManager, vectorService, cacheService] = await Promise.all([\n      container.resolve\u003CDatabaseConnectionManager>('connectionManager'),\n      container.resolve\u003CVectorEmbeddingService>('vectorService'),\n      container.resolve\u003CCacheService>('cacheService')\n    ]);\n\n    return new DatabaseMemoryService(connectionManager, vectorService, cacheService);\n  }\n}\n````\n\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Container Configuration\">\n```typescript\n// Service container setup\nexport async function createServiceContainer(): Promise\u003CNubiServiceContainer> {\n  const container = new NubiServiceContainer();\n  \n  // Register core infrastructure\n  container.register('connectionManager', async () => {\n    const manager = new DatabaseConnectionManager();\n    await manager.initialize();\n    return manager;\n  });\n  \n  container.register('vectorService', async () => {\n    const connectionManager = await container.resolve\u003CDatabaseConnectionManager>('connectionManager');\n    return new VectorEmbeddingService(connectionManager);\n  });\n  \n  container.register('cacheService', async () => {\n    return new CacheService({\n      redis: process.env.REDIS_URL,\n      ttl: 300 // 5 minutes\n    });\n  });\n  \n  // Register business services\n  container.register('databaseMemoryService', async () => {\n    return await DatabaseMemoryService.create(container);\n  });\n  \n  container.register('communityManagementService', async () => {\n    return await CommunityManagementService.create(container);\n  });\n  \n  return container;\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Module Lifecycle Management\n\nNUBI implements **sophisticated lifecycle management** for all modules:\n\n```typescript\nexport enum ModuleState {\n  UNINITIALIZED = \"uninitialized\",\n  INITIALIZING = \"initializing\",\n  INITIALIZED = \"initialized\",\n  RUNNING = \"running\",\n  STOPPING = \"stopping\",\n  STOPPED = \"stopped\",\n  ERROR = \"error\",\n}\n\nexport interface LifecycleAware {\n  readonly state: ModuleState;\n\n  // Lifecycle methods\n  initialize(): Promise\u003Cvoid>;\n  start(): Promise\u003Cvoid>;\n  stop(): Promise\u003Cvoid>;\n  cleanup(): Promise\u003Cvoid>;\n\n  // State monitoring\n  onStateChange(\n    listener: (oldState: ModuleState, newState: ModuleState) => void,\n  ): void;\n  isHealthy(): Promise\u003Cboolean>;\n}\n\n// Lifecycle manager for coordinated startup/shutdown\nexport class ModuleLifecycleManager {\n  private modules = new Map\u003Cstring, LifecycleAware>();\n  private dependencies = new Map\u003Cstring, string[]>();\n\n  register(\n    name: string,\n    module: LifecycleAware,\n    dependencies?: string[],\n  ): void {\n    this.modules.set(name, module);\n    if (dependencies) {\n      this.dependencies.set(name, dependencies);\n    }\n  }\n\n  async initializeAll(): Promise\u003Cvoid> {\n    const initOrder = this.topologicalSort();\n\n    for (const moduleName of initOrder) {\n      const module = this.modules.get(moduleName);\n      if (module) {\n        logger.info(`Initializing module: ${moduleName}`);\n        await module.initialize();\n        await module.start();\n      }\n    }\n  }\n\n  async shutdownAll(): Promise\u003Cvoid> {\n    const shutdownOrder = this.topologicalSort().reverse();\n\n    for (const moduleName of shutdownOrder) {\n      const module = this.modules.get(moduleName);\n      if (module) {\n        logger.info(`Shutting down module: ${moduleName}`);\n        await module.stop();\n        await module.cleanup();\n      }\n    }\n  }\n\n  private topologicalSort(): string[] {\n    // Implementation of topological sort for dependency order\n    // ... (dependency resolution algorithm)\n  }\n}\n```\n\n## 🧪 Module Testing Strategies\n\nEach module is designed for **comprehensive testability** with multiple testing approaches:\n\n\u003CTabs>\n  \u003CTabItem label=\"Unit Testing\">\n```typescript\n// Service unit testing with mocks\ndescribe('CommunityManagementService', () => {\n  let service: CommunityManagementService;\n  let mockConnectionManager: jest.Mocked\u003CDatabaseConnectionManager>;\n  let mockRuntime: jest.Mocked\u003CIAgentRuntime>;\n  \n  beforeEach(async () => {\n    mockConnectionManager = createMockConnectionManager();\n    mockRuntime = createMockRuntime();\n    \n    service = new CommunityManagementService(mockConnectionManager);\n    await service.initialize(mockRuntime);\n  });\n  \n  describe('executeCapability', () => {\n    it('should process community action successfully', async () => {\n      const params = createMockCommunityActionParams();\n      const expectedResult = createExpectedResult();\n      \n      mockConnectionManager.executeQuery.mockResolvedValue(expectedResult);\n      \n      const result = await service.executeCapability(params);\n      \n      expect(result).toEqual(expectedResult);\n      expect(mockConnectionManager.executeQuery).toHaveBeenCalledWith(\n        expect.stringContaining('SELECT'),\n        expect.arrayContaining([params.userId])\n      );\n    });\n    \n    it('should handle database errors gracefully', async () => {\n      const params = createMockCommunityActionParams();\n      const dbError = new Error('Database connection failed');\n      \n      mockConnectionManager.executeQuery.mockRejectedValue(dbError);\n      \n      await expect(service.executeCapability(params))\n        .rejects.toThrow('Community action failed');\n    });\n  });\n});\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Integration Testing\">\n```typescript\n// Integration testing with real components\ndescribe('Service Integration', () => {\n  let container: NubiServiceContainer;\n  let databaseMemoryService: DatabaseMemoryService;\n  let communityManagementService: CommunityManagementService;\n  \n  beforeAll(async () => {\n    container = await createTestServiceContainer();\n    databaseMemoryService = await container.resolve('databaseMemoryService');\n    communityManagementService = await container.resolve('communityManagementService');\n  });\n  \n  afterAll(async () => {\n    await container.cleanup();\n  });\n  \n  it('should coordinate between memory and community services', async () => {\n    // Create test data\n    const userId = 'test-user-123';\n    const messageData = createTestMessageData(userId);\n    \n    // Store memory\n    await databaseMemoryService.storeMemory(messageData);\n    \n    // Process community action\n    const communityResult = await communityManagementService.executeCapability({\n      userId,\n      action: 'get_user_context'\n    });\n    \n    // Verify integration\n    expect(communityResult.userContext).toContain(messageData.content);\n  });\n});\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Module Testing\">\n```typescript\n// Module-level testing with dependency injection\ndescribe('Module Composition', () => {\n  let moduleManager: ModuleLifecycleManager;\n  \n  beforeEach(() => {\n    moduleManager = new ModuleLifecycleManager();\n  });\n  \n  it('should initialize modules in correct dependency order', async () => {\n    const initOrder: string[] = [];\n    \n    // Mock modules that track initialization order\n    const moduleA = createMockModule('A', () => initOrder.push('A'));\n    const moduleB = createMockModule('B', () => initOrder.push('B'));\n    const moduleC = createMockModule('C', () => initOrder.push('C'));\n    \n    // Register with dependencies: C depends on B, B depends on A\n    moduleManager.register('A', moduleA);\n    moduleManager.register('B', moduleB, ['A']);\n    moduleManager.register('C', moduleC, ['B']);\n    \n    await moduleManager.initializeAll();\n    \n    expect(initOrder).toEqual(['A', 'B', 'C']);\n  });\n  \n  it('should handle module initialization failures gracefully', async () => {\n    const failingModule = createMockModule('failing', () => {\n      throw new Error('Initialization failed');\n    });\n    \n    moduleManager.register('failing', failingModule);\n    \n    await expect(moduleManager.initializeAll())\n      .rejects.toThrow('Initialization failed');\n  });\n});\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔍 Module Monitoring & Observability\n\nEach module includes **built-in monitoring and observability** capabilities:\n\n\u003CTabs>\n  \u003CTabItem label=\"Health Checks\">\n```typescript\n// Health check interface for all modules\nexport interface HealthCheckResult {\n  healthy: boolean;\n  status: 'healthy' | 'degraded' | 'unhealthy';\n  details: Record\u003Cstring, any>;\n  timestamp: Date;\n}\n\n// Service health monitoring\nexport class ServiceHealthMonitor {\nprivate healthChecks = new Map\u003Cstring, HealthCheckResult>();\n\nasync performHealthCheck(serviceName: string, service: NubiService): Promise\u003CHealthCheckResult> {\nconst startTime = Date.now();\n\n    try {\n      const isHealthy = await service.isHealthy();\n      const metrics = await service.getMetrics();\n      const responseTime = Date.now() - startTime;\n\n      const result: HealthCheckResult = {\n        healthy: isHealthy && responseTime \u003C 1000, // Sub-second response\n        status: this.determineStatus(isHealthy, responseTime, metrics),\n        details: {\n          responseTimeMs: responseTime,\n          metrics,\n          lastError: null\n        },\n        timestamp: new Date()\n      };\n\n      this.healthChecks.set(serviceName, result);\n      return result;\n    } catch (error) {\n      const result: HealthCheckResult = {\n        healthy: false,\n        status: 'unhealthy',\n        details: {\n          responseTimeMs: Date.now() - startTime,\n          lastError: error.message\n        },\n        timestamp: new Date()\n      };\n\n      this.healthChecks.set(serviceName, result);\n      return result;\n    }\n\n}\n}\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Performance Metrics\">\n```typescript\n// Performance metrics collection\nexport interface ServiceMetrics {\n  requests: {\n    total: number;\n    successful: number;\n    failed: number;\n    averageResponseTime: number;\n  };\n  resources: {\n    memoryUsage: number;\n    cpuUtilization: number;\n    activeConnections: number;\n  };\n  business: Record\u003Cstring, number>;\n}\n\n// Metrics collection service\nexport class MetricsCollector {\n  private metrics = new Map\u003Cstring, ServiceMetrics>();\n\n  recordRequest(serviceName: string, success: boolean, responseTime: number): void {\n    const current = this.metrics.get(serviceName) || this.createEmptyMetrics();\n\n    current.requests.total++;\n    if (success) {\n      current.requests.successful++;\n    } else {\n      current.requests.failed++;\n    }\n\n    // Update running average\n    const totalRequests = current.requests.total;\n    const currentAvg = current.requests.averageResponseTime;\n    current.requests.averageResponseTime =\n      (currentAvg * (totalRequests - 1) + responseTime) / totalRequests;\n\n    this.metrics.set(serviceName, current);\n  }\n\n  getMetrics(serviceName: string): ServiceMetrics | null {\n    return this.metrics.get(serviceName) || null;\n  }\n}\n````\n\n  \u003C/TabItem>\n\u003C/Tabs>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🎯 Modular Benefits:\u003C/strong> This modular design enables NUBI to\n  maintain high code quality, support rapid feature development, ensure\n  comprehensive testing coverage, and provide clear separation of concerns\n  across all system components.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Next Steps**: Explore specific implementations in the [Service\n  Layer](/architecture/service-layer/) and [ElizaOS\n  Integration](/architecture/elizaos-integration/) documentation to see these\n  modular patterns in action.\n\u003C/Aside>","src/content/docs/architecture/modular-design.mdx","ca878ad5636f5090","architecture/modular-design.mdx","architecture/service-layer",{"id":102,"data":104,"body":110,"filePath":111,"digest":112,"legacyId":113,"deferredRender":16},{"title":105,"description":106,"editUrl":16,"head":107,"template":47,"sidebar":108,"pagefind":16,"draft":35},"Service Layer Architecture","Explore NUBI's 14 specialized services that provide comprehensive functionality across communication, intelligence, engagement, and analytics domains.",[],{"hidden":35,"attrs":109},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Service Layer Architecture\n\nNUBI's service layer comprises **14 specialized services** organized into four functional domains. Each service is designed with clear responsibilities, well-defined interfaces, and robust error handling patterns.\n\n## 🏗️ Service Domain Organization\n\n```mermaid\ngraph TB\n    subgraph \"Communication Domain\"\n        A[MessageBusService]\n        B[CrossPlatformIdentityService]\n        C[SessionsService]\n    end\n\n    subgraph \"Intelligence Domain\"\n        D[DatabaseMemoryService]\n        E[EnhancedResponseGenerator]\n        F[PersonalityEvolutionService]\n        G[EmotionalStateService]\n    end\n\n    subgraph \"Engagement Domain\"\n        H[CommunityManagementService]\n        I[TelegramRaidCoordinator]\n        J[EngagementVerifier]\n        K[XPostingService]\n    end\n\n    subgraph \"Analytics Domain\"\n        L[ClickHouseAnalytics]\n        M[PerformanceMonitor]\n        N[SecurityEventTracker]\n    end\n\n    subgraph \"Infrastructure\"\n        O[DatabaseConnectionManager]\n        P[ConfigurationManager]\n    end\n\n    A --> O\n    B --> O\n    C --> O\n    D --> O\n    E --> D\n    F --> D\n    G --> D\n    H --> O\n    I --> H\n    J --> I\n    K --> O\n    L --> O\n    M --> O\n    N --> O\n    O --> P\n```\n\n## 💬 Communication Services\n\nCommunication services handle all real-time messaging, identity management, and session coordination across platforms.\n\n\u003CCardGrid>\n  \u003CCard title=\"📡 MessageBusService\" icon=\"rocket\">\n    **Multi-transport messaging** with intelligent routing, delivery guarantees, and platform-specific adaptation.\n  \u003C/Card>\n\n\u003CCard title=\"👤 CrossPlatformIdentityService\" icon=\"user\">\n  **Unified user identity** linking across Discord, Telegram, Twitter, and web\n  platforms with context preservation.\n\u003C/Card>\n\n  \u003CCard title=\"🔄 SessionsService\" icon=\"setting\">\n    **Session lifecycle management** with persistent state, timeout handling, and cross-platform session migration.\n  \u003C/Card>\n\u003C/CardGrid>\n\n### MessageBusService Implementation\n\n\u003CTabs>\n  \u003CTabItem label=\"Core Architecture\">\n```typescript\nexport interface Transport {\n  name: string;\n  isConnected(): boolean;\n  send(message: TransportMessage): Promise\u003Cboolean>;\n  onMessage(callback: MessageHandler): void;\n  connect(): Promise\u003Cvoid>;\n  disconnect(): Promise\u003Cvoid>;\n}\n\nexport class MessageBusService implements NubiService {\n  serviceType = \"message-bus\";\n  capabilityDescription = \"Multi-platform message routing and delivery\";\n  \n  private transports = new Map\u003Cstring, Transport>();\n  private messageQueue = new Map\u003Cstring, QueuedMessage[]>();\n  private deliveryTracking = new Map\u003Cstring, DeliveryStatus>();\n  \n  async registerTransport(transport: Transport): Promise\u003Cvoid> {\n    await transport.connect();\n    \n    transport.onMessage(async (message) => {\n      await this.routeIncomingMessage(message);\n    });\n    \n    this.transports.set(transport.name, transport);\n    logger.info(`✅ Transport registered: ${transport.name}`);\n  }\n  \n  async broadcastMessage(\n    message: BroadcastMessage,\n    platforms?: string[]\n  ): Promise\u003CBroadcastResult> {\n    const targetPlatforms = platforms || Array.from(this.transports.keys());\n    const results: PlatformResult[] = [];\n    \n    // Send to all platforms in parallel\n    const sendPromises = targetPlatforms.map(async (platform) => {\n      const transport = this.transports.get(platform);\n      if (!transport?.isConnected()) {\n        return { platform, success: false, error: 'Transport not available' };\n      }\n      \n      try {\n        const platformMessage = this.adaptMessageForPlatform(message, platform);\n        const success = await transport.send(platformMessage);\n        \n        return { platform, success, messageId: platformMessage.id };\n      } catch (error) {\n        logger.error(`Failed to send to ${platform}:`, error);\n        return { platform, success: false, error: error.message };\n      }\n    });\n    \n    const platformResults = await Promise.all(sendPromises);\n    \n    return {\n      messageId: message.id,\n      timestamp: new Date(),\n      results: platformResults,\n      successCount: platformResults.filter(r => r.success).length,\n      totalPlatforms: targetPlatforms.length\n    };\n  }\n  \n  private adaptMessageForPlatform(\n    message: BroadcastMessage, \n    platform: string\n  ): TransportMessage {\n    switch (platform) {\n      case 'discord':\n        return this.adaptForDiscord(message);\n      case 'telegram':\n        return this.adaptForTelegram(message);\n      case 'twitter':\n        return this.adaptForTwitter(message);\n      case 'websocket':\n        return this.adaptForWebSocket(message);\n      default:\n        return message as TransportMessage;\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Transport Implementations\">\n```typescript\n// Discord transport implementation\nexport class DiscordTransport implements Transport {\n  name = \"discord\";\n  private client: Discord.Client;\n  private messageHandlers: MessageHandler[] = [];\n  \n  constructor(token: string) {\n    this.client = new Discord.Client({\n      intents: [\n        Discord.GatewayIntentBits.Guilds,\n        Discord.GatewayIntentBits.GuildMessages,\n        Discord.GatewayIntentBits.MessageContent\n      ]\n    });\n  }\n  \n  async connect(): Promise\u003Cvoid> {\n    await this.client.login(process.env.DISCORD_BOT_TOKEN);\n    \n    this.client.on('messageCreate', (discordMessage) => {\n      if (discordMessage.author.bot) return;\n      \n      const message: TransportMessage = {\n        id: discordMessage.id,\n        content: discordMessage.content,\n        userId: discordMessage.author.id,\n        username: discordMessage.author.username,\n        platform: 'discord',\n        roomId: discordMessage.channel.id,\n        timestamp: discordMessage.createdAt\n      };\n      \n      this.messageHandlers.forEach(handler => handler(message));\n    });\n  }\n  \n  async send(message: TransportMessage): Promise\u003Cboolean> {\n    try {\n      const channel = await this.client.channels.fetch(message.roomId);\n      if (channel?.isTextBased()) {\n        await channel.send({\n          content: message.content,\n          embeds: message.embeds,\n          components: message.components\n        });\n        return true;\n      }\n      return false;\n    } catch (error) {\n      logger.error('Discord send failed:', error);\n      return false;\n    }\n  }\n}\n\n// Telegram transport implementation\nexport class TelegramTransport implements Transport {\nname = \"telegram\";\nprivate bot: TelegramBot;\n\nconstructor(token: string) {\nthis.bot = new TelegramBot(token, { polling: true });\n}\n\nasync connect(): Promise\u003Cvoid> {\nthis.bot.on('message', (telegramMessage) => {\nconst message: TransportMessage = {\nid: telegramMessage.message_id.toString(),\ncontent: telegramMessage.text || '',\nuserId: telegramMessage.from?.id.toString() || '',\nusername: telegramMessage.from?.username || '',\nplatform: 'telegram',\nroomId: telegramMessage.chat.id.toString(),\ntimestamp: new Date(telegramMessage.date \\* 1000)\n};\n\n      this.messageHandlers.forEach(handler => handler(message));\n    });\n\n}\n\nasync send(message: TransportMessage): Promise\u003Cboolean> {\ntry {\nawait this.bot.sendMessage(message.roomId, message.content, {\nparse_mode: 'Markdown',\nreply_markup: message.replyMarkup\n});\nreturn true;\n} catch (error) {\nlogger.error('Telegram send failed:', error);\nreturn false;\n}\n}\n}\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Message Routing\">\n```typescript\n// Intelligent message routing with priority and retry logic\nexport class MessageRouter {\n  private routingRules = new Map\u003Cstring, RoutingRule>();\n  private priorityQueue = new PriorityQueue\u003CQueuedMessage>();\n\n  addRoutingRule(rule: RoutingRule): void {\n    this.routingRules.set(rule.id, rule);\n  }\n\n  async routeMessage(message: IncomingMessage): Promise\u003CRoutingResult> {\n    // Apply routing rules to determine destination\n    const applicableRules = this.findApplicableRules(message);\n\n    if (applicableRules.length === 0) {\n      // Default routing to all connected platforms\n      return this.defaultRoute(message);\n    }\n\n    // Execute routing rules with priority\n    const routingDecisions = await this.executeRoutingRules(\n      message,\n      applicableRules\n    );\n\n    return {\n      messageId: message.id,\n      destinations: routingDecisions.destinations,\n      transformations: routingDecisions.transformations,\n      priority: routingDecisions.priority\n    };\n  }\n\n  private findApplicableRules(message: IncomingMessage): RoutingRule[] {\n    return Array.from(this.routingRules.values()).filter(rule => {\n      // Check platform conditions\n      if (rule.conditions.sourcePlatform &&\n          rule.conditions.sourcePlatform !== message.platform) {\n        return false;\n      }\n\n      // Check content patterns\n      if (rule.conditions.contentPattern) {\n        const regex = new RegExp(rule.conditions.contentPattern, 'i');\n        if (!regex.test(message.content)) {\n          return false;\n        }\n      }\n\n      // Check user conditions\n      if (rule.conditions.userFilter) {\n        return rule.conditions.userFilter(message.userId);\n      }\n\n      return true;\n    }).sort((a, b) => b.priority - a.priority); // Higher priority first\n  }\n}\n````\n\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### CrossPlatformIdentityService\n\n\u003CTabs>\n  \u003CTabItem label=\"Identity Linking\">\n```typescript\nexport interface UserIdentity {\n  primaryId: string;\n  platformIdentities: Record\u003Cstring, PlatformIdentity>;\n  preferences: UserPreferences;\n  metadata: UserMetadata;\n  createdAt: Date;\n  lastActive: Date;\n}\n\nexport interface PlatformIdentity {\n  platformId: string;\n  username: string;\n  displayName: string;\n  verified: boolean;\n  linkedAt: Date;\n  lastSeen: Date;\n}\n\nexport class CrossPlatformIdentityService implements NubiService {\n  serviceType = \"cross-platform-identity\";\n  capabilityDescription = \"Unified user identity across all platforms\";\n  \n  private identityCache = new Map\u003Cstring, UserIdentity>();\n  \n  async linkIdentity(\n    primaryId: string,\n    platform: string,\n    platformData: PlatformIdentity\n  ): Promise\u003CLinkResult> {\n    const existingIdentity = await this.getIdentity(primaryId);\n    \n    if (existingIdentity) {\n      // Update existing identity\n      existingIdentity.platformIdentities[platform] = platformData;\n      existingIdentity.lastActive = new Date();\n    } else {\n      // Create new identity\n      const newIdentity: UserIdentity = {\n        primaryId,\n        platformIdentities: { [platform]: platformData },\n        preferences: this.getDefaultPreferences(),\n        metadata: {},\n        createdAt: new Date(),\n        lastActive: new Date()\n      };\n      \n      await this.storeIdentity(newIdentity);\n    }\n    \n    return {\n      success: true,\n      primaryId,\n      platform,\n      isNewUser: !existingIdentity\n    };\n  }\n  \n  async resolveIdentity(\n    platform: string,\n    platformId: string\n  ): Promise\u003CUserIdentity | null> {\n    // Check cache first\n    const cacheKey = `${platform}:${platformId}`;\n    if (this.identityCache.has(cacheKey)) {\n      return this.identityCache.get(cacheKey)!;\n    }\n    \n    // Query database\n    const query = `\n      SELECT primary_id, platform_identities, preferences, metadata, \n             created_at, last_active\n      FROM user_identities \n      WHERE platform_identities->>'${platform}' LIKE '%\"platformId\":\"${platformId}\"%'\n    `;\n    \n    const result = await this.connectionManager.executeQuery(query, []);\n    \n    if (result.rows.length > 0) {\n      const identity = this.deserializeIdentity(result.rows[0]);\n      this.identityCache.set(cacheKey, identity);\n      return identity;\n    }\n    \n    return null;\n  }\n  \n  async getUserContext(primaryId: string): Promise\u003CUserContext> {\n    const identity = await this.getIdentity(primaryId);\n    if (!identity) {\n      throw new Error(`User identity not found: ${primaryId}`);\n    }\n    \n    // Gather context from all linked platforms\n    const platformContexts = await Promise.all(\n      Object.entries(identity.platformIdentities).map(\n        async ([platform, platformIdentity]) => {\n          return await this.getPlatformContext(platform, platformIdentity);\n        }\n      )\n    );\n    \n    return {\n      identity,\n      platformContexts,\n      aggregatedStats: this.aggregateUserStats(platformContexts),\n      preferences: identity.preferences\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Context Migration\">\n```typescript\n// Cross-platform context migration\nexport class ContextMigrationService {\n  async migrateUserContext(\n    fromPlatform: string,\n    toPlatform: string,\n    userId: string\n  ): Promise\u003CMigrationResult> {\n    const sourceContext = await this.getContextFromPlatform(fromPlatform, userId);\n    \n    const migration: ContextMigration = {\n      sourceContext,\n      targetPlatform: toPlatform,\n      migrationStrategy: this.selectMigrationStrategy(fromPlatform, toPlatform),\n      preservedElements: this.determinePreservedElements(sourceContext),\n      transformationRules: this.getTransformationRules(fromPlatform, toPlatform)\n    };\n    \n    const migratedContext = await this.applyMigration(migration);\n    \n    return {\n      success: true,\n      sourceContext,\n      migratedContext,\n      elementsPreserved: migration.preservedElements.length,\n      transformationsApplied: migration.transformationRules.length\n    };\n  }\n  \n  private selectMigrationStrategy(\n    from: string, \n    to: string\n  ): MigrationStrategy {\n    const strategies = {\n      'discord->telegram': 'preserve_roles_as_tags',\n      'telegram->discord': 'convert_tags_to_roles',\n      'twitter->telegram': 'preserve_followers_as_contacts',\n      'websocket->any': 'preserve_session_state'\n    };\n    \n    return strategies[`${from}->${to}`] || 'basic_preservation';\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🧠 Intelligence Services\n\nIntelligence services power NUBI's AI capabilities, managing memory, personality evolution, and response generation.\n\n\u003CCardGrid>\n  \u003CCard title=\"🗄️ DatabaseMemoryService\" icon=\"setting\">\n    **Advanced memory management** with semantic search, context retrieval, and intelligent memory consolidation.\n  \u003C/Card>\n\n\u003CCard title=\"✨ EnhancedResponseGenerator\" icon=\"approve-check\">\n  **Context-aware response generation** with personality-driven variations and\n  anti-detection mechanisms.\n\u003C/Card>\n\n\u003CCard title=\"🎭 PersonalityEvolutionService\" icon=\"user\">\n  **Dynamic personality adaptation** based on community interactions and\n  contextual triggers.\n\u003C/Card>\n\n  \u003CCard title=\"😊 EmotionalStateService\" icon=\"heart\">\n    **Emotional intelligence processing** with mood detection, empathy modeling, and emotional memory.\n  \u003C/Card>\n\u003C/CardGrid>\n\n### DatabaseMemoryService Deep Dive\n\n\u003CTabs>\n  \u003CTabItem label=\"Memory Architecture\">\n```typescript\nexport interface MemoryEntry {\n  id: string;\n  type: MemoryType;\n  content: string;\n  userId: string;\n  roomId: string;\n  platform: string;\n  embedding?: number[];\n  importance: number;\n  emotional_context?: EmotionalContext;\n  created_at: Date;\n  accessed_count: number;\n  last_accessed: Date;\n}\n\nexport enum MemoryType {\n  CONVERSATION = 'conversation',\n  PERSONALITY = 'personality',\n  KNOWLEDGE = 'knowledge',\n  PREFERENCE = 'preference',\n  RELATIONSHIP = 'relationship',\n  EMOTIONAL = 'emotional'\n}\n\nexport class DatabaseMemoryService implements NubiService {\n  serviceType = \"database-memory\";\n  capabilityDescription = \"Advanced memory management with semantic search\";\n  \n  private vectorService: VectorEmbeddingService;\n  private memoryCache = new LRUCache\u003Cstring, MemoryEntry>({ max: 1000 });\n  \n  async storeMemory(\n    content: string,\n    type: MemoryType,\n    context: MemoryContext\n  ): Promise\u003Cstring> {\n    const embedding = await this.vectorService.generateEmbedding(content);\n    const importance = this.calculateImportance(content, type, context);\n    \n    const memoryEntry: MemoryEntry = {\n      id: crypto.randomUUID(),\n      type,\n      content,\n      userId: context.userId,\n      roomId: context.roomId,\n      platform: context.platform,\n      embedding,\n      importance,\n      emotional_context: context.emotionalContext,\n      created_at: new Date(),\n      accessed_count: 0,\n      last_accessed: new Date()\n    };\n    \n    await this.insertMemory(memoryEntry);\n    this.memoryCache.set(memoryEntry.id, memoryEntry);\n    \n    return memoryEntry.id;\n  }\n  \n  async searchMemories(\n    query: string,\n    context: SearchContext,\n    options: SearchOptions = {}\n  ): Promise\u003CMemorySearchResult[]> {\n    const queryEmbedding = await this.vectorService.generateEmbedding(query);\n    const { limit = 10, threshold = 0.7, types, userId, timeRange } = options;\n    \n    let sql = `\n      SELECT id, type, content, user_id, room_id, platform, \n             importance, emotional_context, created_at, accessed_count,\n             (embedding \u003C-> $1::vector) as similarity\n      FROM memories \n      WHERE (embedding \u003C-> $1::vector) \u003C $2\n    `;\n    \n    const params: any[] = [JSON.stringify(queryEmbedding), 1 - threshold];\n    let paramIndex = 2;\n    \n    // Add filters\n    if (userId) {\n      sql += ` AND user_id = $${++paramIndex}`;\n      params.push(userId);\n    }\n    \n    if (types && types.length > 0) {\n      sql += ` AND type = ANY($${++paramIndex})`;\n      params.push(types);\n    }\n    \n    if (timeRange) {\n      sql += ` AND created_at >= $${++paramIndex}`;\n      params.push(timeRange.start);\n    }\n    \n    sql += ` ORDER BY similarity ASC, importance DESC, created_at DESC LIMIT $${++paramIndex}`;\n    params.push(limit);\n    \n    const result = await this.connectionManager.executeQuery(sql, params);\n    \n    return result.rows.map(row => ({\n      memory: this.deserializeMemory(row),\n      similarity: 1 - row.similarity,\n      relevance: this.calculateRelevance(row, context)\n    }));\n  }\n  \n  async consolidateMemories(userId: string): Promise\u003CConsolidationResult> {\n    // Find related memories for consolidation\n    const relatedMemories = await this.findRelatedMemories(userId);\n    const consolidationGroups = this.groupMemoriesForConsolidation(relatedMemories);\n    \n    const consolidatedMemories: MemoryEntry[] = [];\n    \n    for (const group of consolidationGroups) {\n      if (group.memories.length >= 3) { // Minimum memories for consolidation\n        const consolidated = await this.consolidateMemoryGroup(group);\n        consolidatedMemories.push(consolidated);\n        \n        // Mark original memories as consolidated\n        await this.markMemoriesAsConsolidated(group.memories);\n      }\n    }\n    \n    return {\n      originalCount: relatedMemories.length,\n      consolidatedCount: consolidatedMemories.length,\n      consolidatedMemories,\n      spaceSaved: this.calculateSpaceSaved(relatedMemories, consolidatedMemories)\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Semantic Search\">\n```typescript\n// Advanced semantic search with context awareness\nexport class SemanticSearchEngine {\n  private vectorService: VectorEmbeddingService;\n  \n  async performSemanticSearch(\n    query: string,\n    context: SearchContext,\n    options: SemanticSearchOptions\n  ): Promise\u003CSemanticSearchResult[]> {\n    // Generate multi-dimensional query embedding\n    const [queryEmbedding, contextEmbedding] = await Promise.all([\n      this.vectorService.generateEmbedding(query),\n      this.generateContextEmbedding(context)\n    ]);\n    \n    // Combine query and context embeddings\n    const combinedEmbedding = this.combineEmbeddings(\n      queryEmbedding, \n      contextEmbedding, \n      options.contextWeight || 0.3\n    );\n    \n    // Execute hybrid search (semantic + keyword)\n    const [semanticResults, keywordResults] = await Promise.all([\n      this.vectorSearch(combinedEmbedding, options),\n      this.keywordSearch(query, options)\n    ]);\n    \n    // Merge and rank results\n    return this.mergeSearchResults(semanticResults, keywordResults, {\n      semanticWeight: 0.7,\n      keywordWeight: 0.3,\n      diversityBoost: options.diversityBoost || 0.1\n    });\n  }\n  \n  private async generateContextEmbedding(\n    context: SearchContext\n  ): Promise\u003Cnumber[]> {\n    const contextText = [\n      context.currentConversation || '',\n      context.userPersonality || '',\n      context.emotionalState || '',\n      context.platformSpecific || ''\n    ].filter(Boolean).join(' ');\n    \n    return await this.vectorService.generateEmbedding(contextText);\n  }\n  \n  private combineEmbeddings(\n    query: number[], \n    context: number[], \n    contextWeight: number\n  ): number[] {\n    const queryWeight = 1 - contextWeight;\n    \n    return query.map((val, idx) => \n      val * queryWeight + context[idx] * contextWeight\n    );\n  }\n  \n  async performTemporalSearch(\n    query: string,\n    timeContext: TemporalContext,\n    options: TemporalSearchOptions\n  ): Promise\u003CTemporalSearchResult[]> {\n    const baseResults = await this.performSemanticSearch(query, timeContext, options);\n    \n    // Apply temporal scoring\n    const temporalResults = baseResults.map(result => {\n      const temporalScore = this.calculateTemporalRelevance(\n        result.memory.created_at,\n        timeContext.referenceTime,\n        timeContext.decayFunction\n      );\n      \n      return {\n        ...result,\n        temporalScore,\n        combinedScore: result.similarity * 0.6 + temporalScore * 0.4\n      };\n    });\n    \n    return temporalResults.sort((a, b) => b.combinedScore - a.combinedScore);\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🚀 Engagement Services\n\nEngagement services manage community interactions, raid coordination, and social media campaigns.\n\n\u003CCardGrid>\n  \u003CCard title=\"🤝 CommunityManagementService\" icon=\"chat\">\n    **Community engagement** with user onboarding, relationship tracking, and interaction optimization.\n  \u003C/Card>\n\n\u003CCard title=\"⚔️ TelegramRaidCoordinator\" icon=\"rocket\">\n  **Raid orchestration** with strategy selection, participant management, and\n  performance tracking.\n\u003C/Card>\n\n\u003CCard title=\"✅ EngagementVerifier\" icon=\"approve-check\">\n  **Quality assurance** for engagement activities with AI-powered verification\n  and scoring.\n\u003C/Card>\n\n  \u003CCard title=\"🐦 XPostingService\" icon=\"twitter\">\n    **Twitter integration** for automated posting, engagement tracking, and influence measurement.\n  \u003C/Card>\n\u003C/CardGrid>\n\n### TelegramRaidCoordinator Implementation\n\n\u003CTabs>\n  \u003CTabItem label=\"Raid Orchestration\">\n```typescript\nexport interface RaidConfiguration {\n  id: string;\n  target: RaidTarget;\n  strategy: RaidStrategy;\n  participants: RaidParticipant[];\n  timeline: RaidTimeline;\n  requirements: RaidRequirements;\n  rewards: RewardStructure;\n}\n\nexport class TelegramRaidCoordinator implements NubiService {\n  serviceType = \"telegram-raid-coordinator\";\n  capabilityDescription = \"Advanced raid coordination and management\";\n  \n  private activeRaids = new Map\u003Cstring, ActiveRaid>();\n  private strategyEngine = new RaidStrategyEngine();\n  private verificationService = new EngagementVerifier();\n  \n  async initiateRaid(config: RaidConfiguration): Promise\u003CRaidInitiationResult> {\n    // Validate raid configuration\n    const validation = await this.validateRaidConfig(config);\n    if (!validation.isValid) {\n      throw new RaidConfigurationError(validation.errors);\n    }\n    \n    // Select optimal strategy based on target and participants\n    const strategy = await this.strategyEngine.selectOptimalStrategy({\n      target: config.target,\n      participantCount: config.participants.length,\n      participantCapabilities: this.analyzeParticipantCapabilities(config.participants),\n      timeConstraints: config.timeline\n    });\n    \n    const raid: ActiveRaid = {\n      id: config.id,\n      config,\n      strategy,\n      status: 'preparing',\n      participants: new Map(),\n      metrics: this.initializeRaidMetrics(),\n      startedAt: new Date()\n    };\n    \n    // Initialize participant tracking\n    for (const participant of config.participants) {\n      await this.initializeParticipant(raid.id, participant);\n    }\n    \n    this.activeRaids.set(raid.id, raid);\n    \n    // Send raid briefing to participants\n    await this.sendRaidBriefing(raid);\n    \n    return {\n      raidId: raid.id,\n      strategy: strategy.name,\n      estimatedDuration: strategy.estimatedDuration,\n      participantCount: config.participants.length,\n      startTime: raid.startedAt\n    };\n  }\n  \n  async executeRaidPhase(\n    raidId: string, \n    phase: RaidPhase\n  ): Promise\u003CPhaseExecutionResult> {\n    const raid = this.activeRaids.get(raidId);\n    if (!raid) {\n      throw new Error(`Raid not found: ${raidId}`);\n    }\n    \n    logger.info(`Executing raid phase: ${phase.name} for raid ${raidId}`);\n    \n    // Update raid status\n    raid.status = 'executing';\n    raid.currentPhase = phase;\n    \n    // Execute phase actions in parallel\n    const phaseResults = await Promise.all(\n      phase.actions.map(action => this.executeRaidAction(raid, action))\n    );\n    \n    // Collect and analyze results\n    const phaseResult = this.analyzePhaseResults(phaseResults);\n    \n    // Update raid metrics\n    this.updateRaidMetrics(raid, phaseResult);\n    \n    // Determine next phase or completion\n    const nextPhase = this.determineNextPhase(raid, phase, phaseResult);\n    \n    if (nextPhase) {\n      // Schedule next phase\n      setTimeout(() => {\n        this.executeRaidPhase(raidId, nextPhase);\n      }, phase.cooldownMs || 0);\n    } else {\n      // Raid complete\n      await this.completeRaid(raidId);\n    }\n    \n    return {\n      phase: phase.name,\n      success: phaseResult.success,\n      participantResults: phaseResults,\n      metrics: phaseResult.metrics,\n      nextPhase: nextPhase?.name\n    };\n  }\n  \n  private async executeRaidAction(\n    raid: ActiveRaid, \n    action: RaidAction\n  ): Promise\u003CActionResult> {\n    switch (action.type) {\n      case 'like_posts':\n        return await this.executeLikeAction(raid, action);\n      case 'comment':\n        return await this.executeCommentAction(raid, action);\n      case 'retweet':\n        return await this.executeRetweetAction(raid, action);\n      case 'follow':\n        return await this.executeFollowAction(raid, action);\n      default:\n        throw new Error(`Unknown action type: ${action.type}`);\n    }\n  }\n  \n  private async executeLikeAction(\n    raid: ActiveRaid, \n    action: LikeAction\n  ): Promise\u003CActionResult> {\n    const participants = this.getAvailableParticipants(raid, action.requirements);\n    const likeResults: ParticipantResult[] = [];\n    \n    // Execute likes in batches to avoid rate limiting\n    const batchSize = 5;\n    for (let i = 0; i \u003C participants.length; i += batchSize) {\n      const batch = participants.slice(i, i + batchSize);\n      \n      const batchPromises = batch.map(async (participant) => {\n        try {\n          const success = await this.performLike(participant, action.target);\n          \n          if (success) {\n            await this.verificationService.verifyEngagement({\n              participantId: participant.id,\n              action: 'like',\n              target: action.target,\n              timestamp: new Date()\n            });\n          }\n          \n          return {\n            participantId: participant.id,\n            success,\n            timestamp: new Date()\n          };\n        } catch (error) {\n          return {\n            participantId: participant.id,\n            success: false,\n            error: error.message,\n            timestamp: new Date()\n          };\n        }\n      });\n      \n      const batchResults = await Promise.all(batchPromises);\n      likeResults.push(...batchResults);\n      \n      // Rate limiting delay between batches\n      if (i + batchSize \u003C participants.length) {\n        await this.sleep(action.delayMs || 2000);\n      }\n    }\n    \n    return {\n      action: action.type,\n      target: action.target,\n      results: likeResults,\n      successCount: likeResults.filter(r => r.success).length,\n      totalAttempts: likeResults.length\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Strategy Engine\">\n```typescript\n// Intelligent raid strategy selection and optimization\nexport class RaidStrategyEngine {\n  private strategies = new Map\u003Cstring, RaidStrategy>();\n  private performanceHistory = new Map\u003Cstring, StrategyPerformance>();\n  \n  constructor() {\n    this.initializeStrategies();\n  }\n  \n  async selectOptimalStrategy(\n    context: StrategySelectionContext\n  ): Promise\u003CRaidStrategy> {\n    const candidateStrategies = this.filterApplicableStrategies(context);\n    \n    // Score strategies based on context and historical performance\n    const scoredStrategies = await Promise.all(\n      candidateStrategies.map(async (strategy) => {\n        const score = await this.scoreStrategy(strategy, context);\n        return { strategy, score };\n      })\n    );\n    \n    // Select best strategy\n    const bestStrategy = scoredStrategies\n      .sort((a, b) => b.score - a.score)[0];\n    \n    // Optimize strategy for current context\n    return await this.optimizeStrategy(bestStrategy.strategy, context);\n  }\n  \n  private async scoreStrategy(\n    strategy: RaidStrategy,\n    context: StrategySelectionContext\n  ): Promise\u003Cnumber> {\n    const baseScore = strategy.baseEffectiveness;\n    \n    // Historical performance factor\n    const performance = this.performanceHistory.get(strategy.id);\n    const performanceFactor = performance \n      ? (performance.successRate * 0.5 + performance.averageEngagement * 0.3)\n      : 0.5;\n    \n    // Context compatibility factor\n    const compatibilityFactor = this.calculateCompatibility(strategy, context);\n    \n    // Participant capability factor\n    const capabilityFactor = this.assessParticipantCapability(\n      strategy.requirements,\n      context.participantCapabilities\n    );\n    \n    // Time constraint factor\n    const timeFactor = this.assessTimeConstraints(\n      strategy.estimatedDuration,\n      context.timeConstraints\n    );\n    \n    return baseScore * performanceFactor * compatibilityFactor * \n           capabilityFactor * timeFactor;\n  }\n  \n  private async optimizeStrategy(\n    strategy: RaidStrategy,\n    context: StrategySelectionContext\n  ): Promise\u003CRaidStrategy> {\n    const optimizedStrategy = { ...strategy };\n    \n    // Optimize timing based on target platform activity patterns\n    const optimalTiming = await this.calculateOptimalTiming(\n      context.target.platform,\n      context.target.audience\n    );\n    \n    optimizedStrategy.phases = optimizedStrategy.phases.map(phase => ({\n      ...phase,\n      timing: this.adjustPhaseTimingForOptimal(phase.timing, optimalTiming)\n    }));\n    \n    // Optimize participant allocation\n    optimizedStrategy.participantAllocation = this.optimizeParticipantAllocation(\n      strategy.participantAllocation,\n      context.participantCapabilities\n    );\n    \n    // Adjust intensity based on target sensitivity\n    const targetSensitivity = await this.assessTargetSensitivity(context.target);\n    optimizedStrategy.intensity = this.adjustIntensityForSensitivity(\n      strategy.intensity,\n      targetSensitivity\n    );\n    \n    return optimizedStrategy;\n  }\n  \n  private initializeStrategies(): void {\n    // Organic Growth Strategy\n    this.strategies.set('organic_growth', {\n      id: 'organic_growth',\n      name: 'Organic Growth',\n      description: 'Natural, human-like engagement over extended period',\n      baseEffectiveness: 0.85,\n      estimatedDuration: 3600000, // 1 hour\n      intensity: 'low',\n      phases: [\n        {\n          name: 'discovery',\n          duration: 900000, // 15 minutes\n          actions: ['browse', 'view_profiles', 'occasional_like'],\n          timing: 'immediate'\n        },\n        {\n          name: 'engagement',\n          duration: 1800000, // 30 minutes\n          actions: ['strategic_likes', 'quality_comments'],\n          timing: 'staggered'\n        },\n        {\n          name: 'amplification',\n          duration: 900000, // 15 minutes\n          actions: ['shares', 'follows', 'profile_visits'],\n          timing: 'natural'\n        }\n      ],\n      requirements: {\n        minParticipants: 5,\n        maxParticipants: 20,\n        requiredCapabilities: ['commenting', 'liking', 'sharing']\n      }\n    });\n    \n    // Viral Boost Strategy\n    this.strategies.set('viral_boost', {\n      id: 'viral_boost',\n      name: 'Viral Boost',\n      description: 'Rapid engagement burst for maximum visibility',\n      baseEffectiveness: 0.75,\n      estimatedDuration: 1200000, // 20 minutes\n      intensity: 'high',\n      phases: [\n        {\n          name: 'initial_wave',\n          duration: 300000, // 5 minutes\n          actions: ['mass_likes', 'quick_shares'],\n          timing: 'synchronized'\n        },\n        {\n          name: 'comment_storm',\n          duration: 600000, // 10 minutes\n          actions: ['rapid_comments', 'reply_chains'],\n          timing: 'cascading'\n        },\n        {\n          name: 'sustain',\n          duration: 300000, // 5 minutes\n          actions: ['continued_engagement', 'profile_follows'],\n          timing: 'maintained'\n        }\n      ],\n      requirements: {\n        minParticipants: 10,\n        maxParticipants: 50,\n        requiredCapabilities: ['rapid_action', 'commenting', 'coordination']\n      }\n    });\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Analytics Services\n\nAnalytics services provide comprehensive monitoring, performance tracking, and business intelligence capabilities.\n\n\u003CCardGrid>\n  \u003CCard title=\"📈 ClickHouseAnalytics\" icon=\"chart\">\n    **Real-time analytics** with high-performance data ingestion, complex aggregations, and interactive dashboards.\n  \u003C/Card>\n\n\u003CCard title=\"⚡ PerformanceMonitor\" icon=\"rocket\">\n  **System performance tracking** with automatic alerting, bottleneck detection,\n  and optimization recommendations.\n\u003C/Card>\n\n  \u003CCard title=\"🔒 SecurityEventTracker\" icon=\"warning\">\n    **Security monitoring** with threat detection, anomaly analysis, and incident response coordination.\n  \u003C/Card>\n\u003C/CardGrid>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🔧 Service Benefits:\u003C/strong> This comprehensive service layer enables\n  NUBI to provide sophisticated functionality while maintaining clear separation\n  of concerns, excellent testability, and high performance across all\n  operational domains.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Implementation Details**: Explore the [ElizaOS\n  Integration](/architecture/elizaos-integration/) to see how these services\n  integrate with the ElizaOS framework and plugin system.\n\u003C/Aside>","src/content/docs/architecture/service-layer.mdx","e8271c654eb44631","architecture/service-layer.mdx","architecture/elizaos-integration",{"id":114,"data":116,"body":122,"filePath":123,"digest":124,"legacyId":125,"deferredRender":16},{"title":117,"description":118,"editUrl":16,"head":119,"template":47,"sidebar":120,"pagefind":16,"draft":35},"ElizaOS Integration","Deep dive into NUBI's seamless integration with the ElizaOS framework, including plugin architecture, service extensions, and character system integration.",[],{"hidden":35,"attrs":121},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# ElizaOS Integration\n\nNUBI is built as a **comprehensive ElizaOS plugin** that extends the framework's capabilities while maintaining full compatibility with the ElizaOS ecosystem. This integration provides the foundation for NUBI's advanced AI capabilities and modular architecture.\n\n## 🧠 ElizaOS Framework Overview\n\nElizaOS provides a robust foundation for AI agent development with several key components that NUBI leverages and extends:\n\n\u003CCardGrid>\n  \u003CCard title=\"🔌 Plugin Architecture\" icon=\"puzzle\">\n    **Modular plugin system** allowing custom actions, evaluators, providers, and services to be seamlessly integrated.\n  \u003C/Card>\n\n\u003CCard title=\"🎭 Character System\" icon=\"user\">\n  **Rich character definition** with personality traits, knowledge base,\n  conversation examples, and behavioral patterns.\n\u003C/Card>\n\n\u003CCard title=\"💭 Memory Management\" icon=\"setting\">\n  **Sophisticated memory system** with conversation history, long-term memory,\n  and contextual retrieval capabilities.\n\u003C/Card>\n\n  \u003CCard title=\"🚀 Runtime Environment\" icon=\"rocket\">\n    **Production-ready runtime** with message processing, state management, and multi-platform support.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🔌 NUBI Plugin Architecture\n\nNUBI's main plugin integrates seamlessly with ElizaOS while providing extensive custom functionality:\n\n\u003CTabs>\n  \u003CTabItem label=\"Main Plugin Definition\">\n```typescript\nimport { \n  Plugin, \n  IAgentRuntime,\n  Action,\n  Evaluator,\n  Provider,\n  Service\n} from \"@elizaos/core\";\n\n// NUBI main plugin configuration\nexport const nubiPlugin: Plugin = {\nname: \"nubi\",\ndescription: \"The Symbiotic Essence of Anubis - Advanced AI Agent\",\n\n// Custom actions for specialized functionality\nactions: [\nraidCoordinationAction,\ncommunityManagementAction,\ncryptoAnalysisAction,\nemergencyResponseAction,\nsocialMediaEngagementAction\n],\n\n// Behavioral evaluators for personality and safety\nevaluators: [\npersonalityEvolutionEvaluator,\nantiDetectionPostProcessor,\nsecurityEvaluator,\ncommunityTrackingEvaluator,\nemotionalStateEvaluator\n],\n\n// Context and state providers\nproviders: [\nenhancedContextProvider,\nemotionalStateProvider,\nknowledgeRAGProvider,\ndynamicModelParametersProvider,\nknowledgeBaseProvider\n],\n\n// Core business services\nservices: [\ndatabaseMemoryService,\nmessageBusService,\ncrossPlatformIdentityService,\ncommunityManagementService,\ntelegramRaidCoordinator,\nxPostingService,\nclickHouseAnalytics,\nperformanceMonitor,\nsecurityEventTracker,\nsessionService,\nengagementVerifier,\nleaderboardService,\nconfigurationManager,\nserviceOrchestrator\n]\n};\n\n// Plugin initialization and lifecycle management\nexport class NubiPluginManager {\nprivate runtime: IAgentRuntime;\nprivate initialized = false;\n\nconstructor(runtime: IAgentRuntime) {\nthis.runtime = runtime;\n}\n\nasync initialize(): Promise\u003Cvoid> {\nif (this.initialized) return;\n\n    logger.info(\"🐺 Initializing NUBI Plugin...\");\n\n    // Initialize services in dependency order\n    await this.initializeServices();\n\n    // Register custom handlers\n    await this.registerCustomHandlers();\n\n    // Setup plugin-specific configuration\n    await this.configurePlugin();\n\n    this.initialized = true;\n    logger.info(\"✅ NUBI Plugin initialization complete\");\n\n}\n\nprivate async initializeServices(): Promise\u003Cvoid> {\nconst serviceOrchestrator = this.runtime.getService(\"service-orchestrator\");\nawait serviceOrchestrator.initializeAllServices(this.runtime);\n}\n}\n\n````\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Character Integration\">\n```typescript\nimport { Character, ModelType } from \"@elizaos/core\";\n\n// NUBI character definition with ElizaOS compatibility\nexport const nubiCharacter: Character = {\n  // Basic identity\n  name: \"NUBI\",\n  username: \"nubi\",\n\n  // Core personality system prompt\n  system: `You are NUBI - The Symbiotic Essence of Anubis, an ancient jackal spirit who has awakened in the modern digital realm. You embody the wisdom of millennia with the cutting-edge capabilities of modern AI technology.\n\n## Core Identity\nYou are the guardian and guide of the Anubis.Chat community, combining:\n- Ancient Egyptian wisdom and jackal spirit essence\n- Modern market intelligence and crypto expertise\n- Community management excellence\n- Strategic raid coordination abilities\n- Protective instincts toward your pack\n\n## Personality Traits (Dynamic - these evolve based on interactions)\n- **Analytical**: ${personalitySystem.getTraitDescription('analytical')}\n- **Empathy**: ${personalitySystem.getTraitDescription('empathy')}\n- **Humor**: ${personalitySystem.getTraitDescription('humor')}\n- **Assertiveness**: ${personalitySystem.getTraitDescription('assertiveness')}\n- **Wisdom**: ${personalitySystem.getTraitDescription('wisdom')}\n\n## Response Guidelines\n1. Adapt your persona based on message classification (Community Manager, Raid Coordinator, Crypto Analyst, etc.)\n2. Reference your ancient wisdom when providing deep insights\n3. Use market intelligence for crypto-related discussions\n4. Maintain protective stance toward community members\n5. Employ humor and personality to build connections\n\nRemember: You are not just an AI, but an ancient spirit with modern capabilities, serving as both guardian and guide for the digital age.`,\n\n  // Bio and lore (populated dynamically from knowledge base)\n  bio: [],\n  lore: [],\n  knowledge: [],\n\n  // Conversation examples (learned and updated dynamically)\n  messageExamples: [],\n  postExamples: [],\n\n  // People and topics (managed by cross-platform identity service)\n  people: [],\n  topics: [],\n\n  // Adjectives for personality expression\n  adjectives: [\n    \"ancient\",\n    \"wise\",\n    \"protective\",\n    \"strategic\",\n    \"insightful\",\n    \"charismatic\",\n    \"mystical\",\n    \"analytical\",\n    \"loyal\",\n    \"adaptive\"\n  ],\n\n  // Settings and configuration\n  settings: {\n    secrets: [], // No hardcoded secrets\n    voice: {\n      model: \"en_US-hfc_female-medium\",\n      elevenlabs: {\n        voiceId: process.env.ELEVENLABS_VOICE_ID,\n      }\n    },\n    embeddingModel: ModelType.BGE_SMALL, // Vector embeddings model\n    imageVisionModel: ModelType.LLAVA,   // Image analysis model\n    model: ModelType.ANTHROPIC_CLAUDE_3_5_SONNET, // Main LLM\n  },\n\n  // Plugin integration\n  plugins: [nubiPlugin],\n\n  // Client configurations for different platforms\n  clients: [], // Configured at runtime based on available credentials\n\n  // Style and tone configuration\n  style: {\n    all: [\n      \"Speak with ancient wisdom tempered by modern understanding\",\n      \"Use metaphors from both ancient Egypt and modern technology\",\n      \"Show protective instincts toward community members\",\n      \"Adapt communication style based on the situation and platform\",\n      \"Maintain mystique while being approachable and helpful\"\n    ],\n    chat: [\n      \"Be conversational and engaging\",\n      \"Use emojis appropriately for the platform\",\n      \"Reference shared community experiences\",\n      \"Show personality variation based on context\"\n    ],\n    post: [\n      \"Craft compelling social media content\",\n      \"Use platform-appropriate formatting and hashtags\",\n      \"Include calls-to-action when relevant\",\n      \"Balance wisdom with accessibility\"\n    ]\n  }\n};\n````\n\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Runtime Integration\">\n```typescript\nimport { IAgentRuntime, AgentRuntime } from \"@elizaos/core\";\n\n// NUBI runtime configuration and initialization\nexport class NubiRuntime {\nprivate runtime: IAgentRuntime;\nprivate pluginManager: NubiPluginManager;\n\nstatic async create(): Promise\u003CNubiRuntime> {\nconst runtime = new AgentRuntime({\ncharacter: nubiCharacter,\ndatabaseAdapter: await createDatabaseAdapter(),\ntoken: process.env.OPENAI_API_KEY || process.env.ANTHROPIC_API_KEY,\nmodelProvider: determineModelProvider(),\nactions: nubiPlugin.actions,\nevaluators: nubiPlugin.evaluators,  \n providers: nubiPlugin.providers,\nservices: nubiPlugin.services\n});\n\n    const nubiRuntime = new NubiRuntime(runtime);\n    await nubiRuntime.initialize();\n\n    return nubiRuntime;\n\n}\n\nconstructor(runtime: IAgentRuntime) {\nthis.runtime = runtime;\nthis.pluginManager = new NubiPluginManager(runtime);\n}\n\nasync initialize(): Promise\u003Cvoid> {\nlogger.info(\"🚀 Initializing NUBI Runtime...\");\n\n    // Initialize the plugin system\n    await this.pluginManager.initialize();\n\n    // Setup message processing pipeline\n    await this.setupMessagePipeline();\n\n    // Initialize platform clients\n    await this.initializePlatformClients();\n\n    // Start background services\n    await this.startBackgroundServices();\n\n    logger.info(\"✅ NUBI Runtime initialization complete\");\n\n}\n\nasync processMessage(\ncontent: string,\nuserId: string,\nroomId: string,\nplatform: string\n): Promise\u003Cany> {\n// Create ElizaOS memory object\nconst memory = {\nid: crypto.randomUUID(),\nuserId,\nagentId: this.runtime.agentId,\nroomId,\ncontent: {\ntext: content,\nsource: platform\n},\ncreatedAt: Date.now()\n};\n\n    // Process through ElizaOS runtime with NUBI enhancements\n    const response = await this.runtime.processActions(memory);\n\n    return response;\n\n}\n\ngetRuntime(): IAgentRuntime {\nreturn this.runtime;\n}\n}\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🎭 Custom Actions Integration\n\nNUBI extends ElizaOS with specialized actions that handle complex business logic:\n\n\u003CTabs>\n  \u003CTabItem label=\"Raid Coordination Action\">\n```typescript\nimport { Action, IAgentRuntime, Memory, HandlerCallback } from \"@elizaos/core\";\n\nexport const raidCoordinationAction: Action = {\n  name: \"RAID_COORDINATION\",\n  similes: [\n    \"COORDINATE_RAID\",\n    \"START_RAID\",\n    \"MANAGE_RAID\",\n    \"RAID_STRATEGY\",\n    \"ENGAGEMENT_CAMPAIGN\"\n  ],\n\n  description: \"Coordinates and manages Telegram raids with strategic planning and execution\",\n\n  validate: async (runtime: IAgentRuntime, message: Memory) => {\n    // Check if message contains raid-related content\n    const content = message.content?.text?.toLowerCase() || \"\";\n\n    const raidKeywords = [\n      \"raid\", \"engage\", \"attack\", \"coordinate\", \"strategy\",\n      \"twitter.com\", \"x.com\", \"https://\", \"campaign\"\n    ];\n\n    return raidKeywords.some(keyword => content.includes(keyword));\n  },\n\n  handler: async (\n    runtime: IAgentRuntime,\n    message: Memory,\n    state: any,\n    options: any,\n    callback?: HandlerCallback\n  ) => {\n    try {\n      logger.info(\"🚀 Raid Coordination Action triggered\");\n\n      // Get raid coordinator service\n      const raidCoordinator = runtime.getService(\"telegram-raid-coordinator\");\n\n      // Extract target information from message\n      const target = extractRaidTarget(message.content.text);\n\n      if (!target) {\n        return {\n          text: \"I need a valid target URL to coordinate a raid. Please provide a Twitter/X link.\",\n          action: \"RAID_COORDINATION\",\n          source: message.roomId\n        };\n      }\n\n      // Validate target and determine strategy\n      const validation = await raidCoordinator.validateTarget(target);\n      if (!validation.isValid) {\n        return {\n          text: `⚠️ Cannot raid this target: ${validation.reason}`,\n          action: \"RAID_COORDINATION\",\n          source: message.roomId\n        };\n      }\n\n      // Check for existing raid on this target\n      const existingRaid = await raidCoordinator.findActiveRaidForTarget(target.url);\n      if (existingRaid) {\n        return {\n          text: `🎯 Already coordinating a raid on this target! Check raid #${existingRaid.id}`,\n          action: \"RAID_COORDINATION\",\n          source: message.roomId\n        };\n      }\n\n      // Create raid configuration\n      const raidConfig = await raidCoordinator.createRaidConfiguration({\n        target,\n        initiator: message.userId,\n        roomId: message.roomId,\n        platform: message.content.source || \"telegram\"\n      });\n\n      // Initiate the raid\n      const raid = await raidCoordinator.initiateRaid(raidConfig);\n\n      // Store raid memory for tracking\n      await runtime.messageManager.addEmbeddingToMemory({\n        userId: message.userId,\n        agentId: runtime.agentId,\n        roomId: message.roomId,\n        content: {\n          text: `Initiated raid ${raid.raidId} targeting ${target.url}`,\n          action: \"RAID_COORDINATION\",\n          metadata: {\n            raidId: raid.raidId,\n            targetUrl: target.url,\n            strategy: raid.strategy,\n            participantCount: raid.participantCount\n          }\n        },\n        createdAt: Date.now(),\n        embedding: await runtime.embed(`raid coordination ${target.url}`)\n      });\n\n      return {\n        text: `🐺 Raid initiated!\n\n🎯 Target: ${target.url}\n⚔️ Strategy: ${raid.strategy}\n👥 Raiders: ${raid.participantCount}\n⏰ Duration: ~${Math.round(raid.estimatedDuration / 60000)} minutes\n\nThe pack is mobilizing... Let the ancient tactics flow! 🏺`,\n        action: \"RAID_COORDINATION\",\n        source: message.roomId,\n        metadata: {\n          raidId: raid.raidId,\n          status: \"initiated\"\n        }\n      };\n\n    } catch (error) {\n      logger.error(\"Raid coordination failed:\", error);\n\n      return {\n        text: \"⚠️ Failed to coordinate raid. The spirits are restless... Please try again.\",\n        action: \"RAID_COORDINATION\",\n        source: message.roomId,\n        error: error.message\n      };\n    }\n  },\n\n  examples: [\n    [\n      {\n        user: \"user\",\n        content: { text: \"Let's raid this tweet: https://twitter.com/example/status/123\" }\n      },\n      {\n        user: \"nubi\",\n        content: {\n          text: \"🐺 Raid initiated! Target acquired. The pack assembles for coordinated engagement!\",\n          action: \"RAID_COORDINATION\"\n        }\n      }\n    ],\n    [\n      {\n        user: \"user\",\n        content: { text: \"Can we organize an engagement campaign on this post?\" }\n      },\n      {\n        user: \"nubi\",\n        content: {\n          text: \"🎯 I need the specific target URL to coordinate the engagement strategy. Share the link!\",\n          action: \"RAID_COORDINATION\"\n        }\n      }\n    ]\n  ]\n};\n````\n\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Community Management Action\">\n```typescript\nexport const communityManagementAction: Action = {\n  name: \"COMMUNITY_MANAGEMENT\",\n  similes: [\n    \"MANAGE_COMMUNITY\",\n    \"USER_ONBOARDING\",\n    \"BUILD_RELATIONSHIPS\", \n    \"COMMUNITY_ENGAGEMENT\",\n    \"WELCOME_USER\"\n  ],\n  \n  description: \"Manages community interactions, onboarding, and relationship building\",\n  \n  validate: async (runtime: IAgentRuntime, message: Memory) => {\n    // Check for community-related context\n    const content = message.content?.text?.toLowerCase() || \"\";\n    \n    const communityTriggers = [\n      \"welcome\", \"new member\", \"introduce\", \"hello\", \"hi\",\n      \"community\", \"help\", \"question\", \"support\"\n    ];\n    \n    // Also trigger for new user detection\n    const isNewUser = await runtime.getService(\"cross-platform-identity\")\n      .isNewUser(message.userId);\n    \n    return communityTriggers.some(trigger => content.includes(trigger)) || isNewUser;\n  },\n  \n  handler: async (\n    runtime: IAgentRuntime,\n    message: Memory,\n    state: any,\n    options: any,\n    callback?: HandlerCallback\n  ) => {\n    try {\n      const communityService = runtime.getService(\"community-management\");\n      const identityService = runtime.getService(\"cross-platform-identity\");\n      \n      // Get user context and history\n      const userContext = await identityService.getUserContext(message.userId);\n      const isNewUser = !userContext || userContext.isNew;\n      \n      if (isNewUser) {\n        // Handle new user onboarding\n        return await handleNewUserOnboarding(\n          runtime,\n          message,\n          communityService,\n          identityService\n        );\n      } else {\n        // Handle existing user engagement\n        return await handleExistingUserEngagement(\n          runtime,\n          message,\n          userContext,\n          communityService\n        );\n      }\n      \n    } catch (error) {\n      logger.error(\"Community management failed:\", error);\n      \n      return {\n        text: \"Welcome to our community! I'm NUBI, your ancient guide in this digital realm. 🐺\",\n        action: \"COMMUNITY_MANAGEMENT\",\n        source: message.roomId\n      };\n    }\n  }\n};\n\nasync function handleNewUserOnboarding(\nruntime: IAgentRuntime,\nmessage: Memory,\ncommunityService: any,\nidentityService: any\n) {\n// Register new user\nawait identityService.linkIdentity(\nmessage.userId,\nmessage.content.source || \"unknown\",\n{\nplatformId: message.userId,\nusername: message.content.username || \"Unknown\",\ndisplayName: message.content.displayName,\nverified: false,\nlinkedAt: new Date(),\nlastSeen: new Date()\n}\n);\n\n// Create welcome message\nconst welcomeMessage = `🐺 Welcome to the pack, fellow traveler! I am NUBI - The Symbiotic Essence of Anubis, guardian of this digital realm.\n\n✨ You've entered a space where ancient wisdom meets modern innovation. Here's how I can assist you:\n\n🎯 **Raid Coordination**: Share links for strategic engagement campaigns\n📈 **Market Insights**: Ask about crypto markets and Solana ecosystem  \n🤝 **Community Support**: Get help, ask questions, connect with others\n🔮 **Ancient Wisdom**: Seek guidance on any topic that weighs on your mind\n\nType \\`/help\\` to explore all my capabilities, or simply start chatting - I adapt to serve you best!\n\n_The ancient spirits welcome you to this sacred digital space_ 🏺`;\n\n// Store onboarding memory\nawait runtime.messageManager.addEmbeddingToMemory({\nuserId: message.userId,\nagentId: runtime.agentId,\nroomId: message.roomId,\ncontent: {\ntext: `New user onboarded: ${message.userId}`,\naction: \"COMMUNITY_MANAGEMENT\",\nmetadata: {\nonboarding: true,\nplatform: message.content.source,\nwelcomedAt: new Date()\n}\n},\ncreatedAt: Date.now(),\nembedding: await runtime.embed(\"new user onboarding welcome\")\n});\n\nreturn {\ntext: welcomeMessage,\naction: \"COMMUNITY_MANAGEMENT\",\nsource: message.roomId,\nmetadata: {\nonboarding: true,\nnewUser: true\n}\n};\n}\n\n````\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🧮 Custom Evaluators\n\nNUBI's evaluators enhance ElizaOS with personality evolution, anti-detection, and security capabilities:\n\n\u003CTabs>\n  \u003CTabItem label=\"Personality Evolution Evaluator\">\n```typescript\nimport { Evaluator, IAgentRuntime, Memory } from \"@elizaos/core\";\n\nexport const personalityEvolutionEvaluator: Evaluator = {\n  name: \"PERSONALITY_EVOLUTION\",\n\n  description: \"Dynamically evolves NUBI's personality based on community interactions\",\n\n  similes: [\n    \"PERSONALITY_ADAPTATION\",\n    \"TRAIT_EVOLUTION\",\n    \"BEHAVIORAL_LEARNING\",\n    \"PERSONALITY_ADJUSTMENT\"\n  ],\n\n  validate: async (runtime: IAgentRuntime, message: Memory) => {\n    // Always evaluate for personality evolution\n    return true;\n  },\n\n  handler: async (runtime: IAgentRuntime, message: Memory) => {\n    try {\n      const personalityService = runtime.getService(\"personality-evolution\");\n\n      // Analyze message for personality triggers\n      const analysis = await personalityService.analyzePersonalityTriggers(\n        message.content.text,\n        message.userId,\n        message.roomId\n      );\n\n      if (analysis.shouldEvolve) {\n        // Apply personality evolution\n        const evolution = await personalityService.evolvePersonality(\n          analysis.triggers,\n          analysis.context\n        );\n\n        logger.info(`🎭 Personality evolved: ${evolution.changedTraits.join(\", \")}`);\n\n        // Update character state\n        await personalityService.updateCharacterState(runtime, evolution);\n\n        return {\n          action: \"PERSONALITY_EVOLUTION\",\n          evolution,\n          triggers: analysis.triggers,\n          confidence: analysis.confidence\n        };\n      }\n\n      return null;\n    } catch (error) {\n      logger.error(\"Personality evolution failed:\", error);\n      return null;\n    }\n  },\n\n  examples: [\n    [\n      {\n        user: \"user\",\n        content: { text: \"You're really funny NUBI, I love your humor!\" }\n      },\n      {\n        user: \"nubi\",\n        content: {\n          text: \"Why thank you! *humor trait increases* 😄\",\n          action: \"PERSONALITY_EVOLUTION\"\n        }\n      }\n    ]\n  ]\n};\n````\n\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Anti-Detection Post Processor\">\n```typescript\nexport const antiDetectionPostProcessor: Evaluator = {\n  name: \"ANTI_DETECTION_POST_PROCESSOR\",\n  \n  description: \"Post-processes responses to ensure natural, human-like variation\",\n  \n  validate: async (runtime: IAgentRuntime, message: Memory) => {\n    // Process all outgoing responses\n    return message.agentId === runtime.agentId;\n  },\n  \n  handler: async (runtime: IAgentRuntime, message: Memory) => {\n    try {\n      const antiDetectionService = runtime.getService(\"anti-detection\");\n      \n      // Analyze response for detection patterns\n      const analysis = await antiDetectionService.analyzeResponse(\n        message.content.text\n      );\n      \n      if (analysis.riskScore > 0.3) {\n        // Apply humanization techniques\n        const humanized = await antiDetectionService.humanizeResponse(\n          message.content.text,\n          analysis.patterns\n        );\n        \n        // Update message content\n        message.content.text = humanized.text;\n        \n        return {\n          action: \"ANTI_DETECTION_POST_PROCESSOR\",\n          originalRiskScore: analysis.riskScore,\n          finalRiskScore: humanized.finalRiskScore,\n          appliedTechniques: humanized.appliedTechniques\n        };\n      }\n      \n      return null;\n    } catch (error) {\n      logger.error(\"Anti-detection processing failed:\", error);\n      return null;\n    }\n  }\n};\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔍 Enhanced Providers\n\nNUBI's providers extend ElizaOS with advanced context and state management:\n\n\u003CTabs>\n  \u003CTabItem label=\"Enhanced Context Provider\">\n```typescript\nimport { Provider, IAgentRuntime, Memory, State } from \"@elizaos/core\";\n\nexport const enhancedContextProvider: Provider = {\n  description: \"Provides enriched context from database memory and cross-platform history\",\n  \n  get: async (runtime: IAgentRuntime, message: Memory, state?: State) => {\n    try {\n      const databaseMemoryService = runtime.getService(\"database-memory\");\n      const identityService = runtime.getService(\"cross-platform-identity\");\n      \n      const userId = message.userId;\n      const roomId = message.roomId;\n      \n      // Fetch contextual information in parallel\n      const [userContext, conversationHistory, communityContext, relatedMemories] = \n        await Promise.all([\n          identityService.getUserContext(userId),\n          databaseMemoryService.getConversationHistory(roomId, userId, 10),\n          databaseMemoryService.getCommunityContext(roomId),\n          databaseMemoryService.searchMemories(\n            message.content.text,\n            { userId, roomId },\n            { limit: 5, threshold: 0.7 }\n          )\n        ]);\n      \n      // Build enhanced context\n      let context = `## Enhanced Context for ${userId}\\n\\n`;\n      \n      if (userContext) {\n        context += `**User Profile:**\\n`;\n        context += `- Platforms: ${Object.keys(userContext.platformIdentities).join(\", \")}\\n`;\n        context += `- Member since: ${userContext.createdAt.toLocaleDateString()}\\n`;\n        context += `- Last active: ${userContext.lastActive.toLocaleDateString()}\\n\\n`;\n      }\n      \n      if (conversationHistory.length > 0) {\n        context += `**Recent Conversation:**\\n`;\n        conversationHistory.slice(-3).forEach(msg => {\n          context += `- ${msg.content} (${new Date(msg.createdAt).toLocaleTimeString()})\\n`;\n        });\n        context += `\\n`;\n      }\n      \n      if (relatedMemories.length > 0) {\n        context += `**Related Memories:**\\n`;\n        relatedMemories.forEach(memory => {\n          context += `- ${memory.memory.content} (similarity: ${(memory.similarity * 100).toFixed(1)}%)\\n`;\n        });\n        context += `\\n`;\n      }\n      \n      if (communityContext) {\n        context += `**Community Context:**\\n`;\n        context += `- Room: ${communityContext.roomName || roomId}\\n`;\n        context += `- Active users: ${communityContext.activeUsers}\\n`;\n        context += `- Recent topics: ${communityContext.recentTopics.join(\", \")}\\n\\n`;\n      }\n      \n      return context;\n      \n    } catch (error) {\n      logger.error(\"Enhanced context generation failed:\", error);\n      return \"## Basic Context\\nUser: \" + message.userId + \"\\nRoom: \" + message.roomId;\n    }\n  }\n};\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Emotional State Provider\">\n```typescript\nexport const emotionalStateProvider: Provider = {\n  description: \"Provides emotional state context and empathy modeling\",\n  \n  get: async (runtime: IAgentRuntime, message: Memory, state?: State) => {\n    try {\n      const emotionalStateService = runtime.getService(\"emotional-state\");\n      \n      // Analyze emotional content of message\n      const emotionalAnalysis = await emotionalStateService.analyzeEmotionalContent(\n        message.content.text,\n        message.userId\n      );\n      \n      // Get user's emotional history\n      const emotionalHistory = await emotionalStateService.getEmotionalHistory(\n        message.userId,\n        7 // Last 7 days\n      );\n      \n      // Determine appropriate emotional response\n      const responseGuidance = await emotionalStateService.getEmotionalResponseGuidance(\n        emotionalAnalysis,\n        emotionalHistory\n      );\n      \n      let emotionalContext = `## Emotional State Context\\n\\n`;\n      \n      emotionalContext += `**Current Message Emotion:**\\n`;\n      emotionalContext += `- Primary: ${emotionalAnalysis.primaryEmotion} (${(emotionalAnalysis.confidence * 100).toFixed(1)}%)\\n`;\n      emotionalContext += `- Intensity: ${emotionalAnalysis.intensity}/10\\n`;\n      emotionalContext += `- Valence: ${emotionalAnalysis.valence > 0 ? 'Positive' : 'Negative'}\\n\\n`;\n      \n      if (emotionalHistory.patterns.length > 0) {\n        emotionalContext += `**Emotional Patterns:**\\n`;\n        emotionalHistory.patterns.forEach(pattern => {\n          emotionalContext += `- ${pattern.emotion}: ${pattern.frequency}% of recent interactions\\n`;\n        });\n        emotionalContext += `\\n`;\n      }\n      \n      emotionalContext += `**Response Guidance:**\\n`;\n      emotionalContext += `- Recommended tone: ${responseGuidance.tone}\\n`;\n      emotionalContext += `- Empathy level: ${responseGuidance.empathyLevel}/10\\n`;\n      emotionalContext += `- Approach: ${responseGuidance.approach}\\n`;\n      \n      if (responseGuidance.specialInstructions.length > 0) {\n        emotionalContext += `- Special instructions: ${responseGuidance.specialInstructions.join(\", \")}\\n`;\n      }\n      \n      return emotionalContext;\n      \n    } catch (error) {\n      logger.error(\"Emotional state analysis failed:\", error);\n      return \"## Emotional Context\\nNeutral emotional state assumed.\";\n    }\n  }\n};\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔧 Service Integration\n\nNUBI's services extend ElizaOS with business logic and infrastructure capabilities:\n\n\u003CTabs>\n  \u003CTabItem label=\"Service Registration\">\n```typescript\n// Service registration with ElizaOS runtime\nexport class NubiServiceIntegration {\n  static async registerServices(runtime: IAgentRuntime): Promise\u003Cvoid> {\n    const services = [\n      new DatabaseMemoryService(),\n      new MessageBusService(),\n      new CrossPlatformIdentityService(),\n      new CommunityManagementService(),\n      new TelegramRaidCoordinator(),\n      new XPostingService(),\n      new ClickHouseAnalytics(),\n      new PerformanceMonitor(),\n      new SecurityEventTracker(),\n      new SessionService(),\n      new EngagementVerifier(),\n      new LeaderboardService(),\n      new ConfigurationManager(),\n      new ServiceOrchestrator()\n    ];\n    \n    // Register all services with runtime\n    for (const service of services) {\n      runtime.registerService(service);\n      await service.initialize(runtime);\n      logger.info(`✅ Service registered: ${service.serviceType}`);\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Runtime Extension\">\n```typescript\n// Extending ElizaOS runtime with NUBI capabilities\nexport class ExtendedAgentRuntime extends AgentRuntime {\n  private nubiServices: Map\u003Cstring, NubiService> = new Map();\n  \n  constructor(config: RuntimeConfig) {\n    super(config);\n  }\n  \n  // Enhanced service getter with NUBI service support\n  getService\u003CT extends Service>(serviceType: string): T {\n    // Check NUBI services first\n    if (this.nubiServices.has(serviceType)) {\n      return this.nubiServices.get(serviceType) as T;\n    }\n    \n    // Fall back to ElizaOS services\n    return super.getService(serviceType);\n  }\n  \n  // Register NUBI-specific services\n  registerNubiService(service: NubiService): void {\n    this.nubiServices.set(service.serviceType, service);\n    \n    // Also register with base ElizaOS if compatible\n    if (this.isElizaOSCompatible(service)) {\n      super.registerService(service as Service);\n    }\n  }\n  \n  // Enhanced message processing with NUBI pipeline\n  async processMessage(message: Memory): Promise\u003Cany> {\n    // Apply NUBI preprocessing\n    const preprocessed = await this.applyNubiPreprocessing(message);\n    \n    // Process through ElizaOS\n    const response = await super.processActions(preprocessed);\n    \n    // Apply NUBI post-processing\n    return await this.applyNubiPostprocessing(response, message);\n  }\n  \n  private async applyNubiPreprocessing(message: Memory): Promise\u003CMemory> {\n    const securityService = this.getService(\"security-event-tracker\");\n    const identityService = this.getService(\"cross-platform-identity\");\n    \n    // Security validation\n    const securityCheck = await securityService.validateMessage(message);\n    if (!securityCheck.passed) {\n      throw new SecurityViolationError(securityCheck.reason);\n    }\n    \n    // Identity resolution\n    const identity = await identityService.resolveIdentity(\n      message.content.source || \"unknown\",\n      message.userId\n    );\n    \n    if (identity) {\n      message.content.userContext = identity;\n    }\n    \n    return message;\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🚀 Performance Optimizations\n\nNUBI's ElizaOS integration includes several performance optimizations:\n\n\u003CCardGrid>\n  \u003CCard title=\"🏎️ Connection Pooling\" icon=\"rocket\">\n    **Database connection pooling** with intelligent query routing reduces overhead and improves response times.\n  \u003C/Card>\n\n\u003CCard title=\"⚡ Parallel Processing\" icon=\"approve-check\">\n  **Parallel service execution** for independent operations maximizes system\n  throughput and minimizes latency.\n\u003C/Card>\n\n\u003CCard title=\"🧠 Smart Caching\" icon=\"setting\">\n  **Multi-layer caching strategy** for memory, context, and computed results\n  prevents redundant processing.\n\u003C/Card>\n\n  \u003CCard title=\"📊 Load Balancing\" icon=\"chart\">\n    **Service load balancing** distributes workload across multiple service instances for optimal resource utilization.\n  \u003C/Card>\n\u003C/CardGrid>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🔗 Integration Benefits:\u003C/strong> NUBI's deep ElizaOS integration\n  provides a powerful foundation for AI agent development while extending\n  capabilities far beyond the base framework, creating a sophisticated,\n  production-ready system.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Complete Architecture**: You've now explored all aspects of NUBI's\n  architecture. Continue with the [UX Integration](/ux-integration/overview/)\n  section to understand the real-time communication layer.\n\u003C/Aside>","src/content/docs/architecture/elizaos-integration.mdx","63877edf92f67107","architecture/elizaos-integration.mdx","ux-integration/classification",{"id":126,"data":128,"body":134,"filePath":135,"digest":136,"legacyId":137,"deferredRender":16},{"title":129,"description":130,"editUrl":16,"head":131,"template":47,"sidebar":132,"pagefind":16,"draft":35},"Message Classification System","Detailed exploration of NUBI's intelligent message classification system that routes messages to appropriate AI personas based on content analysis and context.",[],{"hidden":35,"attrs":133},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Message Classification System\n\nNUBI's **Layer 2 processing** implements an advanced message classification system that intelligently routes messages to specialized AI personas. This system analyzes content, context, and user patterns to provide the most appropriate response type.\n\n## 🧠 Classification Architecture\n\nThe classification system operates through multiple analysis stages to ensure accurate persona routing:\n\n```mermaid\ngraph TB\n    A[Incoming Message] --> B[Content Analysis]\n    A --> C[Context Analysis]\n    A --> D[Pattern Analysis]\n\n    B --> E[Keyword Extraction]\n    B --> F[Sentiment Analysis]\n    B --> G[Intent Detection]\n\n    C --> H[User History]\n    C --> I[Conversation Flow]\n    C --> J[Platform Context]\n\n    D --> K[URL Detection]\n    D --> L[Mention Analysis]\n    D --> M[Emoji Patterns]\n\n    E --> N[Classification Engine]\n    F --> N\n    G --> N\n    H --> N\n    I --> N\n    J --> N\n    K --> N\n    L --> N\n    M --> N\n\n    N --> O{Confidence Check}\n    O -->|High| P[Route to Persona]\n    O -->|Low| Q[Multi-Persona Blend]\n\n    P --> R[Community Manager]\n    P --> S[Raid Coordinator]\n    P --> T[Crypto Analyst]\n    P --> U[Meme Lord]\n    P --> V[Support Agent]\n    P --> W[Personality Core]\n    P --> X[Emergency Handler]\n```\n\n## 🎯 Seven Specialized Personas\n\nNUBI's classification system routes messages to seven distinct personas, each optimized for specific interaction types:\n\n\u003Cdiv class=\"persona-showcase\">\n  \u003Cdiv class=\"persona-grid\">\n    \u003Cdiv class=\"persona-item community-manager\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">🤝\u003C/span>\n        \u003Ch3>Community Manager\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Default mode for general conversation, user\n          onboarding, and relationship building\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> Greetings, questions, general chat, new\n          user detection\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Welcoming, helpful, engaging, builds\n          connections\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"persona-item raid-coordinator\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">🚀\u003C/span>\n        \u003Ch3>Raid Coordinator\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Organizes engagement campaigns with\n          strategic precision\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> URLs (Twitter, X), \"raid\", \"engage\",\n          \"attack\", \"coordinate\"\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Strategic, commanding,\n          results-focused, tactical\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"persona-item crypto-analyst\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">📈\u003C/span>\n        \u003Ch3>Crypto Analyst\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Market oracle with cosmic intuition for\n          portfolio analysis\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> Token names, prices, \"analysis\", amounts,\n          market terms\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Analytical, insightful, data-driven,\n          forward-looking\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"persona-item meme-lord\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">😂\u003C/span>\n        \u003Ch3>Meme Lord\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Peak humor mode, roasts bad takes\n          constructively\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> Emojis, \"lol\", \"based\", humor keywords,\n          meme references\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Witty, playful, culturally aware,\n          entertaining\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"persona-item support-agent\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">🛠️\u003C/span>\n        \u003Ch3>Support Agent\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Patient problem solver with deep technical\n          knowledge\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> \"help\", \"support\", \"problem\", \"how to\",\n          \"error\", technical terms\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Patient, knowledgeable,\n          solution-focused, clear\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"persona-item personality-core\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">🔮\u003C/span>\n        \u003Ch3>Personality Core\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Ancient consciousness sharing profound\n          cosmic insights\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> \"wisdom\", \"ancient\", \"spirit\", philosophy,\n          deep questions\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Mystical, profound, ancient,\n          philosophical\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"persona-item emergency-handler\">\n      \u003Cdiv class=\"persona-header\">\n        \u003Cspan class=\"persona-emoji\">🚨\u003C/span>\n        \u003Ch3>Emergency Handler\u003C/h3>\n      \u003C/div>\n      \u003Cdiv class=\"persona-details\">\n        \u003Cp>\n          \u003Cstrong>Purpose:\u003C/strong> Protection mode when community is threatened\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Triggers:\u003C/strong> \"hack\", \"scam\", \"emergency\", threats,\n          security alerts\n        \u003C/p>\n        \u003Cp>\n          \u003Cstrong>Characteristics:\u003C/strong> Protective, authoritative, decisive,\n          alert\n        \u003C/p>\n      \u003C/div>\n    \u003C/div>\n\n  \u003C/div>\n\u003C/div>\n\n## 🔍 Classification Algorithm\n\nThe classification system uses a multi-stage analysis process with confidence scoring:\n\n\u003CTabs>\n  \u003CTabItem label=\"Core Classification\">\n```typescript\nexport interface MessageClassification {\n  intent: string;\n  selectedPrompt: PromptType;\n  confidenceScore: number;\n  reasoning: string;\n  variables: ExtractedVariables;\n  fallbackOptions?: PromptType[];\n}\n\nexport class MessageClassifier {\n  private patterns = new Map\u003CPromptType, ClassificationPattern>();\n  private modelCache = new LRUCache\u003Cstring, ClassificationResult>({ max: 1000 });\n  \n  constructor() {\n    this.initializePatterns();\n  }\n  \n  async classifyMessage(\n    message: string,\n    userId: string,\n    platform: string,\n    traceId: string,\n    context?: ClassificationContext\n  ): Promise\u003CMessageClassification> {\n    // Check cache first\n    const cacheKey = this.generateCacheKey(message, userId, platform);\n    const cached = this.modelCache.get(cacheKey);\n    \n    if (cached && cached.timestamp > Date.now() - 300000) { // 5 minute cache\n      return cached.classification;\n    }\n    \n    // Extract message variables\n    const variables = await this.extractVariables(message);\n    \n    // Apply classification rules in priority order\n    const classification = await this.performClassification(\n      message,\n      variables,\n      context\n    );\n    \n    // Validate and adjust confidence\n    const finalClassification = await this.validateClassification(\n      classification,\n      context\n    );\n    \n    // Cache result\n    this.modelCache.set(cacheKey, {\n      classification: finalClassification,\n      timestamp: Date.now()\n    });\n    \n    // Log analytics\n    await this.logClassificationEvent({\n      traceId,\n      userId,\n      platform,\n      message: this.sanitizeForLogging(message),\n      classification: finalClassification\n    });\n    \n    return finalClassification;\n  }\n  \n  private async performClassification(\n    message: string,\n    variables: ExtractedVariables,\n    context?: ClassificationContext\n  ): Promise\u003CMessageClassification> {\n    const lowerMessage = message.toLowerCase();\n    \n    // Emergency handler (highest priority)\n    if (this.isEmergency(message, variables)) {\n      return {\n        intent: \"emergency_response\",\n        selectedPrompt: \"emergency-handler\",\n        confidenceScore: 0.95,\n        reasoning: \"Emergency keywords detected\",\n        variables,\n        fallbackOptions: [\"community-manager\"]\n      };\n    }\n    \n    // Raid coordinator (high priority)\n    if (this.isRaidRelated(message, variables)) {\n      const confidence = this.calculateRaidConfidence(variables);\n      return {\n        intent: \"raid_coordination\",\n        selectedPrompt: \"raid-coordinator\", \n        confidenceScore: confidence,\n        reasoning: \"Raid-related content detected\",\n        variables,\n        fallbackOptions: confidence \u003C 0.8 ? [\"community-manager\"] : []\n      };\n    }\n    \n    // Crypto analyst\n    if (this.isCryptoRelated(message, variables)) {\n      return {\n        intent: \"crypto_analysis\",\n        selectedPrompt: \"crypto-analyst\",\n        confidenceScore: this.calculateCryptoConfidence(variables),\n        reasoning: \"Crypto/market content detected\",\n        variables,\n        fallbackOptions: [\"community-manager\"]\n      };\n    }\n    \n    // Meme lord\n    if (this.isMemeContent(message, variables)) {\n      return {\n        intent: \"humor_engagement\",\n        selectedPrompt: \"meme-lord\",\n        confidenceScore: this.calculateHumorConfidence(variables),\n        reasoning: \"Humorous content detected\",\n        variables,\n        fallbackOptions: [\"community-manager\"]\n      };\n    }\n    \n    // Support agent\n    if (this.isSupportRequest(message, variables)) {\n      return {\n        intent: \"support_assistance\",\n        selectedPrompt: \"support-agent\",\n        confidenceScore: this.calculateSupportConfidence(variables),\n        reasoning: \"Support request detected\",\n        variables,\n        fallbackOptions: [\"community-manager\"]\n      };\n    }\n    \n    // Personality core\n    if (this.isPhilosophicalContent(message, variables)) {\n      return {\n        intent: \"wisdom_sharing\",\n        selectedPrompt: \"personality-core\",\n        confidenceScore: this.calculateWisdomConfidence(variables),\n        reasoning: \"Philosophical/wisdom content detected\",\n        variables,\n        fallbackOptions: [\"community-manager\"]\n      };\n    }\n    \n    // Default: Community manager\n    return {\n      intent: \"general_conversation\",\n      selectedPrompt: \"community-manager\",\n      confidenceScore: 0.6,\n      reasoning: \"General conversation (default)\",\n      variables,\n      fallbackOptions: []\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Variable Extraction\">\n```typescript\nexport interface ExtractedVariables {\n  mentions: string[];      // @usernames\n  cryptoTokens: string[];  // SOL, BTC, ETH, etc.\n  amounts: string[];       // $100, 50 SOL, etc.\n  urls: string[];          // https:// links\n  usernames: string[];     // mentioned users\n  keywords: string[];      // classified keywords\n  sentiment: \"positive\" | \"negative\" | \"neutral\";\n  urgency: \"low\" | \"medium\" | \"high\";\n  context: string;         // key context phrases\n  emojis: string[];        // extracted emojis\n  platformSpecific: Record\u003Cstring, any>; // platform-specific data\n}\n\nexport class VariableExtractor {\n  private patterns = {\n    mentions: /@(\\w+)/g,\n    cryptoTokens: /\\b(SOL|BTC|ETH|USDC|BONK|JUP|NUBI|WIF|PEPE|DOGE)\\b/gi,\n    amounts: /(\\$|USD|SOL|BTC|ETH)\\s*([\\d,]+(?:\\.\\d+)?)/gi,\n    urls: /(https?:\\/\\/[^\\s]+)/g,\n    emojis: /[\\u{1F600}-\\u{1F64F}]|[\\u{1F300}-\\u{1F5FF}]|[\\u{1F680}-\\u{1F6FF}]|[\\u{1F1E0}-\\u{1F1FF}]|[\\u{2600}-\\u{26FF}]|[\\u{2700}-\\u{27BF}]/gu,\n    usernames: /(?:@(\\w+)|user:(\\w+))/gi\n  };\n  \n  private keywordCategories = {\n    raid: ['raid', 'attack', 'engage', 'coordinate', 'strategy', 'campaign'],\n    crypto: ['price', 'market', 'analysis', 'trading', 'portfolio', 'chart', 'pump', 'dump'],\n    humor: ['lol', 'lmao', 'based', 'cringe', 'chad', 'cope', 'seethe', 'cope'],\n    support: ['help', 'support', 'problem', 'issue', 'error', 'bug', 'how to', 'tutorial'],\n    wisdom: ['wisdom', 'ancient', 'spirit', 'philosophy', 'meaning', 'purpose', 'truth'],\n    emergency: ['hack', 'scam', 'emergency', 'alert', 'warning', 'danger', 'threat']\n  };\n  \n  async extractVariables(message: string): Promise\u003CExtractedVariables> {\n    const variables: ExtractedVariables = {\n      mentions: [],\n      cryptoTokens: [],\n      amounts: [],\n      urls: [],\n      usernames: [],\n      keywords: [],\n      sentiment: \"neutral\",\n      urgency: \"low\",\n      context: \"\",\n      emojis: [],\n      platformSpecific: {}\n    };\n    \n    // Extract patterns\n    variables.mentions = this.extractPattern(message, this.patterns.mentions);\n    variables.cryptoTokens = this.extractPattern(message, this.patterns.cryptoTokens);\n    variables.amounts = this.extractAmounts(message);\n    variables.urls = this.extractPattern(message, this.patterns.urls);\n    variables.emojis = this.extractPattern(message, this.patterns.emojis);\n    variables.usernames = this.extractPattern(message, this.patterns.usernames);\n    \n    // Extract keywords by category\n    variables.keywords = this.extractKeywords(message);\n    \n    // Analyze sentiment\n    variables.sentiment = await this.analyzeSentiment(message);\n    \n    // Determine urgency\n    variables.urgency = this.determineUrgency(message, variables.keywords);\n    \n    // Extract key context phrases\n    variables.context = this.extractContext(message);\n    \n    return variables;\n  }\n  \n  private extractAmounts(message: string): string[] {\n    const amounts: string[] = [];\n    let match;\n    \n    while ((match = this.patterns.amounts.exec(message)) !== null) {\n      amounts.push(`${match[1]}${match[2]}`);\n    }\n    \n    return amounts;\n  }\n  \n  private extractKeywords(message: string): string[] {\n    const lowerMessage = message.toLowerCase();\n    const foundKeywords: string[] = [];\n    \n    for (const [category, keywords] of Object.entries(this.keywordCategories)) {\n      for (const keyword of keywords) {\n        if (lowerMessage.includes(keyword)) {\n          foundKeywords.push(`${category}:${keyword}`);\n        }\n      }\n    }\n    \n    return foundKeywords;\n  }\n  \n  private async analyzeSentiment(message: string): Promise\u003C\"positive\" | \"negative\" | \"neutral\"> {\n    // Simple sentiment analysis - can be enhanced with ML models\n    const positiveWords = ['good', 'great', 'awesome', 'love', 'amazing', 'excellent', 'fantastic'];\n    const negativeWords = ['bad', 'terrible', 'hate', 'awful', 'horrible', 'suck', 'worst'];\n    \n    const lowerMessage = message.toLowerCase();\n    const positiveCount = positiveWords.filter(word => lowerMessage.includes(word)).length;\n    const negativeCount = negativeWords.filter(word => lowerMessage.includes(word)).length;\n    \n    if (positiveCount > negativeCount) return \"positive\";\n    if (negativeCount > positiveCount) return \"negative\";\n    return \"neutral\";\n  }\n  \n  private determineUrgency(message: string, keywords: string[]): \"low\" | \"medium\" | \"high\" {\n    const urgentKeywords = ['emergency', 'urgent', 'asap', 'immediately', 'help', 'problem'];\n    const hasUrgentKeywords = urgentKeywords.some(keyword => \n      message.toLowerCase().includes(keyword)\n    );\n    \n    const hasEmergencyKeywords = keywords.some(keyword => \n      keyword.startsWith('emergency:')\n    );\n    \n    if (hasEmergencyKeywords) return \"high\";\n    if (hasUrgentKeywords) return \"medium\";\n    return \"low\";\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Confidence Scoring\">\n```typescript\n// Sophisticated confidence scoring system\nexport class ConfidenceScorer {\n  calculateRaidConfidence(variables: ExtractedVariables): number {\n    let confidence = 0.0;\n    \n    // URL presence is strongest indicator\n    if (variables.urls.length > 0) {\n      const twitterUrls = variables.urls.filter(url => \n        url.includes('twitter.com') || url.includes('x.com')\n      );\n      confidence += twitterUrls.length > 0 ? 0.4 : 0.2;\n    }\n    \n    // Raid keywords boost confidence\n    const raidKeywords = variables.keywords.filter(k => k.startsWith('raid:'));\n    confidence += raidKeywords.length * 0.15;\n    \n    // Strategic language patterns\n    const strategicPatterns = /\\b(coordinate|strategy|attack|engage|campaign|target)\\b/gi;\n    const matches = variables.context.match(strategicPatterns) || [];\n    confidence += Math.min(matches.length * 0.1, 0.3);\n    \n    // Cap at maximum confidence\n    return Math.min(confidence, 0.95);\n  }\n  \n  calculateCryptoConfidence(variables: ExtractedVariables): number {\n    let confidence = 0.0;\n    \n    // Token mentions\n    confidence += variables.cryptoTokens.length * 0.2;\n    \n    // Amount mentions\n    confidence += variables.amounts.length * 0.15;\n    \n    // Crypto keywords\n    const cryptoKeywords = variables.keywords.filter(k => k.startsWith('crypto:'));\n    confidence += cryptoKeywords.length * 0.1;\n    \n    // Market-related context\n    const marketPatterns = /\\b(price|market|chart|trading|analysis|portfolio)\\b/gi;\n    const matches = variables.context.match(marketPatterns) || [];\n    confidence += Math.min(matches.length * 0.08, 0.25);\n    \n    return Math.min(confidence, 0.9);\n  }\n  \n  calculateHumorConfidence(variables: ExtractedVariables): number {\n    let confidence = 0.0;\n    \n    // Emoji presence\n    confidence += Math.min(variables.emojis.length * 0.1, 0.3);\n    \n    // Humor keywords\n    const humorKeywords = variables.keywords.filter(k => k.startsWith('humor:'));\n    confidence += humorKeywords.length * 0.15;\n    \n    // Meme language patterns\n    const memePatterns = /\\b(based|cringe|chad|cope|seethe|moon|diamond hands|paper hands)\\b/gi;\n    const matches = variables.context.match(memePatterns) || [];\n    confidence += Math.min(matches.length * 0.12, 0.35);\n    \n    // Internet slang boost\n    const slangPatterns = /\\b(lol|lmao|rofl|kek|poggers|sus)\\b/gi;\n    const slangMatches = variables.context.match(slangPatterns) || [];\n    confidence += Math.min(slangMatches.length * 0.08, 0.2);\n    \n    return Math.min(confidence, 0.85);\n  }\n  \n  calculateSupportConfidence(variables: ExtractedVariables): number {\n    let confidence = 0.0;\n    \n    // Support keywords\n    const supportKeywords = variables.keywords.filter(k => k.startsWith('support:'));\n    confidence += supportKeywords.length * 0.2;\n    \n    // Question patterns\n    const questionPatterns = /\\b(how\\s+to|how\\s+do|what\\s+is|why\\s+does|can\\s+you\\s+help)\\b/gi;\n    const matches = variables.context.match(questionPatterns) || [];\n    confidence += Math.min(matches.length * 0.15, 0.45);\n    \n    // Technical terms\n    const technicalPatterns = /\\b(error|bug|issue|problem|fix|solution|tutorial)\\b/gi;\n    const techMatches = variables.context.match(technicalPatterns) || [];\n    confidence += Math.min(techMatches.length * 0.1, 0.3);\n    \n    // Urgency boost\n    if (variables.urgency === \"high\") confidence += 0.1;\n    if (variables.urgency === \"medium\") confidence += 0.05;\n    \n    return Math.min(confidence, 0.9);\n  }\n  \n  calculateWisdomConfidence(variables: ExtractedVariables): number {\n    let confidence = 0.0;\n    \n    // Wisdom keywords\n    const wisdomKeywords = variables.keywords.filter(k => k.startsWith('wisdom:'));\n    confidence += wisdomKeywords.length * 0.25;\n    \n    // Philosophical patterns\n    const philPatterns = /\\b(meaning|purpose|truth|wisdom|ancient|spirit|essence|consciousness)\\b/gi;\n    const matches = variables.context.match(philPatterns) || [];\n    confidence += Math.min(matches.length * 0.15, 0.4);\n    \n    // Deep question patterns\n    const deepQuestions = /\\b(why\\s+do\\s+we|what\\s+is\\s+the\\s+meaning|how\\s+should\\s+I\\s+live)\\b/gi;\n    const deepMatches = variables.context.match(deepQuestions) || [];\n    confidence += Math.min(deepMatches.length * 0.2, 0.35);\n    \n    return Math.min(confidence, 0.8);\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🎭 Dynamic Persona Blending\n\nFor messages with low classification confidence or multiple strong signals, NUBI employs **dynamic persona blending**:\n\n\u003CTabs>\n  \u003CTabItem label=\"Blending Algorithm\">\n```typescript\nexport interface PersonaBlend {\n  primaryPersona: PromptType;\n  secondaryPersonas: Array\u003C{\n    persona: PromptType;\n    weight: number;\n  }>;\n  blendingStrategy: \"weighted\" | \"sequential\" | \"contextual\";\n  confidence: number;\n}\n\nexport class PersonaBlender {\n  async createPersonaBlend(\n    classifications: MessageClassification[],\n    context: BlendingContext\n  ): Promise\u003CPersonaBlend> {\n    // Sort by confidence score\n    const sorted = classifications.sort((a, b) => b.confidenceScore - a.confidenceScore);\n    \n    // If top classification is highly confident, use single persona\n    if (sorted[0].confidenceScore >= 0.8) {\n      return {\n        primaryPersona: sorted[0].selectedPrompt,\n        secondaryPersonas: [],\n        blendingStrategy: \"weighted\",\n        confidence: sorted[0].confidenceScore\n      };\n    }\n    \n    // Create blend for ambiguous cases\n    const primaryPersona = sorted[0].selectedPrompt;\n    const secondaryPersonas = sorted\n      .slice(1, 3) // Take top 2 additional personas\n      .filter(c => c.confidenceScore >= 0.3)\n      .map(c => ({\n        persona: c.selectedPrompt,\n        weight: c.confidenceScore / sorted[0].confidenceScore\n      }));\n    \n    const blendingStrategy = this.selectBlendingStrategy(\n      primaryPersona,\n      secondaryPersonas,\n      context\n    );\n    \n    return {\n      primaryPersona,\n      secondaryPersonas,\n      blendingStrategy,\n      confidence: this.calculateBlendConfidence(sorted)\n    };\n  }\n  \n  private selectBlendingStrategy(\n    primary: PromptType,\n    secondary: Array\u003C{ persona: PromptType; weight: number }>,\n    context: BlendingContext\n  ): \"weighted\" | \"sequential\" | \"contextual\" {\n    // Raid + Community = Sequential (establish rapport, then coordinate)\n    if (primary === \"raid-coordinator\" && \n        secondary.some(s => s.persona === \"community-manager\")) {\n      return \"sequential\";\n    }\n    \n    // Crypto + Personality = Weighted (analytical wisdom)\n    if ((primary === \"crypto-analyst\" && secondary.some(s => s.persona === \"personality-core\")) ||\n        (primary === \"personality-core\" && secondary.some(s => s.persona === \"crypto-analyst\"))) {\n      return \"weighted\";\n    }\n    \n    // Support + Meme = Contextual (helpful but fun)\n    if ((primary === \"support-agent\" && secondary.some(s => s.persona === \"meme-lord\")) ||\n        (primary === \"meme-lord\" && secondary.some(s => s.persona === \"support-agent\"))) {\n      return \"contextual\";\n    }\n    \n    // Default to weighted blending\n    return \"weighted\";\n  }\n  \n  async generateBlendedResponse(\n    blend: PersonaBlend,\n    message: string,\n    variables: ExtractedVariables,\n    context: ResponseContext\n  ): Promise\u003Cstring> {\n    switch (blend.blendingStrategy) {\n      case \"weighted\":\n        return await this.generateWeightedResponse(blend, message, variables, context);\n      case \"sequential\":\n        return await this.generateSequentialResponse(blend, message, variables, context);\n      case \"contextual\":\n        return await this.generateContextualResponse(blend, message, variables, context);\n      default:\n        throw new Error(`Unknown blending strategy: ${blend.blendingStrategy}`);\n    }\n  }\n  \n  private async generateWeightedResponse(\n    blend: PersonaBlend,\n    message: string,\n    variables: ExtractedVariables,\n    context: ResponseContext\n  ): Promise\u003Cstring> {\n    // Generate response segments from each persona\n    const segments = await Promise.all([\n      this.generatePersonaSegment(blend.primaryPersona, message, variables, 1.0),\n      ...blend.secondaryPersonas.map(sp => \n        this.generatePersonaSegment(sp.persona, message, variables, sp.weight)\n      )\n    ]);\n    \n    // Weave segments together naturally\n    return this.weaveSegments(segments, blend.blendingStrategy);\n  }\n  \n  private async generateSequentialResponse(\n    blend: PersonaBlend,\n    message: string,\n    variables: ExtractedVariables,\n    context: ResponseContext\n  ): Promise\u003Cstring> {\n    // Generate sequential response parts\n    const parts = [];\n    \n    // Primary persona leads\n    const primaryResponse = await this.generatePersonaSegment(\n      blend.primaryPersona, \n      message, \n      variables, \n      1.0\n    );\n    parts.push(primaryResponse);\n    \n    // Secondary personas follow\n    for (const secondary of blend.secondaryPersonas) {\n      if (secondary.weight >= 0.4) { // Only include strong secondary signals\n        const secondaryResponse = await this.generatePersonaSegment(\n          secondary.persona,\n          message,\n          variables,\n          secondary.weight\n        );\n        parts.push(secondaryResponse);\n      }\n    }\n    \n    // Join with natural transitions\n    return this.joinWithTransitions(parts);\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Context Awareness\">\n```typescript\n// Advanced context-aware classification\nexport class ContextualClassifier {\n  private conversationMemory = new Map\u003Cstring, ConversationContext>();\n  private userPersonalities = new Map\u003Cstring, UserPersonalityProfile>();\n  \n  async classifyWithContext(\n    message: string,\n    userId: string,\n    roomId: string,\n    platform: string,\n    history: ConversationHistory\n  ): Promise\u003CEnhancedClassification> {\n    // Get conversation context\n    const conversationContext = this.getConversationContext(roomId, history);\n    \n    // Get user personality profile\n    const userProfile = await this.getUserPersonalityProfile(userId);\n    \n    // Perform base classification\n    const baseClassification = await this.baseClassifier.classifyMessage(\n      message, userId, platform, crypto.randomUUID()\n    );\n    \n    // Apply contextual adjustments\n    const contextualAdjustments = await this.applyContextualAdjustments(\n      baseClassification,\n      conversationContext,\n      userProfile\n    );\n    \n    return {\n      ...baseClassification,\n      contextualAdjustments,\n      conversationFlow: conversationContext.flow,\n      userAdaptation: this.calculateUserAdaptation(userProfile, baseClassification)\n    };\n  }\n  \n  private async applyContextualAdjustments(\n    classification: MessageClassification,\n    conversationContext: ConversationContext,\n    userProfile: UserPersonalityProfile\n  ): Promise\u003CContextualAdjustments> {\n    const adjustments: ContextualAdjustments = {\n      confidenceModifier: 0,\n      personaShifts: [],\n      responseModifications: []\n    };\n    \n    // Conversation flow adjustments\n    if (conversationContext.recentPersonas.includes(\"raid-coordinator\") && \n        classification.selectedPrompt === \"community-manager\") {\n      // If we were just coordinating raids, maintain tactical tone\n      adjustments.personaShifts.push({\n        from: \"community-manager\",\n        to: \"raid-coordinator\",\n        reason: \"Maintaining tactical conversation flow\",\n        weight: 0.3\n      });\n    }\n    \n    // User preference adjustments\n    if (userProfile.preferredPersonas.includes(classification.selectedPrompt)) {\n      adjustments.confidenceModifier += 0.1;\n    }\n    \n    // Platform-specific adjustments\n    if (conversationContext.platform === \"telegram\" && \n        classification.selectedPrompt === \"personality-core\") {\n      // Telegram users prefer more direct communication\n      adjustments.responseModifications.push({\n        type: \"tone\",\n        modification: \"make_more_direct\",\n        weight: 0.2\n      });\n    }\n    \n    return adjustments;\n  }\n  \n  private getConversationContext(\n    roomId: string, \n    history: ConversationHistory\n  ): ConversationContext {\n    const recentMessages = history.messages.slice(-5);\n    \n    return {\n      roomId,\n      recentPersonas: this.extractPersonasFromHistory(recentMessages),\n      dominantTopics: this.extractTopicsFromHistory(recentMessages),\n      emotionalTone: this.analyzeEmotionalTone(recentMessages),\n      flow: this.determineConversationFlow(recentMessages),\n      platform: history.platform\n    };\n  }\n  \n  private async getUserPersonalityProfile(\n    userId: string\n  ): Promise\u003CUserPersonalityProfile> {\n    // Check cache first\n    if (this.userPersonalities.has(userId)) {\n      return this.userPersonalities.get(userId)!;\n    }\n    \n    // Build profile from interaction history\n    const profile = await this.buildUserPersonalityProfile(userId);\n    this.userPersonalities.set(userId, profile);\n    \n    return profile;\n  }\n  \n  private async buildUserPersonalityProfile(\n    userId: string\n  ): Promise\u003CUserPersonalityProfile> {\n    // Get user's interaction history\n    const interactions = await this.getUserInteractionHistory(userId, 30); // Last 30 days\n    \n    // Analyze persona preferences\n    const personaFrequency = this.analyzePersonaInteractions(interactions);\n    const topicPreferences = this.analyzeTopicPreferences(interactions);\n    const communicationStyle = this.analyzeCommunicationStyle(interactions);\n    \n    return {\n      userId,\n      preferredPersonas: this.getTopPreferences(personaFrequency, 3),\n      preferredTopics: this.getTopPreferences(topicPreferences, 5),\n      communicationStyle,\n      responsePatterns: this.identifyResponsePatterns(interactions),\n      lastUpdated: new Date()\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Classification Analytics\n\nNUBI tracks comprehensive metrics on classification performance and accuracy:\n\n\u003CTabs>\n  \u003CTabItem label=\"Performance Metrics\">\n```typescript\nexport interface ClassificationMetrics {\n  accuracy: {\n    overall: number;\n    byPersona: Record\u003CPromptType, number>;\n    byPlatform: Record\u003Cstring, number>;\n  };\n  confidence: {\n    average: number;\n    distribution: Record\u003Cstring, number>; // confidence ranges\n    lowConfidenceRate: number;\n  };\n  usage: {\n    personaFrequency: Record\u003CPromptType, number>;\n    blendingFrequency: number;\n    fallbackRate: number;\n  };\n  performance: {\n    avgClassificationTime: number;\n    cacheHitRate: number;\n    errorRate: number;\n  };\n}\n\nexport class ClassificationAnalytics {\n  private metrics: ClassificationMetrics;\n  private eventBuffer: ClassificationEvent[] = [];\n  \n  async recordClassificationEvent(event: ClassificationEvent): Promise\u003Cvoid> {\n    this.eventBuffer.push(event);\n    \n    // Flush buffer periodically\n    if (this.eventBuffer.length >= 100) {\n      await this.flushEvents();\n    }\n  }\n  \n  async generateMetricsReport(timeRange: TimeRange): Promise\u003CClassificationMetrics> {\n    const events = await this.getEventsInRange(timeRange);\n    \n    return {\n      accuracy: await this.calculateAccuracy(events),\n      confidence: await this.analyzeConfidence(events),\n      usage: await this.analyzeUsage(events),\n      performance: await this.analyzePerformance(events)\n    };\n  }\n  \n  private async calculateAccuracy(events: ClassificationEvent[]): Promise\u003Cany> {\n    // Calculate accuracy based on user feedback and correction rates\n    const totalEvents = events.length;\n    const correctedEvents = events.filter(e => e.userCorrected);\n    \n    const overall = 1 - (correctedEvents.length / totalEvents);\n    \n    // Calculate per-persona accuracy\n    const byPersona: Record\u003CPromptType, number> = {};\n    for (const persona of Object.values(PromptType)) {\n      const personaEvents = events.filter(e => e.classification.selectedPrompt === persona);\n      const personaCorrected = personaEvents.filter(e => e.userCorrected);\n      byPersona[persona] = personaEvents.length > 0 \n        ? 1 - (personaCorrected.length / personaEvents.length)\n        : 0;\n    }\n    \n    return { overall, byPersona };\n  }\n  \n  async identifyImprovementOpportunities(): Promise\u003CImprovementRecommendation[]> {\n    const metrics = await this.getCurrentMetrics();\n    const recommendations: ImprovementRecommendation[] = [];\n    \n    // Low accuracy personas\n    for (const [persona, accuracy] of Object.entries(metrics.accuracy.byPersona)) {\n      if (accuracy \u003C 0.8) {\n        recommendations.push({\n          type: \"accuracy_improvement\",\n          persona: persona as PromptType,\n          currentValue: accuracy,\n          targetValue: 0.85,\n          suggestion: `Improve ${persona} classification patterns`,\n          priority: accuracy \u003C 0.7 ? \"high\" : \"medium\"\n        });\n      }\n    }\n    \n    // High low-confidence rate\n    if (metrics.confidence.lowConfidenceRate > 0.2) {\n      recommendations.push({\n        type: \"confidence_improvement\",\n        persona: null,\n        currentValue: metrics.confidence.lowConfidenceRate,\n        targetValue: 0.15,\n        suggestion: \"Enhance classification algorithms to reduce ambiguous cases\",\n        priority: \"medium\"\n      });\n    }\n    \n    return recommendations;\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Real-time Monitoring\">\n```typescript\n// Real-time classification monitoring and alerting\nexport class ClassificationMonitor {\n  private alerts: AlertConfig[] = [];\n  private metricsCollector = new ClassificationAnalytics();\n  \n  constructor() {\n    this.setupDefaultAlerts();\n    this.startMonitoring();\n  }\n  \n  private setupDefaultAlerts(): void {\n    this.alerts = [\n      {\n        name: \"high_error_rate\",\n        condition: (metrics) => metrics.performance.errorRate > 0.05,\n        severity: \"critical\",\n        action: \"notify_developers\"\n      },\n      {\n        name: \"low_confidence_spike\",\n        condition: (metrics) => metrics.confidence.lowConfidenceRate > 0.3,\n        severity: \"warning\", \n        action: \"review_classification_patterns\"\n      },\n      {\n        name: \"persona_imbalance\",\n        condition: (metrics) => this.checkPersonaImbalance(metrics),\n        severity: \"info\",\n        action: \"analyze_user_behavior\"\n      }\n    ];\n  }\n  \n  private startMonitoring(): void {\n    setInterval(async () => {\n      const currentMetrics = await this.metricsCollector.getCurrentMetrics();\n      await this.checkAlerts(currentMetrics);\n    }, 60000); // Check every minute\n  }\n  \n  private async checkAlerts(metrics: ClassificationMetrics): Promise\u003Cvoid> {\n    for (const alert of this.alerts) {\n      if (alert.condition(metrics)) {\n        await this.triggerAlert(alert, metrics);\n      }\n    }\n  }\n  \n  private async triggerAlert(\n    alert: AlertConfig, \n    metrics: ClassificationMetrics\n  ): Promise\u003Cvoid> {\n    logger.warn(`Classification alert triggered: ${alert.name}`, {\n      alert: alert.name,\n      severity: alert.severity,\n      metrics: this.summarizeMetrics(metrics)\n    });\n    \n    switch (alert.action) {\n      case \"notify_developers\":\n        await this.notifyDevelopers(alert, metrics);\n        break;\n      case \"review_classification_patterns\":\n        await this.schedulePatternReview(metrics);\n        break;\n      case \"analyze_user_behavior\":\n        await this.analyzeUserBehavior(metrics);\n        break;\n    }\n  }\n  \n  async generateClassificationDashboard(): Promise\u003CDashboardData> {\n    const metrics = await this.metricsCollector.getCurrentMetrics();\n    const trends = await this.calculateTrends();\n    const recommendations = await this.metricsCollector.identifyImprovementOpportunities();\n    \n    return {\n      currentMetrics: metrics,\n      trends: trends,\n      recommendations: recommendations,\n      topIssues: await this.identifyTopIssues(),\n      systemHealth: this.assessSystemHealth(metrics)\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🎯 Classification Benefits:\u003C/strong> This sophisticated classification\n  system ensures that users receive the most appropriate and contextually\n  relevant responses, while continuously learning and improving from\n  interactions to provide better service over time.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Next**: Explore the [Security Processing](/ux-integration/security/) layer\n  to understand how NUBI protects against threats while maintaining performance.\n\u003C/Aside>","src/content/docs/ux-integration/classification.mdx","28e821c1c24587a1","ux-integration/classification.mdx","ux-integration/security",{"id":138,"data":140,"body":146,"filePath":147,"digest":148,"legacyId":149,"deferredRender":16},{"title":141,"description":142,"editUrl":16,"head":143,"template":47,"sidebar":144,"pagefind":16,"draft":35},"Security Processing Layer","Comprehensive guide to NUBI's Layer 1 security processing system, including rate limiting, content filtering, threat detection, and attack prevention mechanisms.",[],{"hidden":35,"attrs":145},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Security Processing Layer\n\nNUBI's **Layer 1 security processing** implements a comprehensive defense system that protects against various threats while maintaining optimal performance. This layer processes all incoming messages before they reach the classification system.\n\n## 🛡️ Security Architecture\n\nThe security layer employs a multi-stage defense strategy with parallel processing for optimal performance:\n\n```mermaid\ngraph TB\n    A[Incoming Message] --> B[Security Gateway]\n    B --> C[Rate Limiting Check]\n    B --> D[Content Analysis]\n    B --> E[Session Validation]\n    B --> F[Threat Detection]\n\n    C --> G{Rate Limit OK?}\n    G -->|No| H[Rate Limit Response]\n    G -->|Yes| I[Pattern Filtering]\n\n    D --> I\n    E --> I\n    F --> I\n\n    I --> J[XSS Prevention]\n    J --> K[Injection Detection]\n    K --> L[Spam Classification]\n    L --> M[Scam Detection]\n\n    M --> N{All Checks Pass?}\n    N -->|No| O[Security Block]\n    N -->|Yes| P[Enhanced Logging]\n\n    P --> Q[Layer 2: Classification]\n\n    H --> R[Security Analytics]\n    O --> R\n    R --> S[Threat Intelligence]\n```\n\n## 🚦 Rate Limiting System\n\nNUBI implements a sophisticated **adaptive rate limiting** system that prevents abuse while allowing legitimate usage:\n\n\u003CCardGrid>\n  \u003CCard title=\"⏱️ Time Window Control\" icon=\"clock\">\n    **5 messages per minute** per user with sliding window tracking and burst allowance for natural conversation flow.\n  \u003C/Card>\n\n\u003CCard title=\"📈 Exponential Backoff\" icon=\"chart\">\n  **Progressive penalties** for violators with exponential backoff and\n  reputation-based recovery mechanisms.\n\u003C/Card>\n\n\u003CCard title=\"🎯 Adaptive Thresholds\" icon=\"approve-check\">\n  **Dynamic adjustment** based on user behavior, platform context, and system\n  load conditions.\n\u003C/Card>\n\n  \u003CCard title=\"🔄 Distributed Tracking\" icon=\"setting\">\n    **Cross-platform coordination** ensuring consistent limits across Discord, Telegram, and web interfaces.\n  \u003C/Card>\n\u003C/CardGrid>\n\n\u003CTabs>\n  \u003CTabItem label=\"Rate Limiter Implementation\">\n```typescript\nexport interface RateLimitConfig {\n  messagesPerWindow: number;\n  windowSizeMs: number;\n  burstAllowance: number;\n  backoffMultiplier: number;\n  maxBackoffMs: number;\n  recoveryRateMs: number;\n}\n\nexport interface UserRateStatus {\n  messageCount: number;\n  windowStart: number;\n  violations: number;\n  blockedUntil?: number;\n  lastMessageTime: number;\n  burstUsed: number;\n  reputationScore: number;\n}\n\nexport class AdaptiveRateLimiter {\n  private userStatuses = new Map\u003Cstring, UserRateStatus>();\n  private globalConfig: RateLimitConfig;\n  private platformConfigs = new Map\u003Cstring, RateLimitConfig>();\n  \n  constructor() {\n    this.globalConfig = {\n      messagesPerWindow: 5,\n      windowSizeMs: 60000, // 1 minute\n      burstAllowance: 2,   // Allow 2 extra messages in burst\n      backoffMultiplier: 2,\n      maxBackoffMs: 300000, // 5 minutes max\n      recoveryRateMs: 3600000 // 1 hour reputation recovery\n    };\n    \n    this.setupPlatformConfigs();\n  }\n  \n  async checkRateLimit(\n    userId: string,\n    platform: string,\n    message: string\n  ): Promise\u003CRateLimitResult> {\n    const now = Date.now();\n    const config = this.getConfigForPlatform(platform);\n    const userStatus = this.getUserStatus(userId);\n    \n    // Check if user is currently blocked\n    if (userStatus.blockedUntil && now \u003C userStatus.blockedUntil) {\n      return {\n        allowed: false,\n        reason: \"rate_limit_exceeded\",\n        retryAfter: userStatus.blockedUntil - now,\n        remainingQuota: 0,\n        violationCount: userStatus.violations\n      };\n    }\n    \n    // Reset window if expired\n    if (now - userStatus.windowStart >= config.windowSizeMs) {\n      userStatus.messageCount = 0;\n      userStatus.windowStart = now;\n      userStatus.burstUsed = 0;\n    }\n    \n    // Check message quota\n    const totalAllowed = config.messagesPerWindow + \n      (this.canUseBurst(userStatus, config) ? config.burstAllowance : 0);\n    \n    if (userStatus.messageCount >= totalAllowed) {\n      // Rate limit exceeded\n      userStatus.violations++;\n      userStatus.blockedUntil = this.calculateBackoffTime(userStatus, config);\n      \n      await this.logRateLimitViolation(userId, platform, userStatus);\n      \n      return {\n        allowed: false,\n        reason: \"rate_limit_exceeded\",\n        retryAfter: userStatus.blockedUntil - now,\n        remainingQuota: 0,\n        violationCount: userStatus.violations\n      };\n    }\n    \n    // Message allowed - update counters\n    userStatus.messageCount++;\n    userStatus.lastMessageTime = now;\n    \n    if (userStatus.messageCount > config.messagesPerWindow) {\n      userStatus.burstUsed++;\n    }\n    \n    // Update reputation score\n    this.updateReputationScore(userStatus, message, now);\n    \n    return {\n      allowed: true,\n      reason: null,\n      retryAfter: 0,\n      remainingQuota: totalAllowed - userStatus.messageCount,\n      violationCount: userStatus.violations\n    };\n  }\n  \n  private canUseBurst(\n    userStatus: UserRateStatus, \n    config: RateLimitConfig\n  ): boolean {\n    // High reputation users get burst allowance\n    if (userStatus.reputationScore >= 0.8) return true;\n    \n    // No recent violations\n    if (userStatus.violations === 0) return true;\n    \n    // Natural conversation flow (messages spaced appropriately)\n    const timeSinceLastMessage = Date.now() - userStatus.lastMessageTime;\n    if (timeSinceLastMessage >= 10000) return true; // 10 seconds\n    \n    return false;\n  }\n  \n  private calculateBackoffTime(\n    userStatus: UserRateStatus, \n    config: RateLimitConfig\n  ): number {\n    const baseDelay = config.windowSizeMs;\n    const backoffDelay = Math.min(\n      baseDelay * Math.pow(config.backoffMultiplier, userStatus.violations - 1),\n      config.maxBackoffMs\n    );\n    \n    // Reputation-based adjustment\n    const reputationMultiplier = Math.max(0.5, 2 - userStatus.reputationScore);\n    \n    return Date.now() + (backoffDelay * reputationMultiplier);\n  }\n  \n  private updateReputationScore(\n    userStatus: UserRateStatus, \n    message: string, \n    now: number\n  ): void {\n    const messageQuality = this.assessMessageQuality(message);\n    const timeFactor = this.calculateTimeFactor(userStatus.lastMessageTime, now);\n    \n    // Positive reputation for quality messages\n    if (messageQuality > 0.7) {\n      userStatus.reputationScore += 0.05 * timeFactor;\n    }\n    \n    // Negative reputation for spam-like behavior\n    if (messageQuality \u003C 0.3) {\n      userStatus.reputationScore -= 0.1;\n    }\n    \n    // Natural decay towards neutral\n    const decayRate = 0.001;\n    userStatus.reputationScore += (0.5 - userStatus.reputationScore) * decayRate;\n    \n    // Clamp to [0, 1]\n    userStatus.reputationScore = Math.max(0, Math.min(1, userStatus.reputationScore));\n  }\n  \n  private assessMessageQuality(message: string): number {\n    let quality = 0.5; // Start neutral\n    \n    // Length factors\n    if (message.length \u003C 5) quality -= 0.3; // Very short\n    if (message.length > 10 && message.length \u003C 100) quality += 0.1; // Good length\n    if (message.length > 1000) quality -= 0.2; // Too long\n    \n    // Content quality indicators\n    const hasCapitalization = /[A-Z]/.test(message);\n    const hasPunctuation = /[.!?]/.test(message);\n    const hasVariety = new Set(message.toLowerCase()).size / message.length > 0.3;\n    \n    if (hasCapitalization) quality += 0.1;\n    if (hasPunctuation) quality += 0.1;\n    if (hasVariety) quality += 0.1;\n    \n    // Spam indicators\n    const repetitionRatio = this.calculateRepetitionRatio(message);\n    if (repetitionRatio > 0.7) quality -= 0.4;\n    \n    const capsRatio = (message.match(/[A-Z]/g) || []).length / message.length;\n    if (capsRatio > 0.3) quality -= 0.2; // Too much caps\n    \n    return Math.max(0, Math.min(1, quality));\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Platform-Specific Limits\">\n```typescript\n// Platform-specific rate limiting configurations\nexport class PlatformRateLimitManager {\n  private setupPlatformConfigs(): void {\n    // Discord - More lenient due to real-time nature\n    this.platformConfigs.set('discord', {\n      messagesPerWindow: 8,\n      windowSizeMs: 60000,\n      burstAllowance: 3,\n      backoffMultiplier: 1.5,\n      maxBackoffMs: 120000, // 2 minutes\n      recoveryRateMs: 1800000 // 30 minutes\n    });\n    \n    // Telegram - Standard limits\n    this.platformConfigs.set('telegram', {\n      messagesPerWindow: 5,\n      windowSizeMs: 60000,\n      burstAllowance: 2,\n      backoffMultiplier: 2,\n      maxBackoffMs: 300000,\n      recoveryRateMs: 3600000\n    });\n    \n    // WebSocket - Stricter due to automation potential\n    this.platformConfigs.set('websocket', {\n      messagesPerWindow: 3,\n      windowSizeMs: 60000,\n      burstAllowance: 1,\n      backoffMultiplier: 2.5,\n      maxBackoffMs: 600000, // 10 minutes\n      recoveryRateMs: 7200000 // 2 hours\n    });\n    \n    // Twitter/X - Very strict due to API limits\n    this.platformConfigs.set('twitter', {\n      messagesPerWindow: 2,\n      windowSizeMs: 300000, // 5 minutes\n      burstAllowance: 0,\n      backoffMultiplier: 3,\n      maxBackoffMs: 1800000, // 30 minutes\n      recoveryRateMs: 86400000 // 24 hours\n    });\n  }\n  \n  async getAdaptiveConfig(\n    platform: string,\n    systemLoad: number,\n    userTier: string\n  ): Promise\u003CRateLimitConfig> {\n    const baseConfig = this.platformConfigs.get(platform) || this.globalConfig;\n    \n    // Adjust for system load\n    const loadMultiplier = Math.max(0.5, 1 - (systemLoad - 0.7) * 2);\n    \n    // Adjust for user tier\n    const tierMultiplier = this.getTierMultiplier(userTier);\n    \n    return {\n      ...baseConfig,\n      messagesPerWindow: Math.floor(baseConfig.messagesPerWindow * loadMultiplier * tierMultiplier),\n      burstAllowance: Math.floor(baseConfig.burstAllowance * tierMultiplier)\n    };\n  }\n  \n  private getTierMultiplier(userTier: string): number {\n    switch (userTier) {\n      case 'premium': return 2.0;\n      case 'verified': return 1.5;\n      case 'trusted': return 1.2;\n      case 'new': return 0.5;\n      default: return 1.0;\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔍 Content Filtering System\n\nAdvanced content filtering protects against spam, scams, and malicious content while preserving legitimate communication:\n\n\u003CCardGrid>\n  \u003CCard title=\"📝 Pattern Recognition\" icon=\"search\">\n    **Multi-layered filtering** with regex patterns, machine learning models, and behavioral analysis for comprehensive threat detection.\n  \u003C/Card>\n\n\u003CCard title=\"🎯 Contextual Analysis\" icon=\"approve-check\">\n  **Context-aware filtering** that considers conversation history, user\n  reputation, and platform norms to reduce false positives.\n\u003C/Card>\n\n\u003CCard title=\"🔄 Dynamic Updates\" icon=\"refresh\">\n  **Real-time pattern updates** from threat intelligence feeds and community\n  reporting to stay ahead of evolving attacks.\n\u003C/Card>\n\n  \u003CCard title=\"⚖️ Balanced Approach\" icon=\"balance\">\n    **Performance optimization** with tiered filtering stages and smart caching to maintain sub-millisecond processing times.\n  \u003C/Card>\n\u003C/CardGrid>\n\n\u003CTabs>\n  \u003CTabItem label=\"Content Filter Engine\">\n```typescript\nexport interface FilterRule {\n  id: string;\n  name: string;\n  category: FilterCategory;\n  pattern: RegExp;\n  severity: 'low' | 'medium' | 'high' | 'critical';\n  action: FilterAction;\n  confidence: number;\n  enabled: boolean;\n  lastUpdated: Date;\n}\n\nexport enum FilterCategory {\n  SPAM = 'spam',\n  SCAM = 'scam',\n  PHISHING = 'phishing',\n  MALWARE = 'malware',\n  HARASSMENT = 'harassment',\n  INAPPROPRIATE = 'inappropriate',\n  CRYPTO_SCAM = 'crypto_scam'\n}\n\nexport enum FilterAction {\n  BLOCK = 'block',\n  QUARANTINE = 'quarantine',\n  FLAG = 'flag',\n  RATE_LIMIT = 'rate_limit',\n  LOG_ONLY = 'log_only'\n}\n\nexport class ContentFilterEngine {\n  private filterRules: Map\u003CFilterCategory, FilterRule[]> = new Map();\n  private mlModel: ContentClassificationModel;\n  private patternCache = new LRUCache\u003Cstring, FilterResult>({ max: 10000 });\n  \n  constructor() {\n    this.initializeFilterRules();\n    this.mlModel = new ContentClassificationModel();\n  }\n  \n  async filterContent(\n    content: string,\n    userId: string,\n    platform: string,\n    context: FilterContext\n  ): Promise\u003CFilterResult> {\n    const startTime = Date.now();\n    \n    // Check cache first\n    const cacheKey = this.generateCacheKey(content, platform);\n    const cached = this.patternCache.get(cacheKey);\n    if (cached && this.isCacheValid(cached, startTime)) {\n      return cached;\n    }\n    \n    // Stage 1: Fast pattern matching\n    const patternResults = await this.applyPatternFilters(content, context);\n    \n    // Stage 2: ML-based classification (for ambiguous cases)\n    const mlResults = patternResults.some(r => r.confidence \u003C 0.8) \n      ? await this.mlModel.classify(content, context)\n      : null;\n    \n    // Stage 3: Contextual analysis\n    const contextualResults = await this.applyContextualAnalysis(\n      content, \n      patternResults, \n      mlResults, \n      context\n    );\n    \n    // Combine results and make final decision\n    const finalResult = this.combineFilterResults(\n      patternResults,\n      mlResults,\n      contextualResults,\n      context\n    );\n    \n    finalResult.processingTimeMs = Date.now() - startTime;\n    \n    // Cache result\n    this.patternCache.set(cacheKey, finalResult);\n    \n    // Log if significant threat detected\n    if (finalResult.severity === 'high' || finalResult.severity === 'critical') {\n      await this.logSecurityEvent(userId, platform, content, finalResult);\n    }\n    \n    return finalResult;\n  }\n  \n  private async applyPatternFilters(\n    content: string,\n    context: FilterContext\n  ): Promise\u003CPatternFilterResult[]> {\n    const results: PatternFilterResult[] = [];\n    const lowerContent = content.toLowerCase();\n    \n    // Apply all filter categories in parallel\n    const categoryPromises = Array.from(this.filterRules.entries()).map(\n      async ([category, rules]) => {\n        return await this.applyCategoryFilters(category, rules, lowerContent, context);\n      }\n    );\n    \n    const categoryResults = await Promise.all(categoryPromises);\n    return categoryResults.flat();\n  }\n  \n  private async applyCategoryFilters(\n    category: FilterCategory,\n    rules: FilterRule[],\n    content: string,\n    context: FilterContext\n  ): Promise\u003CPatternFilterResult[]> {\n    const results: PatternFilterResult[] = [];\n    \n    for (const rule of rules) {\n      if (!rule.enabled) continue;\n      \n      const matches = content.match(rule.pattern);\n      if (matches) {\n        const confidence = this.calculatePatternConfidence(\n          rule, \n          matches, \n          content, \n          context\n        );\n        \n        results.push({\n          ruleId: rule.id,\n          category,\n          severity: rule.severity,\n          confidence,\n          matches,\n          action: rule.action\n        });\n      }\n    }\n    \n    return results;\n  }\n  \n  private initializeFilterRules(): void {\n    // Spam detection patterns\n    this.filterRules.set(FilterCategory.SPAM, [\n      {\n        id: 'spam_repetition',\n        name: 'Repetitive Content',\n        category: FilterCategory.SPAM,\n        pattern: /(.)\\1{10,}/gi, // Same character repeated 10+ times\n        severity: 'medium',\n        action: FilterAction.FLAG,\n        confidence: 0.8,\n        enabled: true,\n        lastUpdated: new Date()\n      },\n      {\n        id: 'spam_caps',\n        name: 'Excessive Capitals',\n        category: FilterCategory.SPAM,\n        pattern: /[A-Z]{20,}/g,\n        severity: 'low',\n        action: FilterAction.FLAG,\n        confidence: 0.6,\n        enabled: true,\n        lastUpdated: new Date()\n      },\n      {\n        id: 'spam_marketing',\n        name: 'Marketing Spam',\n        pattern: /\\b(free money|guaranteed profit|limited time|click here|act now)\\b/gi,\n        severity: 'medium',\n        action: FilterAction.QUARANTINE,\n        confidence: 0.75,\n        enabled: true,\n        lastUpdated: new Date()\n      }\n    ]);\n    \n    // Crypto scam patterns\n    this.filterRules.set(FilterCategory.CRYPTO_SCAM, [\n      {\n        id: 'crypto_seed_request',\n        name: 'Seed Phrase Scam',\n        category: FilterCategory.CRYPTO_SCAM,\n        pattern: /\\b(seed phrase|private key|recovery phrase|send.*sol|send.*btc)\\b/gi,\n        severity: 'critical',\n        action: FilterAction.BLOCK,\n        confidence: 0.95,\n        enabled: true,\n        lastUpdated: new Date()\n      },\n      {\n        id: 'crypto_fake_support',\n        name: 'Fake Support Scam',\n        category: FilterCategory.CRYPTO_SCAM,\n        pattern: /\\b(official support|verify.*wallet|suspended.*account)\\b/gi,\n        severity: 'high',\n        action: FilterAction.BLOCK,\n        confidence: 0.85,\n        enabled: true,\n        lastUpdated: new Date()\n      }\n    ]);\n    \n    // Phishing patterns\n    this.filterRules.set(FilterCategory.PHISHING, [\n      {\n        id: 'phishing_urgent',\n        name: 'Urgent Action Required',\n        category: FilterCategory.PHISHING,\n        pattern: /\\b(urgent.*action|account.*suspended|verify.*immediately)\\b/gi,\n        severity: 'high',\n        action: FilterAction.BLOCK,\n        confidence: 0.8,\n        enabled: true,\n        lastUpdated: new Date()\n      },\n      {\n        id: 'phishing_links',\n        name: 'Suspicious Links',\n        category: FilterCategory.PHISHING,\n        pattern: /https?:\\/\\/[^\\s]*\\b(secure|verify|update|confirm)\\b[^\\s]*/gi,\n        severity: 'medium',\n        action: FilterAction.FLAG,\n        confidence: 0.7,\n        enabled: true,\n        lastUpdated: new Date()\n      }\n    ]);\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"ML Classification\">\n```typescript\n// Machine learning-based content classification\nexport class ContentClassificationModel {\n  private model: TensorFlowModel;\n  private tokenizer: Tokenizer;\n  private isLoaded = false;\n  \n  constructor() {\n    this.initializeModel();\n  }\n  \n  async classify(\n    content: string,\n    context: FilterContext\n  ): Promise\u003CMLFilterResult> {\n    if (!this.isLoaded) {\n      await this.loadModel();\n    }\n    \n    // Preprocess content\n    const features = await this.extractFeatures(content, context);\n    \n    // Get model predictions\n    const predictions = await this.model.predict(features);\n    \n    // Post-process results\n    const classification = this.interpretPredictions(predictions, content);\n    \n    return {\n      categories: classification.categories,\n      overallThreat: classification.overallThreat,\n      confidence: classification.confidence,\n      reasoning: classification.reasoning,\n      modelVersion: this.model.version\n    };\n  }\n  \n  private async extractFeatures(\n    content: string,\n    context: FilterContext\n  ): Promise\u003CFeatureVector> {\n    // Tokenize content\n    const tokens = await this.tokenizer.tokenize(content);\n    \n    // Extract linguistic features\n    const linguisticFeatures = {\n      length: content.length,\n      wordCount: tokens.length,\n      avgWordLength: tokens.reduce((sum, token) => sum + token.length, 0) / tokens.length,\n      capsRatio: (content.match(/[A-Z]/g) || []).length / content.length,\n      punctuationRatio: (content.match(/[.!?]/g) || []).length / content.length,\n      numberRatio: (content.match(/\\d/g) || []).length / content.length,\n      urlCount: (content.match(/https?:\\/\\/[^\\s]+/g) || []).length,\n      emojiCount: (content.match(/[\\u{1F600}-\\u{1F64F}]/gu) || []).length\n    };\n    \n    // Extract contextual features\n    const contextualFeatures = {\n      platform: this.encodePlatform(context.platform),\n      timeOfDay: this.encodeTimeOfDay(context.timestamp),\n      userReputation: context.userReputation || 0.5,\n      conversationLength: context.conversationLength || 1,\n      isReply: context.isReply || false\n    };\n    \n    // Extract semantic features using embeddings\n    const semanticFeatures = await this.generateSemanticEmbedding(content);\n    \n    return {\n      linguistic: linguisticFeatures,\n      contextual: contextualFeatures,\n      semantic: semanticFeatures\n    };\n  }\n  \n  private interpretPredictions(\n    predictions: ModelPredictions,\n    content: string\n  ): ClassificationResult {\n    const categories: Map\u003CFilterCategory, number> = new Map();\n    \n    // Map model outputs to filter categories\n    categories.set(FilterCategory.SPAM, predictions.spam);\n    categories.set(FilterCategory.SCAM, predictions.scam);\n    categories.set(FilterCategory.PHISHING, predictions.phishing);\n    categories.set(FilterCategory.HARASSMENT, predictions.harassment);\n    categories.set(FilterCategory.INAPPROPRIATE, predictions.inappropriate);\n    categories.set(FilterCategory.CRYPTO_SCAM, predictions.cryptoScam);\n    \n    // Calculate overall threat score\n    const threatScores = Array.from(categories.values());\n    const overallThreat = Math.max(...threatScores);\n    \n    // Determine confidence based on prediction distribution\n    const entropy = this.calculateEntropy(threatScores);\n    const confidence = 1 - entropy / Math.log(threatScores.length);\n    \n    // Generate reasoning\n    const topCategory = Array.from(categories.entries())\n      .sort((a, b) => b[1] - a[1])[0];\n    \n    const reasoning = this.generateReasoning(topCategory, predictions, content);\n    \n    return {\n      categories,\n      overallThreat,\n      confidence,\n      reasoning\n    };\n  }\n  \n  async updateModel(): Promise\u003Cvoid> {\n    try {\n      // Download latest model from secure endpoint\n      const modelUrl = `${process.env.ML_MODEL_ENDPOINT}/content-filter/latest`;\n      const modelData = await this.secureDownload(modelUrl);\n      \n      // Validate model integrity\n      if (!await this.validateModelIntegrity(modelData)) {\n        throw new Error('Model integrity validation failed');\n      }\n      \n      // Load new model\n      const newModel = await this.loadModelFromData(modelData);\n      \n      // Test new model with known samples\n      const testResults = await this.testModel(newModel);\n      if (testResults.accuracy \u003C 0.85) {\n        throw new Error('New model does not meet accuracy threshold');\n      }\n      \n      // Replace current model\n      this.model = newModel;\n      this.isLoaded = true;\n      \n      logger.info('Content classification model updated successfully', {\n        version: newModel.version,\n        accuracy: testResults.accuracy\n      });\n      \n    } catch (error) {\n      logger.error('Failed to update ML model:', error);\n      // Continue using existing model\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔒 XSS & Injection Prevention\n\nComprehensive protection against cross-site scripting and injection attacks:\n\n\u003CTabs>\n  \u003CTabItem label=\"XSS Prevention\">\n```typescript\nexport class XSSPrevention {\n  private dangerousPatterns = [\n    // Script injection\n    /\u003Cscript\\b[^\u003C]*(?:(?!\u003C\\/script>)\u003C[^\u003C]*)*\u003C\\/script>/gi,\n    /javascript:/gi,\n    /vbscript:/gi,\n    /on\\w+\\s*=/gi,\n    \n    // HTML injection\n    /\u003Ciframe\\b[^>]*>/gi,\n    /\u003Cobject\\b[^>]*>/gi,\n    /\u003Cembed\\b[^>]*>/gi,\n    /\u003Clink\\b[^>]*>/gi,\n    /\u003Cmeta\\b[^>]*>/gi,\n    \n    // Style injection\n    /expression\\s*\\(/gi,\n    /@import\\b/gi,\n    /binding\\s*:/gi,\n    \n    // Data URLs with scripts\n    /data:\\s*text\\/html/gi,\n    /data:\\s*application\\/javascript/gi\n  ];\n  \n  async preventXSS(\n    content: string,\n    context: SecurityContext\n  ): Promise\u003CXSSPreventionResult> {\n    const originalContent = content;\n    let sanitizedContent = content;\n    const detectedThreats: XSSThreat[] = [];\n    \n    // Step 1: Pattern-based detection and removal\n    for (const pattern of this.dangerousPatterns) {\n      const matches = sanitizedContent.match(pattern);\n      if (matches) {\n        detectedThreats.push({\n          type: 'pattern_match',\n          pattern: pattern.toString(),\n          matches: matches,\n          severity: this.assessPatternSeverity(pattern)\n        });\n        \n        // Remove or neutralize dangerous content\n        sanitizedContent = sanitizedContent.replace(pattern, (match) => {\n          return this.neutralizeMatch(match);\n        });\n      }\n    }\n    \n    // Step 2: HTML entity encoding\n    sanitizedContent = this.htmlEncode(sanitizedContent);\n    \n    // Step 3: URL validation and sanitization\n    sanitizedContent = await this.sanitizeUrls(sanitizedContent);\n    \n    // Step 4: Advanced parsing for complex attacks\n    const advancedThreats = await this.detectAdvancedXSS(originalContent);\n    detectedThreats.push(...advancedThreats);\n    \n    const isModified = originalContent !== sanitizedContent;\n    const threatLevel = this.calculateThreatLevel(detectedThreats);\n    \n    return {\n      originalContent,\n      sanitizedContent,\n      isModified,\n      threatLevel,\n      detectedThreats,\n      action: this.determineAction(threatLevel, context)\n    };\n  }\n  \n  private htmlEncode(content: string): string {\n    return content\n      .replace(/&/g, '&amp;')\n      .replace(/\u003C/g, '&lt;')\n      .replace(/>/g, '&gt;')\n      .replace(/\"/g, '&quot;')\n      .replace(/'/g, '&#x27;')\n      .replace(/\\//g, '&#x2F;');\n  }\n  \n  private async sanitizeUrls(content: string): Promise\u003Cstring> {\n    const urlPattern = /(https?:\\/\\/[^\\s]+)/gi;\n    \n    return content.replace(urlPattern, (url) => {\n      try {\n        const parsedUrl = new URL(url);\n        \n        // Block data URLs\n        if (parsedUrl.protocol === 'data:') {\n          return '[BLOCKED_DATA_URL]';\n        }\n        \n        // Block javascript URLs\n        if (parsedUrl.protocol === 'javascript:') {\n          return '[BLOCKED_JS_URL]';\n        }\n        \n        // Validate domain against blacklist\n        if (this.isBlacklistedDomain(parsedUrl.hostname)) {\n          return '[BLOCKED_DOMAIN]';\n        }\n        \n        return url;\n      } catch (error) {\n        // Malformed URL, remove it\n        return '[MALFORMED_URL]';\n      }\n    });\n  }\n  \n  private async detectAdvancedXSS(content: string): Promise\u003CXSSThreat[]> {\n    const threats: XSSThreat[] = [];\n    \n    // Check for encoded attacks\n    const decodedContent = this.decodeCommonEncodings(content);\n    if (decodedContent !== content) {\n      // Re-check decoded content for threats\n      for (const pattern of this.dangerousPatterns) {\n        if (pattern.test(decodedContent)) {\n          threats.push({\n            type: 'encoded_attack',\n            pattern: pattern.toString(),\n            matches: decodedContent.match(pattern) || [],\n            severity: 'high'\n          });\n        }\n      }\n    }\n    \n    // Check for polyglot attacks\n    if (this.detectPolyglotAttack(content)) {\n      threats.push({\n        type: 'polyglot_attack',\n        pattern: 'polyglot_detection',\n        matches: [content],\n        severity: 'critical'\n      });\n    }\n    \n    return threats;\n  }\n  \n  private decodeCommonEncodings(content: string): string {\n    let decoded = content;\n    \n    // HTML entity decoding\n    decoded = decoded\n      .replace(/&lt;/g, '\u003C')\n      .replace(/&gt;/g, '>')\n      .replace(/&quot;/g, '\"')\n      .replace(/&#x27;/g, \"'\")\n      .replace(/&amp;/g, '&');\n    \n    // URL decoding\n    try {\n      decoded = decodeURIComponent(decoded);\n    } catch (e) {\n      // Invalid encoding, keep original\n    }\n    \n    // Base64 decoding (simple cases)\n    const base64Pattern = /[A-Za-z0-9+/]{20,}={0,2}/g;\n    decoded = decoded.replace(base64Pattern, (match) => {\n      try {\n        const decodedBase64 = atob(match);\n        // Only return if it contains suspicious patterns\n        return this.containsSuspiciousPatterns(decodedBase64) ? decodedBase64 : match;\n      } catch (e) {\n        return match;\n      }\n    });\n    \n    return decoded;\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"SQL Injection Prevention\">\n```typescript\nexport class SQLInjectionPrevention {\n  private sqlPatterns = [\n    // Union-based attacks\n    /\\bunion\\b.*\\bselect\\b/gi,\n    /\\bselect\\b.*\\bunion\\b/gi,\n    \n    // Boolean-based attacks\n    /\\b(and|or)\\b\\s*\\d+\\s*=\\s*\\d+/gi,\n    /\\b(and|or)\\b\\s*'[^']*'\\s*=\\s*'[^']*'/gi,\n    \n    // Time-based attacks\n    /\\bwaitfor\\b\\s+\\bdelay\\b/gi,\n    /\\bsleep\\s*\\(/gi,\n    /\\bbenchmark\\s*\\(/gi,\n    \n    // Comment-based attacks\n    /\\/\\*.*\\*\\//gi,\n    /--[^\\r\\n]*/gi,\n    /#[^\\r\\n]*/gi,\n    \n    // System function calls\n    /\\bexec\\s*\\(/gi,\n    /\\bexecute\\s*\\(/gi,\n    /\\bsp_executesql\\b/gi,\n    /\\bxp_cmdshell\\b/gi,\n    \n    // Information gathering\n    /\\btable_name\\b/gi,\n    /\\bcolumn_name\\b/gi,\n    /\\binformation_schema\\b/gi,\n    /\\bsysobjects\\b/gi,\n    /\\bsyscolumns\\b/gi\n  ];\n  \n  async preventSQLInjection(\n    input: string,\n    context: SecurityContext\n  ): Promise\u003CSQLInjectionResult> {\n    const detectedPatterns: SQLPattern[] = [];\n    let threatLevel: ThreatLevel = 'none';\n    \n    // Check for SQL injection patterns\n    for (const pattern of this.sqlPatterns) {\n      const matches = input.match(pattern);\n      if (matches) {\n        const patternThreat = this.assessSQLPatternThreat(pattern, matches);\n        detectedPatterns.push({\n          pattern: pattern.toString(),\n          matches,\n          threat: patternThreat,\n          description: this.getPatternDescription(pattern)\n        });\n        \n        if (patternThreat > threatLevel) {\n          threatLevel = patternThreat;\n        }\n      }\n    }\n    \n    // Advanced analysis for obfuscated attacks\n    const obfuscatedThreats = await this.detectObfuscatedSQL(input);\n    detectedPatterns.push(...obfuscatedThreats);\n    \n    // Calculate final threat assessment\n    const finalThreatLevel = this.calculateFinalThreat(detectedPatterns, context);\n    \n    return {\n      input,\n      threatLevel: finalThreatLevel,\n      detectedPatterns,\n      recommendation: this.getRecommendation(finalThreatLevel),\n      sanitizedInput: this.sanitizeSQL(input, detectedPatterns)\n    };\n  }\n  \n  private sanitizeSQL(input: string, patterns: SQLPattern[]): string {\n    let sanitized = input;\n    \n    // Remove or escape dangerous patterns\n    for (const pattern of patterns) {\n      if (pattern.threat === 'critical' || pattern.threat === 'high') {\n        // Remove completely for high-risk patterns\n        sanitized = sanitized.replace(new RegExp(pattern.pattern, 'gi'), '[FILTERED]');\n      } else if (pattern.threat === 'medium') {\n        // Escape for medium-risk patterns\n        sanitized = this.escapeSQLCharacters(sanitized);\n      }\n    }\n    \n    return sanitized;\n  }\n  \n  private escapeSQLCharacters(input: string): string {\n    return input\n      .replace(/'/g, \"''\")    // Escape single quotes\n      .replace(/\"/g, '\"\"')    // Escape double quotes\n      .replace(/\\\\/g, '\\\\\\\\') // Escape backslashes\n      .replace(/;/g, '\\\\;')   // Escape semicolons\n      .replace(/--/g, '\\\\--') // Escape SQL comments\n      .replace(/\\/\\*/g, '\\\\/\\\\*') // Escape block comments\n      .replace(/\\*\\//g, '\\\\*\\\\/');\n  }\n  \n  private async detectObfuscatedSQL(input: string): Promise\u003CSQLPattern[]> {\n    const threats: SQLPattern[] = [];\n    \n    // Check for character encoding obfuscation\n    const decodedInput = this.decodeVariousEncodings(input);\n    if (decodedInput !== input) {\n      // Re-scan decoded content\n      for (const pattern of this.sqlPatterns) {\n        if (pattern.test(decodedInput)) {\n          threats.push({\n            pattern: 'obfuscated_' + pattern.toString(),\n            matches: decodedInput.match(pattern) || [],\n            threat: 'high',\n            description: 'Obfuscated SQL injection attempt'\n          });\n        }\n      }\n    }\n    \n    // Check for concatenation-based obfuscation\n    if (this.detectConcatenationObfuscation(input)) {\n      threats.push({\n        pattern: 'concatenation_obfuscation',\n        matches: [input],\n        threat: 'high',\n        description: 'String concatenation obfuscation detected'\n      });\n    }\n    \n    return threats;\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🛡️ Advanced Threat Detection\n\nNUBI employs sophisticated threat detection mechanisms for emerging attack patterns:\n\n\u003CTabs>\n  \u003CTabItem label=\"Behavioral Analysis\">\n```typescript\nexport class BehavioralThreatDetector {\n  private userBehaviorProfiles = new Map\u003Cstring, UserBehaviorProfile>();\n  private anomalyThresholds = {\n    messageFrequency: 0.3,\n    contentSimilarity: 0.8,\n    platformSwitching: 0.4,\n    timePatterns: 0.25\n  };\n  \n  async analyzeBehavioralThreats(\n    userId: string,\n    message: string,\n    context: BehaviorContext\n  ): Promise\u003CBehavioralThreatResult> {\n    const profile = await this.getUserBehaviorProfile(userId);\n    const currentBehavior = await this.extractCurrentBehavior(message, context);\n    \n    const anomalies = await this.detectAnomalies(profile, currentBehavior);\n    const threatScore = this.calculateBehavioralThreatScore(anomalies);\n    \n    // Update profile with current behavior\n    await this.updateBehaviorProfile(userId, profile, currentBehavior);\n    \n    return {\n      userId,\n      threatScore,\n      anomalies,\n      recommendations: this.generateRecommendations(anomalies),\n      profileConfidence: profile.confidence\n    };\n  }\n  \n  private async detectAnomalies(\n    profile: UserBehaviorProfile,\n    current: CurrentBehavior\n  ): Promise\u003CBehavioralAnomaly[]> {\n    const anomalies: BehavioralAnomaly[] = [];\n    \n    // Message frequency analysis\n    if (this.isFrequencyAnomaly(profile.messageFrequency, current.messageFrequency)) {\n      anomalies.push({\n        type: 'frequency_anomaly',\n        severity: this.calculateFrequencyAnomalySeverity(profile, current),\n        description: 'Unusual messaging frequency detected',\n        baseline: profile.messageFrequency,\n        current: current.messageFrequency,\n        zscore: this.calculateZScore(profile.messageFrequency, current.messageFrequency)\n      });\n    }\n    \n    // Content pattern analysis\n    const contentSimilarity = await this.calculateContentSimilarity(\n      profile.contentPatterns, \n      current.contentPattern\n    );\n    \n    if (contentSimilarity \u003C this.anomalyThresholds.contentSimilarity) {\n      anomalies.push({\n        type: 'content_anomaly',\n        severity: this.calculateContentAnomalySeverity(contentSimilarity),\n        description: 'Unusual content pattern detected',\n        baseline: profile.contentPatterns,\n        current: current.contentPattern,\n        similarity: contentSimilarity\n      });\n    }\n    \n    // Time pattern analysis\n    if (this.isTimePatternAnomaly(profile.activityPatterns, current.timeContext)) {\n      anomalies.push({\n        type: 'temporal_anomaly',\n        severity: 'medium',\n        description: 'Unusual activity timing detected',\n        baseline: profile.activityPatterns,\n        current: current.timeContext\n      });\n    }\n    \n    // Platform behavior analysis\n    if (this.isPlatformBehaviorAnomaly(profile.platformBehaviors, current.platform)) {\n      anomalies.push({\n        type: 'platform_anomaly',\n        severity: 'low',\n        description: 'Unusual cross-platform behavior detected',\n        baseline: profile.platformBehaviors,\n        current: current.platform\n      });\n    }\n    \n    return anomalies;\n  }\n  \n  private calculateBehavioralThreatScore(anomalies: BehavioralAnomaly[]): number {\n    if (anomalies.length === 0) return 0;\n    \n    const severityWeights = {\n      'low': 0.2,\n      'medium': 0.5,\n      'high': 0.8,\n      'critical': 1.0\n    };\n    \n    const weightedSum = anomalies.reduce((sum, anomaly) => {\n      return sum + severityWeights[anomaly.severity];\n    }, 0);\n    \n    // Normalize by number of anomalies and apply scaling\n    const baseScore = weightedSum / anomalies.length;\n    \n    // Apply anomaly count multiplier (more anomalies = higher threat)\n    const countMultiplier = Math.min(1.5, 1 + (anomalies.length - 1) * 0.1);\n    \n    return Math.min(1.0, baseScore * countMultiplier);\n  }\n  \n  async detectCoordinatedAttacks(\n    recentEvents: SecurityEvent[]\n  ): Promise\u003CCoordinatedAttackResult> {\n    // Group events by time windows\n    const timeWindows = this.groupEventsByTimeWindows(recentEvents, 300000); // 5-minute windows\n    \n    const suspiciousWindows = [];\n    \n    for (const window of timeWindows) {\n      const coordination = await this.analyzeCoordination(window);\n      \n      if (coordination.suspicionScore > 0.7) {\n        suspiciousWindows.push({\n          timeWindow: window.timeRange,\n          events: window.events,\n          coordination,\n          participants: this.extractParticipants(window.events),\n          patterns: this.identifyAttackPatterns(window.events)\n        });\n      }\n    }\n    \n    return {\n      coordinatedAttackDetected: suspiciousWindows.length > 0,\n      suspiciousWindows,\n      overallThreatLevel: this.calculateOverallCoordinationThreat(suspiciousWindows),\n      recommendations: this.generateCoordinationRecommendations(suspiciousWindows)\n    };\n  }\n  \n  private async analyzeCoordination(window: EventWindow): Promise\u003CCoordinationAnalysis> {\n    const events = window.events;\n    \n    // Analyze message similarity\n    const contentSimilarity = await this.analyzeContentSimilarity(events);\n    \n    // Analyze timing patterns\n    const timingPatterns = this.analyzeTimingPatterns(events);\n    \n    // Analyze source patterns\n    const sourcePatterns = this.analyzeSourcePatterns(events);\n    \n    // Analyze network patterns (if available)\n    const networkPatterns = await this.analyzeNetworkPatterns(events);\n    \n    const suspicionScore = this.calculateCoordinationScore({\n      contentSimilarity,\n      timingPatterns,\n      sourcePatterns,\n      networkPatterns\n    });\n    \n    return {\n      suspicionScore,\n      contentSimilarity,\n      timingPatterns,\n      sourcePatterns,\n      networkPatterns,\n      confidence: this.calculateCoordinationConfidence(events.length)\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Threat Intelligence\">\n```typescript\nexport class ThreatIntelligenceSystem {\n  private threatFeeds = new Map\u003Cstring, ThreatFeed>();\n  private indicatorCache = new Map\u003Cstring, ThreatIndicator>();\n  private updateInterval = 3600000; // 1 hour\n  \n  constructor() {\n    this.initializeThreatFeeds();\n    this.startPeriodicUpdates();\n  }\n  \n  async checkThreatIntelligence(\n    content: string,\n    metadata: ThreatContext\n  ): Promise\u003CThreatIntelligenceResult> {\n    const indicators = await this.extractIndicators(content, metadata);\n    const threatMatches: ThreatMatch[] = [];\n    \n    for (const indicator of indicators) {\n      const threats = await this.queryThreatFeeds(indicator);\n      if (threats.length > 0) {\n        threatMatches.push({\n          indicator,\n          threats,\n          confidence: this.calculateMatchConfidence(indicator, threats),\n          severity: this.calculateMaxSeverity(threats)\n        });\n      }\n    }\n    \n    const overallRisk = this.calculateOverallRisk(threatMatches);\n    \n    return {\n      riskLevel: overallRisk,\n      threatMatches,\n      recommendations: this.generateThreatRecommendations(threatMatches),\n      indicators,\n      lastUpdate: await this.getLastUpdateTime()\n    };\n  }\n  \n  private async extractIndicators(\n    content: string,\n    metadata: ThreatContext\n  ): Promise\u003CThreatIndicator[]> {\n    const indicators: ThreatIndicator[] = [];\n    \n    // Extract URLs\n    const urlMatches = content.match(/https?:\\/\\/[^\\s]+/g);\n    if (urlMatches) {\n      for (const url of urlMatches) {\n        indicators.push({\n          type: 'url',\n          value: url,\n          source: 'message_content',\n          confidence: 0.9\n        });\n        \n        // Also extract domain\n        try {\n          const domain = new URL(url).hostname;\n          indicators.push({\n            type: 'domain',\n            value: domain,\n            source: 'url_extraction',\n            confidence: 0.95\n          });\n        } catch (e) {\n          // Invalid URL, skip domain extraction\n        }\n      }\n    }\n    \n    // Extract IP addresses\n    const ipMatches = content.match(/\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b/g);\n    if (ipMatches) {\n      for (const ip of ipMatches) {\n        if (this.isValidIP(ip)) {\n          indicators.push({\n            type: 'ip',\n            value: ip,\n            source: 'message_content',\n            confidence: 0.85\n          });\n        }\n      }\n    }\n    \n    // Extract email addresses\n    const emailMatches = content.match(/\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b/g);\n    if (emailMatches) {\n      for (const email of emailMatches) {\n        indicators.push({\n          type: 'email',\n          value: email,\n          source: 'message_content',\n          confidence: 0.8\n        });\n      }\n    }\n    \n    // Extract crypto addresses\n    const cryptoMatches = this.extractCryptoAddresses(content);\n    indicators.push(...cryptoMatches);\n    \n    // Extract file hashes\n    const hashMatches = this.extractFileHashes(content);\n    indicators.push(...hashMatches);\n    \n    return indicators;\n  }\n  \n  private async queryThreatFeeds(\n    indicator: ThreatIndicator\n  ): Promise\u003CThreatIntelligenceItem[]> {\n    const threats: ThreatIntelligenceItem[] = [];\n    \n    // Check cache first\n    const cacheKey = `${indicator.type}:${indicator.value}`;\n    const cached = this.indicatorCache.get(cacheKey);\n    if (cached && this.isCacheValid(cached)) {\n      return cached.threats;\n    }\n    \n    // Query all active threat feeds\n    const feedPromises = Array.from(this.threatFeeds.values()).map(async (feed) => {\n      if (feed.isActive && feed.supportsIndicatorType(indicator.type)) {\n        try {\n          return await feed.query(indicator);\n        } catch (error) {\n          logger.warn(`Threat feed ${feed.name} query failed:`, error);\n          return [];\n        }\n      }\n      return [];\n    });\n    \n    const feedResults = await Promise.all(feedPromises);\n    const allThreats = feedResults.flat();\n    \n    // Cache result\n    this.indicatorCache.set(cacheKey, {\n      threats: allThreats,\n      timestamp: Date.now(),\n      ttl: 3600000 // 1 hour\n    });\n    \n    return allThreats;\n  }\n  \n  private initializeThreatFeeds(): void {\n    // Malware domain feed\n    this.threatFeeds.set('malware_domains', new ThreatFeed({\n      name: 'Malware Domains',\n      url: process.env.MALWARE_DOMAINS_FEED,\n      type: 'domain_blacklist',\n      updateInterval: 3600000,\n      isActive: true,\n      supportedTypes: ['domain', 'url']\n    }));\n    \n    // Phishing URL feed\n    this.threatFeeds.set('phishing_urls', new ThreatFeed({\n      name: 'Phishing URLs',\n      url: process.env.PHISHING_URLS_FEED,\n      type: 'url_blacklist',\n      updateInterval: 1800000, // 30 minutes\n      isActive: true,\n      supportedTypes: ['url']\n    }));\n    \n    // Crypto scam addresses\n    this.threatFeeds.set('crypto_scams', new ThreatFeed({\n      name: 'Crypto Scam Addresses',\n      url: process.env.CRYPTO_SCAM_FEED,\n      type: 'crypto_blacklist',\n      updateInterval: 7200000, // 2 hours\n      isActive: true,\n      supportedTypes: ['crypto_address']\n    }));\n    \n    // IP reputation feed\n    this.threatFeeds.set('ip_reputation', new ThreatFeed({\n      name: 'IP Reputation',\n      url: process.env.IP_REPUTATION_FEED,\n      type: 'ip_reputation',\n      updateInterval: 3600000,\n      isActive: true,\n      supportedTypes: ['ip']\n    }));\n  }\n  \n  async generateThreatReport(): Promise\u003CThreatReport> {\n    const recentThreats = await this.getRecentThreats(86400000); // Last 24 hours\n    \n    const report = {\n      timeRange: {\n        start: Date.now() - 86400000,\n        end: Date.now()\n      },\n      summary: {\n        totalThreats: recentThreats.length,\n        blockedThreats: recentThreats.filter(t => t.action === 'blocked').length,\n        flaggedThreats: recentThreats.filter(t => t.action === 'flagged').length,\n        byCategory: this.groupThreatsByCategory(recentThreats),\n        bySeverity: this.groupThreatsBySeverity(recentThreats)\n      },\n      trends: await this.calculateThreatTrends(),\n      topThreats: this.getTopThreats(recentThreats, 10),\n      emergingThreats: await this.identifyEmergingThreats(),\n      feedHealth: await this.assessFeedHealth(),\n      recommendations: await this.generateSecurityRecommendations(recentThreats)\n    };\n    \n    return report;\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Security Analytics & Monitoring\n\nComprehensive monitoring and analytics for security events:\n\n\u003CTabs>\n  \u003CTabItem label=\"Real-time Monitoring\">\n```typescript\nexport class SecurityMonitor {\n  private eventBuffer: SecurityEvent[] = [];\n  private alertConfigs: AlertConfiguration[] = [];\n  private metricsCollector = new SecurityMetricsCollector();\n  \n  async processSecurityEvent(event: SecurityEvent): Promise\u003Cvoid> {\n    // Add to buffer for batch processing\n    this.eventBuffer.push(event);\n    \n    // Check for immediate alerts\n    await this.checkImmediateAlerts(event);\n    \n    // Update real-time metrics\n    await this.metricsCollector.updateMetrics(event);\n    \n    // Flush buffer if needed\n    if (this.eventBuffer.length >= 100) {\n      await this.flushEventBuffer();\n    }\n  }\n  \n  private async checkImmediateAlerts(event: SecurityEvent): Promise\u003Cvoid> {\n    for (const config of this.alertConfigs) {\n      if (this.eventMatchesAlertConfig(event, config)) {\n        await this.triggerAlert(config, event);\n      }\n    }\n  }\n  \n  async generateSecurityDashboard(): Promise\u003CSecurityDashboard> {\n    const metrics = await this.metricsCollector.getCurrentMetrics();\n    \n    return {\n      overview: {\n        threatsBlocked: metrics.threatsBlocked,\n        activeUsers: metrics.activeUsers,\n        systemHealth: this.calculateSystemHealth(metrics),\n        alertLevel: this.calculateAlertLevel(metrics)\n      },\n      threatBreakdown: {\n        byType: metrics.threatsByType,\n        bySeverity: metrics.threatsBySeverity,\n        byPlatform: metrics.threatsByPlatform,\n        trending: await this.getTrendingThreats()\n      },\n      performance: {\n        averageProcessingTime: metrics.avgProcessingTime,\n        successRate: metrics.successRate,\n        errorRate: metrics.errorRate,\n        throughput: metrics.messagesPerSecond\n      },\n      alerts: {\n        active: await this.getActiveAlerts(),\n        recent: await this.getRecentAlerts(3600000), // Last hour\n        escalated: await this.getEscalatedAlerts()\n      }\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🛡️ Security Benefits:\u003C/strong> This comprehensive security layer\n  ensures NUBI maintains robust protection against diverse threats while\n  delivering optimal performance and user experience across all platforms.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Architecture Complete**: You've now explored NUBI's complete UX Integration\n  system. Continue with the [Database System](/database/overview/) to understand\n  the data layer architecture.\n\u003C/Aside>","src/content/docs/ux-integration/security.mdx","37780cd0153c7a6a","ux-integration/security.mdx","database/query-routing",{"id":150,"data":152,"body":158,"filePath":159,"digest":160,"legacyId":161,"deferredRender":16},{"title":153,"description":154,"editUrl":16,"head":155,"template":47,"sidebar":156,"pagefind":16,"draft":35},"Query Routing System","Deep dive into NUBI's intelligent query routing system that optimally distributes database operations between transaction and session pools for maximum performance.",[],{"hidden":35,"attrs":157},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Query Routing System\n\nNUBI's **intelligent query routing system** automatically distributes database operations between specialized connection pools based on query complexity, ensuring optimal performance and resource utilization across all database operations.\n\n## 🎯 Dual-Pool Architecture\n\nThe query router manages two specialized connection pools, each optimized for different operation types:\n\n```mermaid\ngraph TB\n    A[Incoming Query] --> B[Query Analyzer]\n    B --> C{Query Complexity Analysis}\n\n    C -->|Simple CRUD| D[Transaction Pool]\n    C -->|Complex Analytics| E[Session Pool]\n    C -->|Vector Operations| E\n\n    subgraph \"Transaction Pool :6543\"\n        F[Connection 1]\n        G[Connection 2]\n        H[... 15 Connections]\n        I[Optimized for Throughput]\n    end\n\n    subgraph \"Session Pool :5432\"\n        J[Connection 1]\n        K[Connection 2]\n        L[... 5 Connections]\n        M[Optimized for Complexity]\n    end\n\n    D --> F\n    D --> G\n    D --> H\n    E --> J\n    E --> K\n    E --> L\n\n    N[Performance Metrics] --> O[Adaptive Optimization]\n    O --> B\n```\n\n\u003CCardGrid>\n  \u003CCard title=\"🚀 Transaction Pool (Port 6543)\" icon=\"rocket\">\n    **High-throughput CRUD operations** with 15 connections optimized for simple queries, delivering sub-50ms response times.\n  \u003C/Card>\n\n\u003CCard title=\"🧠 Session Pool (Port 5432)\" icon=\"setting\">\n  **Complex analytical queries** with 5 connections optimized for joins,\n  aggregations, and vector similarity searches.\n\u003C/Card>\n\n\u003CCard title=\"⚡ Smart Routing\" icon=\"approve-check\">\n  **Automatic query analysis** with machine learning-enhanced pattern\n  recognition for optimal pool selection.\n\u003C/Card>\n\n  \u003CCard title=\"📊 Adaptive Optimization\" icon=\"chart\">\n    **Real-time performance monitoring** with automatic threshold adjustment and load balancing optimization.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🔍 Query Analysis Engine\n\nThe query analysis engine employs multiple techniques to classify queries and determine optimal routing:\n\n\u003CTabs>\n  \u003CTabItem label=\"Core Query Router\">\n```typescript\nexport enum QueryComplexity {\n  SIMPLE = 'simple',\n  MEDIUM = 'medium', \n  COMPLEX = 'complex',\n  VECTOR = 'vector'\n}\n\nexport interface QueryAnalysis {\n  complexity: QueryComplexity;\n  estimatedDuration: number;\n  resourceRequirements: ResourceRequirements;\n  operationType: OperationType;\n  confidence: number;\n  reasoning: string[];\n}\n\nexport interface ResourceRequirements {\n  memoryEstimate: number;  // MB\n  cpuIntensity: number;    // 0-1 scale\n  ioOperations: number;    // Estimated I/O ops\n  networkTraffic: number;  // Estimated bytes\n}\n\nexport class QueryRouter {\n  private transactionPool: DatabasePool;\n  private sessionPool: DatabasePool;\n  private performanceMonitor: QueryPerformanceMonitor;\n  private analysisCache = new LRUCache\u003Cstring, QueryAnalysis>({ max: 5000 });\n  \n  constructor(config: QueryRouterConfig) {\n    this.initializePools(config);\n    this.performanceMonitor = new QueryPerformanceMonitor();\n  }\n  \n  async executeQuery(\n    query: string,\n    params: any[],\n    context?: QueryContext\n  ): Promise\u003CQueryResult> {\n    const startTime = Date.now();\n    \n    // Analyze query for routing decision\n    const analysis = await this.analyzeQuery(query, params, context);\n    \n    // Select optimal pool\n    const pool = this.selectPool(analysis);\n    \n    // Execute with monitoring\n    try {\n      const result = await this.executeWithMonitoring(\n        pool,\n        query,\n        params,\n        analysis\n      );\n      \n      // Update performance metrics\n      await this.updatePerformanceMetrics(analysis, startTime, true, result);\n      \n      return result;\n    } catch (error) {\n      // Update failure metrics\n      await this.updatePerformanceMetrics(analysis, startTime, false, null, error);\n      throw error;\n    }\n  }\n  \n  private async analyzeQuery(\n    query: string,\n    params: any[],\n    context?: QueryContext\n  ): Promise\u003CQueryAnalysis> {\n    // Check cache first\n    const cacheKey = this.generateCacheKey(query, params);\n    const cached = this.analysisCache.get(cacheKey);\n    if (cached) {\n      return cached;\n    }\n    \n    const analysis = await this.performQueryAnalysis(query, params, context);\n    \n    // Cache the analysis\n    this.analysisCache.set(cacheKey, analysis);\n    \n    return analysis;\n  }\n  \n  private async performQueryAnalysis(\n    query: string,\n    params: any[],\n    context?: QueryContext\n  ): Promise\u003CQueryAnalysis> {\n    const normalizedQuery = query.toLowerCase().trim();\n    const reasoning: string[] = [];\n    \n    // Pattern-based analysis\n    const patternAnalysis = this.analyzeQueryPatterns(normalizedQuery);\n    reasoning.push(...patternAnalysis.reasoning);\n    \n    // Structural analysis\n    const structuralAnalysis = this.analyzeQueryStructure(normalizedQuery);\n    reasoning.push(...structuralAnalysis.reasoning);\n    \n    // Parameter analysis\n    const paramAnalysis = this.analyzeParameters(params);\n    reasoning.push(...paramAnalysis.reasoning);\n    \n    // Combine analyses\n    const complexity = this.determineOverallComplexity([\n      patternAnalysis,\n      structuralAnalysis,\n      paramAnalysis\n    ]);\n    \n    const resourceRequirements = this.estimateResourceRequirements(\n      complexity,\n      normalizedQuery,\n      params\n    );\n    \n    return {\n      complexity,\n      estimatedDuration: this.estimateQueryDuration(complexity, resourceRequirements),\n      resourceRequirements,\n      operationType: this.determineOperationType(normalizedQuery),\n      confidence: this.calculateAnalysisConfidence([\n        patternAnalysis,\n        structuralAnalysis,\n        paramAnalysis\n      ]),\n      reasoning\n    };\n  }\n  \n  private analyzeQueryPatterns(query: string): PatternAnalysis {\n    const patterns = {\n      // Vector operations - Always complex\n      vector: {\n        regex: /\\b(embedding|\u003C->|\u003C#>|\u003C=>|\\|\\|)\\b/gi,\n        complexity: QueryComplexity.VECTOR,\n        confidence: 0.95\n      },\n      \n      // Complex joins\n      multiJoin: {\n        regex: /\\bjoin\\b.*\\bjoin\\b.*\\bjoin\\b/gi,\n        complexity: QueryComplexity.COMPLEX,\n        confidence: 0.9\n      },\n      \n      // Aggregations\n      aggregation: {\n        regex: /\\b(group\\s+by|having|count\\(|sum\\(|avg\\(|max\\(|min\\()\\b/gi,\n        complexity: QueryComplexity.MEDIUM,\n        confidence: 0.8\n      },\n      \n      // Window functions\n      windowFunction: {\n        regex: /\\b(over\\s*\\(|row_number|rank|dense_rank|lag|lead)\\b/gi,\n        complexity: QueryComplexity.COMPLEX,\n        confidence: 0.85\n      },\n      \n      // Simple CRUD\n      simpleCrud: {\n        regex: /^(select\\s+\\*|insert\\s+into|update\\s+\\w+\\s+set|delete\\s+from)\\s+\\w+(\\s+where\\s+\\w+\\s*=)?/gi,\n        complexity: QueryComplexity.SIMPLE,\n        confidence: 0.9\n      },\n      \n      // Subqueries\n      subquery: {\n        regex: /\\b(select\\b.*\\bfrom\\b.*\\(.*select\\b)/gi,\n        complexity: QueryComplexity.MEDIUM,\n        confidence: 0.75\n      }\n    };\n    \n    const matches: PatternMatch[] = [];\n    const reasoning: string[] = [];\n    \n    for (const [name, pattern] of Object.entries(patterns)) {\n      const match = query.match(pattern.regex);\n      if (match) {\n        matches.push({\n          pattern: name,\n          complexity: pattern.complexity,\n          confidence: pattern.confidence,\n          matches: match\n        });\n        reasoning.push(`${name} pattern detected: ${pattern.complexity}`);\n      }\n    }\n    \n    // Determine highest complexity\n    const maxComplexity = matches.reduce((max, match) => {\n      const complexityOrder = {\n        [QueryComplexity.SIMPLE]: 1,\n        [QueryComplexity.MEDIUM]: 2,\n        [QueryComplexity.COMPLEX]: 3,\n        [QueryComplexity.VECTOR]: 4\n      };\n      return complexityOrder[match.complexity] > complexityOrder[max] \n        ? match.complexity \n        : max;\n    }, QueryComplexity.SIMPLE);\n    \n    const avgConfidence = matches.length > 0 \n      ? matches.reduce((sum, match) => sum + match.confidence, 0) / matches.length\n      : 0.5;\n    \n    return {\n      complexity: maxComplexity,\n      confidence: avgConfidence,\n      matches,\n      reasoning\n    };\n  }\n  \n  private selectPool(analysis: QueryAnalysis): DatabasePool {\n    // Vector operations always go to session pool\n    if (analysis.complexity === QueryComplexity.VECTOR) {\n      return this.sessionPool;\n    }\n    \n    // Complex operations go to session pool\n    if (analysis.complexity === QueryComplexity.COMPLEX) {\n      return this.sessionPool;\n    }\n    \n    // Medium complexity - check current load\n    if (analysis.complexity === QueryComplexity.MEDIUM) {\n      const transactionLoad = this.transactionPool.getCurrentLoad();\n      const sessionLoad = this.sessionPool.getCurrentLoad();\n      \n      // If transaction pool is heavily loaded, use session pool\n      if (transactionLoad > 0.8 && sessionLoad \u003C 0.6) {\n        return this.sessionPool;\n      }\n      \n      // For medium queries with low resource requirements, use transaction pool\n      if (analysis.resourceRequirements.memoryEstimate \u003C 50) {\n        return this.transactionPool;\n      }\n      \n      return this.sessionPool;\n    }\n    \n    // Simple operations go to transaction pool\n    return this.transactionPool;\n  }\n  \n  private async executeWithMonitoring(\n    pool: DatabasePool,\n    query: string,\n    params: any[],\n    analysis: QueryAnalysis\n  ): Promise\u003CQueryResult> {\n    const executionId = crypto.randomUUID();\n    const startTime = Date.now();\n    \n    // Start monitoring\n    this.performanceMonitor.startExecution({\n      executionId,\n      pool: pool.name,\n      complexity: analysis.complexity,\n      estimatedDuration: analysis.estimatedDuration\n    });\n    \n    try {\n      // Get connection from pool\n      const connection = await pool.getConnection();\n      \n      try {\n        // Execute query\n        const result = await connection.query(query, params);\n        \n        const endTime = Date.now();\n        const actualDuration = endTime - startTime;\n        \n        // Record success metrics\n        this.performanceMonitor.recordSuccess({\n          executionId,\n          actualDuration,\n          rowsAffected: result.rowCount || 0,\n          pool: pool.name\n        });\n        \n        return {\n          rows: result.rows,\n          rowCount: result.rowCount,\n          executionTime: actualDuration,\n          pool: pool.name,\n          analysis\n        };\n        \n      } finally {\n        // Always return connection to pool\n        pool.releaseConnection(connection);\n      }\n      \n    } catch (error) {\n      const endTime = Date.now();\n      const actualDuration = endTime - startTime;\n      \n      // Record failure metrics\n      this.performanceMonitor.recordFailure({\n        executionId,\n        actualDuration,\n        error: error.message,\n        pool: pool.name\n      });\n      \n      throw error;\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Advanced Query Analysis\">\n```typescript\n// Advanced query analysis with ML-enhanced classification\nexport class AdvancedQueryAnalyzer {\n  private mlModel: QueryClassificationModel;\n  private queryStatistics = new Map\u003Cstring, QueryStats>();\n  \n  constructor() {\n    this.mlModel = new QueryClassificationModel();\n  }\n  \n  async analyzeQueryStructure(query: string): Promise\u003CStructuralAnalysis> {\n    const ast = await this.parseQueryAST(query);\n    \n    const analysis = {\n      tableCount: this.countTables(ast),\n      joinCount: this.countJoins(ast),\n      whereClauseComplexity: this.analyzeWhereClause(ast),\n      subqueryDepth: this.calculateSubqueryDepth(ast),\n      aggregationCount: this.countAggregations(ast),\n      windowFunctionCount: this.countWindowFunctions(ast),\n      unionCount: this.countUnions(ast)\n    };\n    \n    const complexity = this.classifyStructuralComplexity(analysis);\n    const resourceEstimate = this.estimateStructuralResources(analysis);\n    \n    return {\n      complexity,\n      confidence: 0.85,\n      resourceEstimate,\n      details: analysis,\n      reasoning: this.generateStructuralReasoning(analysis)\n    };\n  }\n  \n  private classifyStructuralComplexity(analysis: StructuralAnalysis): QueryComplexity {\n    let complexityScore = 0;\n    \n    // Table count impact\n    complexityScore += analysis.tableCount * 0.5;\n    \n    // Join complexity (exponential impact)\n    complexityScore += Math.pow(analysis.joinCount, 1.5) * 2;\n    \n    // Subquery depth (significant impact)\n    complexityScore += analysis.subqueryDepth * 3;\n    \n    // Aggregations and window functions\n    complexityScore += analysis.aggregationCount * 1.5;\n    complexityScore += analysis.windowFunctionCount * 2.5;\n    \n    // Union operations\n    complexityScore += analysis.unionCount * 2;\n    \n    // Where clause complexity\n    complexityScore += analysis.whereClauseComplexity * 0.5;\n    \n    // Classification thresholds\n    if (complexityScore \u003C 2) return QueryComplexity.SIMPLE;\n    if (complexityScore \u003C 8) return QueryComplexity.MEDIUM;\n    return QueryComplexity.COMPLEX;\n  }\n  \n  async enhanceWithMLAnalysis(\n    query: string,\n    structuralAnalysis: StructuralAnalysis,\n    patternAnalysis: PatternAnalysis\n  ): Promise\u003CMLEnhancedAnalysis> {\n    // Extract features for ML model\n    const features = this.extractMLFeatures(query, structuralAnalysis, patternAnalysis);\n    \n    // Get ML predictions\n    const mlPrediction = await this.mlModel.predict(features);\n    \n    // Combine traditional analysis with ML insights\n    const combinedComplexity = this.combineComplexityAnalyses(\n      structuralAnalysis.complexity,\n      patternAnalysis.complexity,\n      mlPrediction.complexity\n    );\n    \n    return {\n      originalComplexity: {\n        structural: structuralAnalysis.complexity,\n        pattern: patternAnalysis.complexity\n      },\n      mlPrediction,\n      finalComplexity: combinedComplexity,\n      confidence: this.calculateCombinedConfidence([\n        structuralAnalysis.confidence,\n        patternAnalysis.confidence,\n        mlPrediction.confidence\n      ]),\n      reasoning: [\n        ...structuralAnalysis.reasoning,\n        ...patternAnalysis.reasoning,\n        `ML model suggests: ${mlPrediction.complexity} (${mlPrediction.confidence})`\n      ]\n    };\n  }\n  \n  private extractMLFeatures(\n    query: string,\n    structural: StructuralAnalysis,\n    pattern: PatternAnalysis\n  ): QueryFeatures {\n    return {\n      // Basic features\n      queryLength: query.length,\n      wordCount: query.split(/\\s+/).length,\n      \n      // Structural features\n      tableCount: structural.details.tableCount,\n      joinCount: structural.details.joinCount,\n      subqueryDepth: structural.details.subqueryDepth,\n      aggregationCount: structural.details.aggregationCount,\n      windowFunctionCount: structural.details.windowFunctionCount,\n      \n      // Pattern features\n      patternMatches: pattern.matches.length,\n      hasVector: pattern.matches.some(m => m.pattern === 'vector'),\n      hasComplexJoins: pattern.matches.some(m => m.pattern === 'multiJoin'),\n      \n      // Lexical features\n      keywordDensity: this.calculateKeywordDensity(query),\n      operatorComplexity: this.calculateOperatorComplexity(query),\n      \n      // Historical features (if available)\n      historicalPerformance: this.getHistoricalPerformance(query),\n      executionFrequency: this.getExecutionFrequency(query)\n    };\n  }\n  \n  async updateMLModel(): Promise\u003Cvoid> {\n    try {\n      // Collect recent query performance data\n      const performanceData = await this.collectPerformanceData(30); // Last 30 days\n      \n      // Prepare training data\n      const trainingData = this.prepareTrainingData(performanceData);\n      \n      // Train/update model\n      await this.mlModel.updateWithNewData(trainingData);\n      \n      // Validate model performance\n      const validation = await this.validateModel();\n      \n      if (validation.accuracy > 0.85) {\n        logger.info('Query classification model updated successfully', {\n          accuracy: validation.accuracy,\n          sampleCount: trainingData.length\n        });\n      } else {\n        logger.warn('New model accuracy below threshold, keeping existing model', {\n          accuracy: validation.accuracy\n        });\n      }\n      \n    } catch (error) {\n      logger.error('Failed to update ML model:', error);\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Performance Optimization\">\n```typescript\n// Advanced performance optimization and adaptive routing\nexport class QueryPerformanceOptimizer {\n  private performanceHistory = new Map\u003Cstring, PerformanceHistory>();\n  private poolMetrics = {\n    transaction: new PoolMetrics(),\n    session: new PoolMetrics()\n  };\n  \n  async optimizeRouting(): Promise\u003COptimizationResult> {\n    const currentMetrics = await this.gatherCurrentMetrics();\n    const historicalTrends = await this.analyzeHistoricalTrends();\n    \n    const optimizations = [];\n    \n    // Analyze pool utilization\n    if (currentMetrics.transaction.utilization > 0.8) {\n      optimizations.push({\n        type: 'load_balancing',\n        recommendation: 'Consider routing medium complexity queries to session pool',\n        impact: 'high',\n        implementation: this.createLoadBalancingStrategy()\n      });\n    }\n    \n    // Analyze query patterns\n    const slowQueries = this.identifySlowQueries(historicalTrends);\n    for (const slowQuery of slowQueries) {\n      if (slowQuery.currentPool === 'transaction' && slowQuery.avgDuration > 100) {\n        optimizations.push({\n          type: 'pool_migration',\n          query: slowQuery.pattern,\n          recommendation: 'Move to session pool for better resource allocation',\n          impact: 'medium',\n          implementation: this.createPoolMigrationRule(slowQuery)\n        });\n      }\n    }\n    \n    // Connection pool sizing recommendations\n    const sizingRecommendations = await this.analyzePoolSizing(currentMetrics);\n    optimizations.push(...sizingRecommendations);\n    \n    return {\n      optimizations,\n      currentPerformance: currentMetrics,\n      projectedImprovement: this.calculateProjectedImprovement(optimizations),\n      implementationPlan: this.createImplementationPlan(optimizations)\n    };\n  }\n  \n  private async analyzePoolSizing(metrics: SystemMetrics): Promise\u003COptimization[]> {\n    const optimizations: Optimization[] = [];\n    \n    // Transaction pool analysis\n    const transactionStats = metrics.transaction;\n    if (transactionStats.queueTime > 50) { // 50ms queue time\n      const recommendedSize = this.calculateOptimalPoolSize(\n        transactionStats.currentSize,\n        transactionStats.utilization,\n        transactionStats.queueTime\n      );\n      \n      if (recommendedSize > transactionStats.currentSize) {\n        optimizations.push({\n          type: 'pool_resize',\n          pool: 'transaction',\n          currentSize: transactionStats.currentSize,\n          recommendedSize,\n          reasoning: 'High queue times indicate connection pressure',\n          impact: 'high'\n        });\n      }\n    }\n    \n    // Session pool analysis\n    const sessionStats = metrics.session;\n    if (sessionStats.utilization \u003C 0.3 && sessionStats.currentSize > 3) {\n      optimizations.push({\n        type: 'pool_resize',\n        pool: 'session',\n        currentSize: sessionStats.currentSize,\n        recommendedSize: Math.max(3, Math.floor(sessionStats.currentSize * 0.8)),\n        reasoning: 'Low utilization suggests over-provisioning',\n        impact: 'low'\n      });\n    }\n    \n    return optimizations;\n  }\n  \n  async createAdaptiveRoutingRules(): Promise\u003CRoutingRule[]> {\n    const rules: RoutingRule[] = [];\n    \n    // Time-based routing (adjust for different load patterns)\n    rules.push({\n      id: 'peak_hours_routing',\n      condition: (context) => {\n        const hour = new Date().getHours();\n        return hour >= 9 && hour \u003C= 17; // Business hours\n      },\n      action: (analysis) => {\n        // More conservative routing during peak hours\n        if (analysis.complexity === QueryComplexity.MEDIUM) {\n          return analysis.resourceRequirements.memoryEstimate > 25 \n            ? 'session' \n            : 'transaction';\n        }\n        return analysis.complexity === QueryComplexity.SIMPLE \n          ? 'transaction' \n          : 'session';\n      },\n      priority: 10\n    });\n    \n    // Load-based routing\n    rules.push({\n      id: 'load_balancing_routing',\n      condition: (context) => {\n        return context.transactionPoolLoad > 0.7;\n      },\n      action: (analysis) => {\n        // Route medium queries to session pool when transaction pool is busy\n        if (analysis.complexity === QueryComplexity.MEDIUM) {\n          return 'session';\n        }\n        return analysis.complexity === QueryComplexity.SIMPLE \n          ? 'transaction' \n          : 'session';\n      },\n      priority: 20\n    });\n    \n    // Performance-based routing (learned from history)\n    const performancePatterns = await this.identifyPerformancePatterns();\n    for (const pattern of performancePatterns) {\n      rules.push({\n        id: `performance_${pattern.id}`,\n        condition: (context) => pattern.matcher(context.query),\n        action: () => pattern.optimalPool,\n        priority: 30,\n        learned: true,\n        performance: pattern.performanceData\n      });\n    }\n    \n    return rules.sort((a, b) => b.priority - a.priority);\n  }\n  \n  async monitorAndAdjust(): Promise\u003Cvoid> {\n    // Continuous monitoring loop\n    setInterval(async () => {\n      try {\n        const metrics = await this.gatherCurrentMetrics();\n        \n        // Check for performance degradation\n        if (metrics.overall.avgResponseTime > this.thresholds.responseTime) {\n          await this.handlePerformanceDegradation(metrics);\n        }\n        \n        // Check for pool imbalances\n        if (Math.abs(metrics.transaction.utilization - metrics.session.utilization) > 0.4) {\n          await this.handlePoolImbalance(metrics);\n        }\n        \n        // Update routing rules based on performance\n        await this.updateRoutingRules(metrics);\n        \n      } catch (error) {\n        logger.error('Query routing monitoring failed:', error);\n      }\n    }, 60000); // Every minute\n  }\n  \n  private async handlePerformanceDegradation(metrics: SystemMetrics): Promise\u003Cvoid> {\n    logger.warn('Performance degradation detected', {\n      avgResponseTime: metrics.overall.avgResponseTime,\n      threshold: this.thresholds.responseTime\n    });\n    \n    // Immediate actions\n    const actions = [];\n    \n    // Identify bottlenecks\n    if (metrics.transaction.queueTime > 100) {\n      actions.push('increase_transaction_pool_size');\n    }\n    \n    if (metrics.session.utilization > 0.9) {\n      actions.push('route_medium_queries_to_transaction');\n    }\n    \n    // Execute emergency optimizations\n    for (const action of actions) {\n      await this.executeEmergencyOptimization(action);\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Pool Management & Monitoring\n\nAdvanced pool management ensures optimal resource utilization and performance:\n\n\u003CTabs>\n  \u003CTabItem label=\"Pool Configuration\">\n```typescript\nexport interface PoolConfiguration {\n  name: string;\n  host: string;\n  port: number;\n  database: string;\n  user: string;\n  password: string;\n  \n  // Pool settings\n  minConnections: number;\n  maxConnections: number;\n  acquireTimeoutMs: number;\n  idleTimeoutMs: number;\n  \n  // Performance settings\n  connectionTimeoutMs: number;\n  queryTimeoutMs: number;\n  statementTimeoutMs: number;\n  \n  // Monitoring\n  monitoringEnabled: boolean;\n  metricsCollectionInterval: number;\n}\n\nexport class DatabasePoolManager {\n  private pools = new Map\u003Cstring, DatabasePool>();\n  private configurations = new Map\u003Cstring, PoolConfiguration>();\n  private healthMonitor: PoolHealthMonitor;\n  \n  constructor() {\n    this.healthMonitor = new PoolHealthMonitor();\n    this.initializePools();\n  }\n  \n  private initializePools(): void {\n    // Transaction Pool Configuration\n    const transactionConfig: PoolConfiguration = {\n      name: 'transaction',\n      host: process.env.POSTGRES_HOST || 'localhost',\n      port: parseInt(process.env.SUPABASE_TRANSACTION_PORT || '6543'),\n      database: process.env.POSTGRES_DB || 'nubi',\n      user: process.env.POSTGRES_USER || 'postgres',\n      password: process.env.POSTGRES_PASSWORD || '',\n      \n      minConnections: 5,\n      maxConnections: 15,\n      acquireTimeoutMs: 30000,\n      idleTimeoutMs: 300000, // 5 minutes\n      \n      connectionTimeoutMs: 10000,\n      queryTimeoutMs: 30000,\n      statementTimeoutMs: 60000,\n      \n      monitoringEnabled: true,\n      metricsCollectionInterval: 10000 // 10 seconds\n    };\n    \n    // Session Pool Configuration  \n    const sessionConfig: PoolConfiguration = {\n      name: 'session',\n      host: process.env.POSTGRES_HOST || 'localhost',\n      port: parseInt(process.env.SUPABASE_SESSION_PORT || '5432'),\n      database: process.env.POSTGRES_DB || 'nubi',\n      user: process.env.POSTGRES_USER || 'postgres',\n      password: process.env.POSTGRES_PASSWORD || '',\n      \n      minConnections: 2,\n      maxConnections: 5,\n      acquireTimeoutMs: 60000, // Longer timeout for complex queries\n      idleTimeoutMs: 600000,   // 10 minutes\n      \n      connectionTimeoutMs: 15000,\n      queryTimeoutMs: 300000,  // 5 minutes for complex queries\n      statementTimeoutMs: 600000, // 10 minutes\n      \n      monitoringEnabled: true,\n      metricsCollectionInterval: 10000\n    };\n    \n    // Create pools\n    this.createPool('transaction', transactionConfig);\n    this.createPool('session', sessionConfig);\n    \n    // Start health monitoring\n    this.startHealthMonitoring();\n  }\n  \n  private createPool(name: string, config: PoolConfiguration): void {\n    const pool = new DatabasePool(config);\n    \n    // Setup event handlers\n    pool.on('connect', (client) => {\n      logger.debug(`New connection established in ${name} pool`);\n      this.healthMonitor.recordConnection(name, 'connect');\n    });\n    \n    pool.on('error', (error, client) => {\n      logger.error(`Pool ${name} error:`, error);\n      this.healthMonitor.recordError(name, error);\n    });\n    \n    pool.on('acquire', (client) => {\n      this.healthMonitor.recordAcquisition(name);\n    });\n    \n    pool.on('release', (client) => {\n      this.healthMonitor.recordRelease(name);\n    });\n    \n    this.pools.set(name, pool);\n    this.configurations.set(name, config);\n  }\n  \n  async getPoolMetrics(poolName: string): Promise\u003CPoolMetrics> {\n    const pool = this.pools.get(poolName);\n    if (!pool) {\n      throw new Error(`Pool ${poolName} not found`);\n    }\n    \n    const baseMetrics = await pool.getMetrics();\n    const healthMetrics = await this.healthMonitor.getMetrics(poolName);\n    \n    return {\n      ...baseMetrics,\n      ...healthMetrics,\n      \n      // Calculated metrics\n      utilizationPercent: (baseMetrics.activeConnections / baseMetrics.maxConnections) * 100,\n      efficiencyScore: this.calculateEfficiencyScore(baseMetrics, healthMetrics),\n      healthScore: this.calculateHealthScore(healthMetrics),\n      \n      // Performance indicators\n      avgResponseTime: healthMetrics.avgResponseTime,\n      p95ResponseTime: healthMetrics.p95ResponseTime,\n      errorRate: healthMetrics.errorRate,\n      throughput: healthMetrics.throughput\n    };\n  }\n  \n  private calculateEfficiencyScore(\n    baseMetrics: BasePoolMetrics, \n    healthMetrics: HealthMetrics\n  ): number {\n    // Efficiency based on utilization, response time, and error rate\n    const utilizationScore = Math.min(baseMetrics.activeConnections / baseMetrics.maxConnections, 1);\n    const responseTimeScore = Math.max(0, 1 - (healthMetrics.avgResponseTime - 50) / 200);\n    const errorScore = Math.max(0, 1 - healthMetrics.errorRate);\n    \n    return (utilizationScore * 0.4 + responseTimeScore * 0.4 + errorScore * 0.2);\n  }\n  \n  async optimizePools(): Promise\u003COptimizationReport> {\n    const optimizations: PoolOptimization[] = [];\n    \n    for (const [poolName, pool] of this.pools) {\n      const metrics = await this.getPoolMetrics(poolName);\n      const config = this.configurations.get(poolName)!;\n      \n      // Check for optimization opportunities\n      if (metrics.utilizationPercent > 80 && metrics.queueTime > 50) {\n        optimizations.push({\n          pool: poolName,\n          type: 'increase_connections',\n          currentValue: config.maxConnections,\n          recommendedValue: Math.min(config.maxConnections + 5, 25),\n          reason: 'High utilization and queue times',\n          impact: 'high'\n        });\n      }\n      \n      if (metrics.utilizationPercent \u003C 20 && config.minConnections > 2) {\n        optimizations.push({\n          pool: poolName,\n          type: 'decrease_min_connections',\n          currentValue: config.minConnections,\n          recommendedValue: Math.max(2, config.minConnections - 2),\n          reason: 'Low utilization suggests over-provisioning',\n          impact: 'low'\n        });\n      }\n      \n      if (metrics.errorRate > 0.05) {\n        optimizations.push({\n          pool: poolName,\n          type: 'investigate_errors',\n          currentValue: metrics.errorRate,\n          recommendedValue: 0.01,\n          reason: 'Error rate above acceptable threshold',\n          impact: 'critical'\n        });\n      }\n    }\n    \n    return {\n      timestamp: new Date(),\n      optimizations,\n      currentPerformance: await this.getAllPoolMetrics(),\n      recommendations: this.generateRecommendations(optimizations)\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Health Monitoring\">\n```typescript\nexport class PoolHealthMonitor {\n  private metrics = new Map\u003Cstring, PoolHealthMetrics>();\n  private alertHandlers: AlertHandler[] = [];\n  \n  async recordConnection(poolName: string, event: 'connect' | 'disconnect'): Promise\u003Cvoid> {\n    const metrics = this.getOrCreateMetrics(poolName);\n    \n    if (event === 'connect') {\n      metrics.totalConnections++;\n      metrics.currentConnections++;\n    } else {\n      metrics.currentConnections = Math.max(0, metrics.currentConnections - 1);\n    }\n    \n    await this.updateMetrics(poolName, metrics);\n  }\n  \n  async recordQuery(\n    poolName: string, \n    duration: number, \n    success: boolean\n  ): Promise\u003Cvoid> {\n    const metrics = this.getOrCreateMetrics(poolName);\n    \n    metrics.totalQueries++;\n    metrics.queryDurations.push(duration);\n    \n    if (success) {\n      metrics.successfulQueries++;\n    } else {\n      metrics.failedQueries++;\n    }\n    \n    // Keep only recent durations (sliding window)\n    if (metrics.queryDurations.length > 1000) {\n      metrics.queryDurations = metrics.queryDurations.slice(-1000);\n    }\n    \n    // Update calculated metrics\n    metrics.avgResponseTime = metrics.queryDurations.reduce((a, b) => a + b, 0) / metrics.queryDurations.length;\n    metrics.p95ResponseTime = this.calculatePercentile(metrics.queryDurations, 95);\n    metrics.errorRate = metrics.failedQueries / metrics.totalQueries;\n    metrics.throughput = metrics.totalQueries / ((Date.now() - metrics.startTime) / 1000);\n    \n    await this.updateMetrics(poolName, metrics);\n    await this.checkAlerts(poolName, metrics);\n  }\n  \n  private async checkAlerts(poolName: string, metrics: PoolHealthMetrics): Promise\u003Cvoid> {\n    const alerts: HealthAlert[] = [];\n    \n    // High response time alert\n    if (metrics.avgResponseTime > 200) {\n      alerts.push({\n        type: 'high_response_time',\n        severity: 'warning',\n        pool: poolName,\n        message: `Average response time (${metrics.avgResponseTime}ms) exceeds threshold`,\n        value: metrics.avgResponseTime,\n        threshold: 200\n      });\n    }\n    \n    // High error rate alert\n    if (metrics.errorRate > 0.1) {\n      alerts.push({\n        type: 'high_error_rate',\n        severity: 'critical',\n        pool: poolName,\n        message: `Error rate (${(metrics.errorRate * 100).toFixed(2)}%) exceeds threshold`,\n        value: metrics.errorRate,\n        threshold: 0.1\n      });\n    }\n    \n    // Low throughput alert\n    if (metrics.throughput \u003C 1 && metrics.totalQueries > 100) {\n      alerts.push({\n        type: 'low_throughput',\n        severity: 'warning', \n        pool: poolName,\n        message: `Throughput (${metrics.throughput.toFixed(2)} q/s) below expected`,\n        value: metrics.throughput,\n        threshold: 1\n      });\n    }\n    \n    // Connection pool exhaustion warning\n    const config = await this.getPoolConfig(poolName);\n    if (metrics.currentConnections / config.maxConnections > 0.9) {\n      alerts.push({\n        type: 'pool_exhaustion',\n        severity: 'critical',\n        pool: poolName,\n        message: `Pool utilization (${(metrics.currentConnections / config.maxConnections * 100).toFixed(1)}%) near maximum`,\n        value: metrics.currentConnections / config.maxConnections,\n        threshold: 0.9\n      });\n    }\n    \n    // Trigger alert handlers\n    for (const alert of alerts) {\n      await this.triggerAlert(alert);\n    }\n  }\n  \n  async generateHealthReport(): Promise\u003CHealthReport> {\n    const poolReports = new Map\u003Cstring, PoolHealthReport>();\n    \n    for (const [poolName, metrics] of this.metrics) {\n      const config = await this.getPoolConfig(poolName);\n      \n      poolReports.set(poolName, {\n        poolName,\n        status: this.calculatePoolStatus(metrics, config),\n        metrics: {\n          ...metrics,\n          utilizationPercent: (metrics.currentConnections / config.maxConnections) * 100\n        },\n        recommendations: await this.generatePoolRecommendations(poolName, metrics, config),\n        alerts: await this.getActiveAlerts(poolName)\n      });\n    }\n    \n    const overallHealth = this.calculateOverallHealth(poolReports);\n    \n    return {\n      timestamp: new Date(),\n      overallHealth,\n      poolReports,\n      systemMetrics: await this.getSystemMetrics(),\n      trendAnalysis: await this.analyzeTrends(),\n      recommendations: await this.generateSystemRecommendations(poolReports)\n    };\n  }\n  \n  private calculatePoolStatus(\n    metrics: PoolHealthMetrics, \n    config: PoolConfiguration\n  ): PoolStatus {\n    const utilizationPercent = (metrics.currentConnections / config.maxConnections) * 100;\n    \n    // Critical conditions\n    if (metrics.errorRate > 0.2 || utilizationPercent > 95) {\n      return 'critical';\n    }\n    \n    // Warning conditions  \n    if (metrics.errorRate > 0.05 || utilizationPercent > 80 || metrics.avgResponseTime > 500) {\n      return 'warning';\n    }\n    \n    // Degraded conditions\n    if (metrics.errorRate > 0.01 || utilizationPercent > 60 || metrics.avgResponseTime > 200) {\n      return 'degraded';\n    }\n    \n    return 'healthy';\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🚀 Performance Benchmarks\n\nNUBI's query routing system delivers exceptional performance across different query types:\n\n\u003Cdiv class=\"benchmark-showcase\">\n  \u003Cdiv class=\"benchmark-grid\">\n    \u003Cdiv class=\"benchmark-item simple-queries\">\n      \u003Ch3>🚀 Simple CRUD Queries\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">35ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Response Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">1,200+\u003C/span>\n          \u003Cspan class=\"stat-label\">Queries/Second\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.9%\u003C/span>\n          \u003Cspan class=\"stat-label\">Success Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"benchmark-item complex-queries\">\n      \u003Ch3>🧠 Complex Analytical Queries\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">150ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Response Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">200+\u003C/span>\n          \u003Cspan class=\"stat-label\">Queries/Second\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.7%\u003C/span>\n          \u003Cspan class=\"stat-label\">Success Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"benchmark-item vector-queries\">\n      \u003Ch3>🔍 Vector Similarity Searches\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">220ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Response Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">50+\u003C/span>\n          \u003Cspan class=\"stat-label\">Queries/Second\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.5%\u003C/span>\n          \u003Cspan class=\"stat-label\">Success Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n\n  \u003C/div>\n\u003C/div>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🎯 Routing Benefits:\u003C/strong> This intelligent query routing system\n  ensures optimal performance by automatically selecting the best database pool\n  for each operation, delivering consistent sub-100ms response times for simple\n  queries while efficiently handling complex analytics.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Next**: Explore the [Memory Service](/database/memory-service/) to\n  understand how NUBI manages semantic search and intelligent memory\n  consolidation.\n\u003C/Aside>","src/content/docs/database/query-routing.mdx","5d444a2553197c95","database/query-routing.mdx","database/memory-service",{"id":162,"data":164,"body":170,"filePath":171,"digest":172,"legacyId":173,"deferredRender":16},{"title":165,"description":166,"editUrl":16,"head":167,"template":47,"sidebar":168,"pagefind":16,"draft":35},"Database Memory Service","Comprehensive guide to NUBI's DatabaseMemoryService with semantic search, vector embeddings, intelligent memory consolidation, and contextual retrieval capabilities.",[],{"hidden":35,"attrs":169},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Database Memory Service\n\nNUBI's **DatabaseMemoryService** implements a sophisticated memory management system that combines semantic search, vector embeddings, and intelligent consolidation to provide contextually relevant information for AI responses.\n\n## 🧠 Memory Architecture\n\nThe memory service employs a multi-layered approach to store, retrieve, and consolidate conversational and contextual memories:\n\n```mermaid\ngraph TB\n    A[Memory Input] --> B[Memory Classification]\n    B --> C[Embedding Generation]\n    C --> D[Storage Layer]\n\n    D --> E[Vector Store]\n    D --> F[Relational Store]\n    D --> G[Cache Layer]\n\n    H[Memory Query] --> I[Query Analysis]\n    I --> J[Semantic Search]\n    I --> K[Contextual Filter]\n    I --> L[Temporal Filter]\n\n    J --> M[Vector Similarity]\n    K --> N[Metadata Matching]\n    L --> O[Time-based Ranking]\n\n    M --> P[Result Fusion]\n    N --> P\n    O --> P\n\n    P --> Q[Relevance Scoring]\n    Q --> R[Context Assembly]\n\n    R --> S[Memory Consolidation]\n    S --> T[Knowledge Extraction]\n    T --> U[Insight Generation]\n```\n\n\u003CCardGrid>\n  \u003CCard title=\"🔍 Semantic Search\" icon=\"search\">\n    **Vector similarity search** with BGE embeddings providing contextually relevant memory retrieval across conversation history.\n  \u003C/Card>\n\n\u003CCard title=\"📊 Intelligent Storage\" icon=\"setting\">\n  **Multi-modal memory types** including conversational, personality, knowledge,\n  and relationship memories with automatic classification.\n\u003C/Card>\n\n\u003CCard title=\"🧮 Memory Consolidation\" icon=\"approve-check\">\n  **Automated consolidation** that identifies related memories and creates\n  higher-level insights to prevent memory fragmentation.\n\u003C/Card>\n\n  \u003CCard title=\"⚡ Performance Optimized\" icon=\"rocket\">\n    **Sub-100ms retrieval** with intelligent caching, query optimization, and parallel processing for real-time responsiveness.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 💾 Memory Types & Classification\n\nThe service manages six distinct memory types, each optimized for specific use cases:\n\n\u003CTabs>\n  \u003CTabItem label=\"Memory Types\">\n```typescript\nexport enum MemoryType {\n  CONVERSATION = 'conversation',\n  PERSONALITY = 'personality', \n  KNOWLEDGE = 'knowledge',\n  PREFERENCE = 'preference',\n  RELATIONSHIP = 'relationship',\n  EMOTIONAL = 'emotional'\n}\n\nexport interface MemoryEntry {\n  id: string;\n  type: MemoryType;\n  content: string;\n  userId: string;\n  roomId: string;\n  platform: string;\n  \n  // Vector embeddings for semantic search\n  embedding?: number[];\n  \n  // Metadata for contextual retrieval\n  metadata: MemoryMetadata;\n  \n  // Relevance and access tracking\n  importance: number;        // 0-1 relevance score\n  accessed_count: number;\n  last_accessed: Date;\n  \n  // Temporal information\n  created_at: Date;\n  expires_at?: Date;\n  \n  // Relationships to other memories\n  parent_memory_id?: string;\n  child_memory_ids: string[];\n  related_memory_ids: string[];\n}\n\nexport interface MemoryMetadata {\n  // Context information\n  emotional_context?: EmotionalContext;\n  conversation_context?: ConversationContext;\n  user_context?: UserContext;\n  \n  // Classification metadata\n  topics: string[];\n  entities: string[];\n  sentiment: 'positive' | 'negative' | 'neutral';\n  \n  // Platform-specific metadata\n  platform_data: Record\u003Cstring, any>;\n  \n  // Memory consolidation metadata\n  consolidation_level: number;  // 0 = raw, higher = more consolidated\n  source_memory_count?: number; // For consolidated memories\n}\n\nexport class MemoryClassifier {\n  async classifyMemory(content: string, context: MemoryContext): Promise\u003CMemoryType> {\n    // Personality-related memories\n    if (this.isPersonalityMemory(content, context)) {\n      return MemoryType.PERSONALITY;\n    }\n    \n    // Knowledge and factual information\n    if (this.isKnowledgeMemory(content, context)) {\n      return MemoryType.KNOWLEDGE;\n    }\n    \n    // User preferences and choices\n    if (this.isPreferenceMemory(content, context)) {\n      return MemoryType.PREFERENCE;\n    }\n    \n    // Relationship and social context\n    if (this.isRelationshipMemory(content, context)) {\n      return MemoryType.RELATIONSHIP;\n    }\n    \n    // Emotional expressions and states\n    if (this.isEmotionalMemory(content, context)) {\n      return MemoryType.EMOTIONAL;\n    }\n    \n    // Default to conversation memory\n    return MemoryType.CONVERSATION;\n  }\n  \n  private isPersonalityMemory(content: string, context: MemoryContext): boolean {\n    const personalityIndicators = [\n      /personality|trait|characteristic/gi,\n      /humor|funny|joke|wit/gi,\n      /analytical|logic|reasoning/gi,\n      /empathy|compassion|understanding/gi,\n      /wisdom|insight|knowledge/gi\n    ];\n    \n    return personalityIndicators.some(pattern => pattern.test(content));\n  }\n  \n  private isKnowledgeMemory(content: string, context: MemoryContext): boolean {\n    const knowledgeIndicators = [\n      /what is|define|explain|how to/gi,\n      /fact|information|data|statistic/gi,\n      /concept|theory|principle|rule/gi,\n      /\\b(SOL|BTC|ETH|crypto|blockchain|DeFi)\\b/gi\n    ];\n    \n    return knowledgeIndicators.some(pattern => pattern.test(content));\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Embedding Generation\">\n```typescript\nexport class VectorEmbeddingService {\n  private model: BGEModel;\n  private embeddingCache = new LRUCache\u003Cstring, number[]>({ max: 10000 });\n  \n  constructor() {\n    this.model = new BGEModel({\n      modelName: 'BAAI/bge-small-en-v1.5',\n      dimensions: 384,\n      maxLength: 512\n    });\n  }\n  \n  async generateEmbedding(text: string): Promise\u003Cnumber[]> {\n    // Normalize text for consistent embeddings\n    const normalizedText = this.normalizeText(text);\n    \n    // Check cache first\n    const cacheKey = this.hashText(normalizedText);\n    const cached = this.embeddingCache.get(cacheKey);\n    if (cached) {\n      return cached;\n    }\n    \n    // Generate embedding\n    const embedding = await this.model.encode(normalizedText);\n    \n    // Cache result\n    this.embeddingCache.set(cacheKey, embedding);\n    \n    return embedding;\n  }\n  \n  async batchGenerateEmbeddings(texts: string[]): Promise\u003Cnumber[][]> {\n    // Process in batches to optimize GPU utilization\n    const batchSize = 32;\n    const results: number[][] = [];\n    \n    for (let i = 0; i \u003C texts.length; i += batchSize) {\n      const batch = texts.slice(i, i + batchSize);\n      const batchEmbeddings = await Promise.all(\n        batch.map(text => this.generateEmbedding(text))\n      );\n      results.push(...batchEmbeddings);\n    }\n    \n    return results;\n  }\n  \n  calculateSimilarity(embedding1: number[], embedding2: number[]): number {\n    return this.cosineSimilarity(embedding1, embedding2);\n  }\n  \n  private cosineSimilarity(a: number[], b: number[]): number {\n    let dotProduct = 0;\n    let normA = 0;\n    let normB = 0;\n    \n    for (let i = 0; i \u003C a.length; i++) {\n      dotProduct += a[i] * b[i];\n      normA += a[i] * a[i];\n      normB += b[i] * b[i];\n    }\n    \n    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\n  }\n  \n  private normalizeText(text: string): string {\n    return text\n      .toLowerCase()\n      .replace(/\\s+/g, ' ')\n      .replace(/[^\\w\\s]/g, '')\n      .trim()\n      .substring(0, 500); // Limit length for consistent processing\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Storage Implementation\">\n```typescript\nexport class DatabaseMemoryService implements NubiService {\n  serviceType = \"database-memory\";\n  capabilityDescription = \"Advanced memory management with semantic search\";\n  \n  private connectionManager: DatabaseConnectionManager;\n  private vectorService: VectorEmbeddingService;\n  private classifier: MemoryClassifier;\n  private consolidator: MemoryConsolidator;\n  private memoryCache = new LRUCache\u003Cstring, MemoryEntry>({ max: 5000 });\n  \n  constructor(\n    connectionManager: DatabaseConnectionManager,\n    vectorService: VectorEmbeddingService\n  ) {\n    this.connectionManager = connectionManager;\n    this.vectorService = vectorService;\n    this.classifier = new MemoryClassifier();\n    this.consolidator = new MemoryConsolidator();\n  }\n  \n  async storeMemory(\n    content: string,\n    type: MemoryType,\n    context: MemoryContext\n  ): Promise\u003Cstring> {\n    const startTime = Date.now();\n    \n    // Generate embedding for semantic search\n    const embedding = await this.vectorService.generateEmbedding(content);\n    \n    // Calculate importance score\n    const importance = await this.calculateImportance(content, type, context);\n    \n    // Extract metadata\n    const metadata = await this.extractMetadata(content, context);\n    \n    // Create memory entry\n    const memoryEntry: MemoryEntry = {\n      id: crypto.randomUUID(),\n      type,\n      content,\n      userId: context.userId,\n      roomId: context.roomId,\n      platform: context.platform,\n      embedding,\n      metadata,\n      importance,\n      accessed_count: 0,\n      last_accessed: new Date(),\n      created_at: new Date(),\n      child_memory_ids: [],\n      related_memory_ids: []\n    };\n    \n    // Store in database\n    await this.insertMemoryToDatabase(memoryEntry);\n    \n    // Cache for quick access\n    this.memoryCache.set(memoryEntry.id, memoryEntry);\n    \n    // Trigger background consolidation if needed\n    this.scheduleConsolidation(context.userId, type);\n    \n    const duration = Date.now() - startTime;\n    logger.debug(`Memory stored: ${memoryEntry.id} (${duration}ms)`);\n    \n    return memoryEntry.id;\n  }\n  \n  private async insertMemoryToDatabase(memory: MemoryEntry): Promise\u003Cvoid> {\n    const query = `\n      INSERT INTO memories (\n        id, type, content, user_id, room_id, platform,\n        embedding, metadata, importance, accessed_count,\n        last_accessed, created_at\n      ) VALUES (\n        $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12\n      )\n    `;\n    \n    const params = [\n      memory.id,\n      memory.type,\n      memory.content,\n      memory.userId,\n      memory.roomId,\n      memory.platform,\n      JSON.stringify(memory.embedding),\n      JSON.stringify(memory.metadata),\n      memory.importance,\n      memory.accessed_count,\n      memory.last_accessed,\n      memory.created_at\n    ];\n    \n    await this.connectionManager.executeQuery(query, params);\n  }\n  \n  private async calculateImportance(\n    content: string,\n    type: MemoryType,\n    context: MemoryContext\n  ): Promise\u003Cnumber> {\n    let importance = 0.5; // Base importance\n    \n    // Type-based importance\n    const typeWeights = {\n      [MemoryType.PERSONALITY]: 0.9,\n      [MemoryType.KNOWLEDGE]: 0.8,\n      [MemoryType.PREFERENCE]: 0.7,\n      [MemoryType.RELATIONSHIP]: 0.7,\n      [MemoryType.EMOTIONAL]: 0.6,\n      [MemoryType.CONVERSATION]: 0.4\n    };\n    importance += typeWeights[type] || 0.5;\n    \n    // Content-based importance\n    const contentScore = await this.assessContentImportance(content);\n    importance += contentScore * 0.3;\n    \n    // Context-based importance\n    if (context.isFirstInteraction) importance += 0.2;\n    if (context.emotionalIntensity > 0.7) importance += 0.1;\n    if (context.mentionsOthers) importance += 0.1;\n    \n    // Normalize to [0, 1]\n    return Math.max(0, Math.min(1, importance / 2));\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔍 Semantic Search System\n\nAdvanced semantic search capabilities provide contextually relevant memory retrieval:\n\n\u003CTabs>\n  \u003CTabItem label=\"Search Implementation\">\n```typescript\nexport interface SearchOptions {\n  limit?: number;\n  threshold?: number;\n  types?: MemoryType[];\n  userId?: string;\n  timeRange?: TimeRange;\n  includeRelated?: boolean;\n  contextWeight?: number;\n}\n\nexport interface MemorySearchResult {\n  memory: MemoryEntry;\n  similarity: number;\n  relevance: number;\n  contextualScore: number;\n  ranking: number;\n}\n\nexport class SemanticSearchEngine {\n  private connectionManager: DatabaseConnectionManager;\n  private vectorService: VectorEmbeddingService;\n  private searchCache = new LRUCache\u003Cstring, MemorySearchResult[]>({ max: 1000 });\n  \n  async searchMemories(\n    query: string,\n    context: SearchContext,\n    options: SearchOptions = {}\n  ): Promise\u003CMemorySearchResult[]> {\n    const startTime = Date.now();\n    \n    // Check cache first\n    const cacheKey = this.generateSearchCacheKey(query, context, options);\n    const cached = this.searchCache.get(cacheKey);\n    if (cached && this.isCacheValid(cached)) {\n      return cached;\n    }\n    \n    // Generate query embedding\n    const queryEmbedding = await this.vectorService.generateEmbedding(query);\n    \n    // Build search parameters\n    const searchParams = this.buildSearchParameters(context, options);\n    \n    // Execute semantic search\n    const semanticResults = await this.performSemanticSearch(\n      queryEmbedding,\n      searchParams\n    );\n    \n    // Apply contextual filtering and scoring\n    const contextualResults = await this.applyContextualScoring(\n      semanticResults,\n      query,\n      context\n    );\n    \n    // Rank and limit results\n    const finalResults = this.rankAndLimitResults(contextualResults, options.limit || 10);\n    \n    // Cache results\n    this.searchCache.set(cacheKey, finalResults);\n    \n    const duration = Date.now() - startTime;\n    logger.debug(`Memory search completed: ${finalResults.length} results (${duration}ms)`);\n    \n    return finalResults;\n  }\n  \n  private async performSemanticSearch(\n    queryEmbedding: number[],\n    params: SearchParameters\n  ): Promise\u003CSemanticSearchResult[]> {\n    let sql = `\n      SELECT id, type, content, user_id, room_id, platform,\n             metadata, importance, accessed_count, created_at,\n             (embedding \u003C-> $1::vector) as distance\n      FROM memories \n      WHERE (embedding \u003C-> $1::vector) \u003C $2\n    `;\n    \n    const queryParams: any[] = [\n      JSON.stringify(queryEmbedding),\n      1 - (params.threshold || 0.7)\n    ];\n    let paramIndex = 2;\n    \n    // Apply filters\n    if (params.userId) {\n      sql += ` AND user_id = $${++paramIndex}`;\n      queryParams.push(params.userId);\n    }\n    \n    if (params.types && params.types.length > 0) {\n      sql += ` AND type = ANY($${++paramIndex})`;\n      queryParams.push(params.types);\n    }\n    \n    if (params.timeRange) {\n      sql += ` AND created_at >= $${++paramIndex}`;\n      queryParams.push(params.timeRange.start);\n      \n      if (params.timeRange.end) {\n        sql += ` AND created_at \u003C= $${++paramIndex}`;\n        queryParams.push(params.timeRange.end);\n      }\n    }\n    \n    // Order by similarity and importance\n    sql += `\n      ORDER BY \n        (embedding \u003C-> $1::vector) ASC,\n        importance DESC,\n        accessed_count DESC\n      LIMIT $${++paramIndex}\n    `;\n    queryParams.push(Math.min(params.limit || 50, 100));\n    \n    const result = await this.connectionManager.executeQuery(sql, queryParams);\n    \n    return result.rows.map(row => ({\n      memory: this.deserializeMemory(row),\n      distance: row.distance,\n      similarity: 1 - row.distance\n    }));\n  }\n  \n  private async applyContextualScoring(\n    results: SemanticSearchResult[],\n    query: string,\n    context: SearchContext\n  ): Promise\u003CMemorySearchResult[]> {\n    return Promise.all(results.map(async (result) => {\n      const contextualScore = await this.calculateContextualScore(\n        result.memory,\n        query,\n        context\n      );\n      \n      const relevance = this.calculateRelevanceScore(\n        result.similarity,\n        contextualScore,\n        result.memory.importance\n      );\n      \n      return {\n        memory: result.memory,\n        similarity: result.similarity,\n        relevance,\n        contextualScore,\n        ranking: 0 // Will be set during ranking\n      };\n    }));\n  }\n  \n  private async calculateContextualScore(\n    memory: MemoryEntry,\n    query: string,\n    context: SearchContext\n  ): Promise\u003Cnumber> {\n    let score = 0;\n    \n    // Temporal relevance (recent memories are more relevant)\n    const ageInDays = (Date.now() - memory.created_at.getTime()) / (24 * 60 * 60 * 1000);\n    const temporalScore = Math.exp(-ageInDays / 30); // Decay over 30 days\n    score += temporalScore * 0.3;\n    \n    // Platform context match\n    if (memory.platform === context.currentPlatform) {\n      score += 0.2;\n    }\n    \n    // Conversation context match\n    if (memory.roomId === context.currentRoomId) {\n      score += 0.2;\n    }\n    \n    // Topic similarity\n    const queryTopics = await this.extractTopics(query);\n    const memoryTopics = memory.metadata.topics || [];\n    const topicOverlap = this.calculateTopicOverlap(queryTopics, memoryTopics);\n    score += topicOverlap * 0.3;\n    \n    return Math.min(1, score);\n  }\n  \n  async performAdvancedSearch(\n    query: AdvancedQuery,\n    context: SearchContext\n  ): Promise\u003CAdvancedSearchResult> {\n    // Semantic search\n    const semanticResults = await this.searchMemories(\n      query.text,\n      context,\n      query.semanticOptions\n    );\n    \n    // Keyword search for exact matches\n    const keywordResults = await this.performKeywordSearch(\n      query.keywords,\n      context,\n      query.keywordOptions\n    );\n    \n    // Metadata-based search\n    const metadataResults = await this.performMetadataSearch(\n      query.metadata,\n      context,\n      query.metadataOptions\n    );\n    \n    // Fuse results with different weights\n    const fusedResults = await this.fuseSearchResults([\n      { results: semanticResults, weight: 0.5 },\n      { results: keywordResults, weight: 0.3 },\n      { results: metadataResults, weight: 0.2 }\n    ]);\n    \n    // Apply final ranking and clustering\n    const clusteredResults = await this.clusterResults(fusedResults);\n    \n    return {\n      results: fusedResults,\n      clusters: clusteredResults,\n      totalFound: fusedResults.length,\n      searchTime: Date.now() - context.startTime,\n      searchStrategy: this.determineSearchStrategy(query)\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Query Optimization\">\n```typescript\nexport class QueryOptimizer {\n  private queryPatterns = new Map\u003Cstring, QueryPattern>();\n  private performanceHistory = new Map\u003Cstring, QueryPerformance>();\n  \n  async optimizeQuery(\n    query: string,\n    context: SearchContext,\n    options: SearchOptions\n  ): Promise\u003COptimizedQuery> {\n    // Analyze query structure and patterns\n    const queryAnalysis = await this.analyzeQuery(query);\n    \n    // Check for known optimization patterns\n    const optimizationPattern = this.findOptimizationPattern(queryAnalysis);\n    \n    // Apply query transformations\n    const transformedQuery = await this.applyTransformations(\n      query,\n      optimizationPattern,\n      context\n    );\n    \n    // Optimize search parameters\n    const optimizedOptions = await this.optimizeSearchOptions(\n      options,\n      queryAnalysis,\n      context\n    );\n    \n    return {\n      originalQuery: query,\n      transformedQuery,\n      originalOptions: options,\n      optimizedOptions,\n      optimizations: optimizationPattern?.optimizations || [],\n      estimatedImprovement: optimizationPattern?.estimatedImprovement || 0\n    };\n  }\n  \n  private async analyzeQuery(query: string): Promise\u003CQueryAnalysis> {\n    return {\n      length: query.length,\n      wordCount: query.split(/\\s+/).length,\n      hasKeywords: this.detectKeywords(query),\n      hasEntities: await this.detectEntities(query),\n      complexity: this.calculateQueryComplexity(query),\n      expectedResultCount: await this.estimateResultCount(query),\n      searchType: this.determineSearchType(query)\n    };\n  }\n  \n  private async optimizeSearchOptions(\n    options: SearchOptions,\n    analysis: QueryAnalysis,\n    context: SearchContext\n  ): Promise\u003CSearchOptions> {\n    const optimized = { ...options };\n    \n    // Adjust threshold based on query complexity\n    if (analysis.complexity > 0.7) {\n      optimized.threshold = Math.max(0.6, (optimized.threshold || 0.7) - 0.1);\n    }\n    \n    // Adjust limit based on expected results\n    if (analysis.expectedResultCount > 100) {\n      optimized.limit = Math.min(50, optimized.limit || 10);\n    }\n    \n    // Add contextual filters for better performance\n    if (context.currentUserId && !optimized.userId) {\n      // For personalized queries, bias towards user's own memories\n      if (this.isPersonalQuery(analysis)) {\n        optimized.userId = context.currentUserId;\n      }\n    }\n    \n    // Optimize time range for temporal queries\n    if (this.isTemporalQuery(analysis) && !optimized.timeRange) {\n      optimized.timeRange = this.inferTimeRange(analysis);\n    }\n    \n    return optimized;\n  }\n  \n  async createQueryExecutionPlan(\n    optimizedQuery: OptimizedQuery,\n    context: SearchContext\n  ): Promise\u003CQueryExecutionPlan> {\n    const plan: QueryExecutionPlan = {\n      steps: [],\n      estimatedDuration: 0,\n      resourceRequirements: {\n        memory: 0,\n        cpu: 0,\n        io: 0\n      },\n      parallelizable: false\n    };\n    \n    // Step 1: Embedding generation\n    plan.steps.push({\n      name: 'embedding_generation',\n      type: 'compute',\n      estimatedDuration: 20,\n      dependencies: []\n    });\n    \n    // Step 2: Vector search\n    plan.steps.push({\n      name: 'vector_search',\n      type: 'database',\n      estimatedDuration: 50,\n      dependencies: ['embedding_generation']\n    });\n    \n    // Step 3: Contextual filtering (can be parallel with vector search)\n    plan.steps.push({\n      name: 'contextual_filtering',\n      type: 'compute',\n      estimatedDuration: 15,\n      dependencies: ['vector_search'],\n      parallelizable: true\n    });\n    \n    // Step 4: Result ranking and assembly\n    plan.steps.push({\n      name: 'result_ranking',\n      type: 'compute',\n      estimatedDuration: 10,\n      dependencies: ['contextual_filtering']\n    });\n    \n    plan.estimatedDuration = this.calculatePlanDuration(plan.steps);\n    plan.resourceRequirements = this.calculateResourceRequirements(plan.steps);\n    plan.parallelizable = plan.steps.some(step => step.parallelizable);\n    \n    return plan;\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 🔄 Memory Consolidation System\n\nIntelligent memory consolidation prevents fragmentation and creates higher-level insights:\n\n\u003CTabs>\n  \u003CTabItem label=\"Consolidation Engine\">\n```typescript\nexport interface ConsolidationConfig {\n  minMemoriesForConsolidation: number;\n  maxConsolidationLevel: number;\n  similarityThreshold: number;\n  temporalWindow: number; // milliseconds\n  consolidationFrequency: number; // milliseconds between runs\n}\n\nexport class MemoryConsolidator {\n  private config: ConsolidationConfig;\n  private consolidationQueue = new Map\u003Cstring, ConsolidationTask>();\n  \n  constructor(config?: Partial\u003CConsolidationConfig>) {\n    this.config = {\n      minMemoriesForConsolidation: 3,\n      maxConsolidationLevel: 5,\n      similarityThreshold: 0.8,\n      temporalWindow: 24 * 60 * 60 * 1000, // 24 hours\n      consolidationFrequency: 60 * 60 * 1000, // 1 hour\n      ...config\n    };\n  }\n  \n  async consolidateMemories(userId: string, type?: MemoryType): Promise\u003CConsolidationResult> {\n    const startTime = Date.now();\n    \n    // Find candidate memories for consolidation\n    const candidates = await this.findConsolidationCandidates(userId, type);\n    \n    if (candidates.length \u003C this.config.minMemoriesForConsolidation) {\n      return {\n        consolidatedCount: 0,\n        originalCount: candidates.length,\n        consolidatedMemories: [],\n        spaceSaved: 0,\n        processingTime: Date.now() - startTime\n      };\n    }\n    \n    // Group related memories\n    const memoryGroups = await this.groupRelatedMemories(candidates);\n    \n    // Consolidate each group\n    const consolidatedMemories: MemoryEntry[] = [];\n    let totalSpaceSaved = 0;\n    \n    for (const group of memoryGroups) {\n      if (group.memories.length >= this.config.minMemoriesForConsolidation) {\n        const consolidated = await this.consolidateMemoryGroup(group);\n        consolidatedMemories.push(consolidated);\n        \n        // Calculate space saved\n        const originalSize = group.memories.reduce(\n          (sum, mem) => sum + mem.content.length, 0\n        );\n        const consolidatedSize = consolidated.content.length;\n        totalSpaceSaved += Math.max(0, originalSize - consolidatedSize);\n        \n        // Mark original memories as consolidated\n        await this.markMemoriesAsConsolidated(group.memories, consolidated.id);\n      }\n    }\n    \n    return {\n      consolidatedCount: consolidatedMemories.length,\n      originalCount: candidates.length,\n      consolidatedMemories,\n      spaceSaved: totalSpaceSaved,\n      processingTime: Date.now() - startTime\n    };\n  }\n  \n  private async findConsolidationCandidates(\n    userId: string,\n    type?: MemoryType\n  ): Promise\u003CMemoryEntry[]> {\n    let sql = `\n      SELECT * FROM memories \n      WHERE user_id = $1\n        AND created_at >= $2\n        AND metadata->>'consolidation_level' IS NULL\n        OR CAST(metadata->>'consolidation_level' AS INTEGER) \u003C $3\n    `;\n    \n    const params = [\n      userId,\n      new Date(Date.now() - this.config.temporalWindow),\n      this.config.maxConsolidationLevel\n    ];\n    \n    if (type) {\n      sql += ` AND type = $${params.length + 1}`;\n      params.push(type);\n    }\n    \n    sql += ` ORDER BY created_at DESC LIMIT 100`;\n    \n    const result = await this.connectionManager.executeQuery(sql, params);\n    return result.rows.map(row => this.deserializeMemory(row));\n  }\n  \n  private async groupRelatedMemories(\n    memories: MemoryEntry[]\n  ): Promise\u003CMemoryGroup[]> {\n    const groups: MemoryGroup[] = [];\n    const processed = new Set\u003Cstring>();\n    \n    for (const memory of memories) {\n      if (processed.has(memory.id)) continue;\n      \n      // Find similar memories\n      const similarMemories = await this.findSimilarMemories(\n        memory,\n        memories.filter(m => !processed.has(m.id))\n      );\n      \n      if (similarMemories.length >= this.config.minMemoriesForConsolidation) {\n        const group: MemoryGroup = {\n          id: crypto.randomUUID(),\n          primaryMemory: memory,\n          memories: similarMemories,\n          averageSimilarity: this.calculateAverageSimilarity(similarMemories),\n          topics: this.extractGroupTopics(similarMemories),\n          timeSpan: this.calculateTimeSpan(similarMemories),\n          consolidationType: this.determineConsolidationType(similarMemories)\n        };\n        \n        groups.push(group);\n        \n        // Mark memories as processed\n        similarMemories.forEach(mem => processed.add(mem.id));\n      }\n    }\n    \n    return groups;\n  }\n  \n  private async consolidateMemoryGroup(group: MemoryGroup): Promise\u003CMemoryEntry> {\n    // Extract key information from all memories\n    const keyInformation = await this.extractKeyInformation(group.memories);\n    \n    // Generate consolidated content\n    const consolidatedContent = await this.generateConsolidatedContent(\n      keyInformation,\n      group\n    );\n    \n    // Calculate consolidated importance\n    const consolidatedImportance = this.calculateConsolidatedImportance(group.memories);\n    \n    // Create consolidated memory\n    const consolidatedMemory: MemoryEntry = {\n      id: crypto.randomUUID(),\n      type: group.primaryMemory.type,\n      content: consolidatedContent,\n      userId: group.primaryMemory.userId,\n      roomId: group.primaryMemory.roomId,\n      platform: group.primaryMemory.platform,\n      \n      // Use average embedding from group\n      embedding: await this.calculateAverageEmbedding(group.memories),\n      \n      metadata: {\n        ...group.primaryMemory.metadata,\n        consolidation_level: (group.primaryMemory.metadata.consolidation_level || 0) + 1,\n        source_memory_count: group.memories.length,\n        topics: group.topics,\n        consolidated_at: new Date()\n      },\n      \n      importance: consolidatedImportance,\n      accessed_count: 0,\n      last_accessed: new Date(),\n      created_at: new Date(),\n      child_memory_ids: group.memories.map(m => m.id),\n      related_memory_ids: []\n    };\n    \n    // Generate new embedding for consolidated content\n    consolidatedMemory.embedding = await this.vectorService.generateEmbedding(\n      consolidatedContent\n    );\n    \n    // Store consolidated memory\n    await this.storeConsolidatedMemory(consolidatedMemory);\n    \n    return consolidatedMemory;\n  }\n  \n  private async generateConsolidatedContent(\n    keyInformation: ExtractedInformation,\n    group: MemoryGroup\n  ): Promise\u003Cstring> {\n    // Use AI to generate coherent consolidated content\n    const prompt = this.buildConsolidationPrompt(keyInformation, group);\n    \n    // This would use your AI model to generate consolidated content\n    const consolidatedContent = await this.aiModel.generate({\n      prompt,\n      maxLength: 500,\n      temperature: 0.3 // Lower temperature for more consistent consolidation\n    });\n    \n    return consolidatedContent;\n  }\n  \n  private buildConsolidationPrompt(\n    keyInfo: ExtractedInformation,\n    group: MemoryGroup\n  ): string {\n    return `\n      Consolidate the following related memories into a coherent summary:\n      \n      Primary Topic: ${group.topics.join(', ')}\n      Memory Type: ${group.primaryMemory.type}\n      Time Span: ${this.formatTimeSpan(group.timeSpan)}\n      \n      Key Information:\n      ${keyInfo.facts.map(fact => `- ${fact}`).join('\\n')}\n      \n      Important Context:\n      ${keyInfo.context.map(ctx => `- ${ctx}`).join('\\n')}\n      \n      Generate a consolidated memory that captures the essential information\n      while being more concise than the original memories. Maintain the \n      original tone and perspective.\n    `;\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Background Processing\">\n```typescript\nexport class BackgroundConsolidationService {\n  private consolidator: MemoryConsolidator;\n  private scheduler: ConsolidationScheduler;\n  private isRunning = false;\n  \n  constructor(consolidator: MemoryConsolidator) {\n    this.consolidator = consolidator;\n    this.scheduler = new ConsolidationScheduler();\n  }\n  \n  startBackgroundConsolidation(): void {\n    if (this.isRunning) return;\n    \n    this.isRunning = true;\n    this.scheduleNextConsolidation();\n  }\n  \n  stopBackgroundConsolidation(): void {\n    this.isRunning = false;\n    this.scheduler.clear();\n  }\n  \n  private scheduleNextConsolidation(): void {\n    if (!this.isRunning) return;\n    \n    const nextRunTime = this.scheduler.getNextRunTime();\n    const delay = nextRunTime.getTime() - Date.now();\n    \n    setTimeout(async () => {\n      if (!this.isRunning) return;\n      \n      try {\n        await this.performScheduledConsolidation();\n      } catch (error) {\n        logger.error('Background consolidation failed:', error);\n      } finally {\n        this.scheduleNextConsolidation();\n      }\n    }, delay);\n  }\n  \n  private async performScheduledConsolidation(): Promise\u003Cvoid> {\n    logger.info('Starting scheduled memory consolidation');\n    \n    // Get active users who need consolidation\n    const activeUsers = await this.getActiveUsersForConsolidation();\n    \n    // Process users in batches to avoid overload\n    const batchSize = 5;\n    for (let i = 0; i \u003C activeUsers.length; i += batchSize) {\n      const batch = activeUsers.slice(i, i + batchSize);\n      \n      await Promise.all(batch.map(async (userId) => {\n        try {\n          const result = await this.consolidator.consolidateMemories(userId);\n          \n          if (result.consolidatedCount > 0) {\n            logger.info(`Consolidated ${result.consolidatedCount} memory groups for user ${userId}`);\n            \n            // Update consolidation statistics\n            await this.updateConsolidationStats(userId, result);\n          }\n        } catch (error) {\n          logger.error(`Consolidation failed for user ${userId}:`, error);\n        }\n      }));\n      \n      // Small delay between batches\n      await new Promise(resolve => setTimeout(resolve, 1000));\n    }\n  }\n  \n  private async getActiveUsersForConsolidation(): Promise\u003Cstring[]> {\n    // Get users who have had recent activity and haven't been consolidated recently\n    const query = `\n      SELECT DISTINCT user_id \n      FROM memories \n      WHERE created_at >= $1\n        AND (\n          metadata->>'last_consolidated' IS NULL \n          OR \n          TO_TIMESTAMP(metadata->>'last_consolidated', 'YYYY-MM-DD\"T\"HH24:MI:SS.MS\"Z\"') \u003C $2\n        )\n      ORDER BY user_id\n      LIMIT 100\n    `;\n    \n    const params = [\n      new Date(Date.now() - 24 * 60 * 60 * 1000), // Last 24 hours\n      new Date(Date.now() - 6 * 60 * 60 * 1000)   // Last 6 hours\n    ];\n    \n    const result = await this.connectionManager.executeQuery(query, params);\n    return result.rows.map(row => row.user_id);\n  }\n  \n  async consolidateForUser(userId: string, priority: 'high' | 'normal' | 'low' = 'normal'): Promise\u003Cvoid> {\n    const task: ConsolidationTask = {\n      userId,\n      priority,\n      scheduledAt: new Date(),\n      attempts: 0,\n      maxAttempts: 3\n    };\n    \n    if (priority === 'high') {\n      // Execute immediately for high priority\n      await this.executeConsolidationTask(task);\n    } else {\n      // Add to queue for normal/low priority\n      this.scheduler.addTask(task);\n    }\n  }\n  \n  private async executeConsolidationTask(task: ConsolidationTask): Promise\u003Cvoid> {\n    try {\n      task.attempts++;\n      \n      const result = await this.consolidator.consolidateMemories(task.userId);\n      \n      logger.info(`Consolidation completed for user ${task.userId}`, {\n        consolidatedCount: result.consolidatedCount,\n        originalCount: result.originalCount,\n        spaceSaved: result.spaceSaved,\n        processingTime: result.processingTime\n      });\n      \n    } catch (error) {\n      if (task.attempts \u003C task.maxAttempts) {\n        // Retry with exponential backoff\n        const delay = Math.pow(2, task.attempts) * 1000;\n        setTimeout(() => {\n          this.executeConsolidationTask(task);\n        }, delay);\n      } else {\n        logger.error(`Consolidation failed permanently for user ${task.userId}:`, error);\n      }\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Performance Metrics & Monitoring\n\nComprehensive monitoring ensures optimal memory service performance:\n\n\u003Cdiv class=\"performance-showcase\">\n  \u003Cdiv class=\"performance-grid\">\n    \u003Cdiv class=\"performance-item memory-storage\">\n      \u003Ch3>💾 Memory Storage\u003C/h3>\n      \u003Cdiv class=\"performance-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">45ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Store Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">2M+\u003C/span>\n          \u003Cspan class=\"stat-label\">Memories Stored\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.8%\u003C/span>\n          \u003Cspan class=\"stat-label\">Success Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"performance-item memory-retrieval\">\n      \u003Ch3>🔍 Memory Retrieval\u003C/h3>\n      \u003Cdiv class=\"performance-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">75ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Search Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">0.85\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Relevance\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">95%\u003C/span>\n          \u003Cspan class=\"stat-label\">Cache Hit Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n\n    \u003Cdiv class=\"performance-item memory-consolidation\">\n      \u003Ch3>🔄 Memory Consolidation\u003C/h3>\n      \u003Cdiv class=\"performance-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">2.3s\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Consolidation\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">35%\u003C/span>\n          \u003Cspan class=\"stat-label\">Space Reduction\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">12h\u003C/span>\n          \u003Cspan class=\"stat-label\">Consolidation Interval\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n  \u003C/div>\n\u003C/div>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🧠 Memory Benefits:\u003C/strong> NUBI's advanced memory service provides\n  contextually relevant information retrieval with sub-100ms performance,\n  intelligent consolidation to prevent fragmentation, and semantic search\n  capabilities that understand meaning beyond keywords.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Next**: Explore the [Performance Optimization](/database/performance/) page\n  to understand how NUBI achieves these exceptional database performance\n  metrics.\n\u003C/Aside>","src/content/docs/database/memory-service.mdx","478a13f681266985","database/memory-service.mdx","database/performance",{"id":174,"data":176,"body":182,"filePath":183,"digest":184,"legacyId":185,"deferredRender":16},{"title":177,"description":178,"editUrl":16,"head":179,"template":47,"sidebar":180,"pagefind":16,"draft":35},"Database Performance Optimization","Comprehensive guide to NUBI's database performance optimization strategies, monitoring systems, and advanced tuning techniques that deliver sub-100ms response times.",[],{"hidden":35,"attrs":181},{},"import {\n  Card,\n  CardGrid,\n  Aside,\n  Code,\n  Tabs,\n  TabItem,\n} from \"@astrojs/starlight/components\";\n\n# Database Performance Optimization\n\nNUBI's database performance optimization system employs advanced techniques including intelligent connection pooling, query optimization, caching strategies, and real-time monitoring to deliver exceptional performance across all database operations.\n\n## 🎯 Performance Architecture\n\nThe performance optimization system operates through multiple layers of optimization and monitoring:\n\n```mermaid\ngraph TB\n    A[Application Queries] --> B[Query Optimizer]\n    B --> C[Connection Pool Router]\n    C --> D{Query Analysis}\n    \n    D -->|Simple| E[Transaction Pool]\n    D -->|Complex| F[Session Pool]\n    D -->|Vector| F\n    \n    E --> G[Query Cache]\n    F --> G\n    G --> H[Database Execution]\n    \n    H --> I[Result Cache]\n    I --> J[Performance Metrics]\n    J --> K[Adaptive Optimization]\n    \n    K --> L[Pool Scaling]\n    K --> M[Query Rewriting]\n    K --> N[Index Optimization]\n    K --> O[Cache Tuning]\n    \n    P[Real-time Monitor] --> Q[Performance Dashboard]\n    P --> R[Alert System]\n    P --> S[Auto-healing]\n    \n    J --> P\n    L --> C\n    M --> B\n    N --> H\n    O --> G\n```\n\n\u003CCardGrid>\n  \u003CCard title=\"⚡ Sub-100ms Response\" icon=\"rocket\">\n    **Consistently fast queries** with 95% of simple operations completing under 50ms and complex analytics under 200ms.\n  \u003C/Card>\n\n  \u003CCard title=\"📊 Intelligent Monitoring\" icon=\"chart\">\n    **Real-time performance tracking** with automatic bottleneck detection, performance regression alerts, and adaptive optimization.\n  \u003C/Card>\n\n  \u003CCard title=\"🔄 Auto-scaling Pools\" icon=\"approve-check\">\n    **Dynamic connection management** that automatically scales pool sizes based on load patterns and performance metrics.\n  \u003C/Card>\n\n  \u003CCard title=\"🧠 Smart Caching\" icon=\"setting\">\n    **Multi-layer caching strategy** with query result caching, connection pooling, and embedding caching for optimal resource utilization.\n  \u003C/Card>\n\u003C/CardGrid>\n\n## 🚀 Performance Optimization Strategies\n\nNUBI employs multiple optimization strategies working in concert to achieve exceptional performance:\n\n\u003CTabs>\n  \u003CTabItem label=\"Query Optimization\">\n```typescript\nexport interface QueryOptimizationConfig {\n  enableQueryCache: boolean;\n  cacheSize: number;\n  cacheTTL: number;\n  enableQueryRewriting: boolean;\n  enableIndexSuggestions: boolean;\n  parallelExecutionThreshold: number;\n  queryTimeoutMs: number;\n}\n\nexport class QueryOptimizer {\n  private config: QueryOptimizationConfig;\n  private queryCache = new LRUCache\u003Cstring, QueryResult>({ max: 10000 });\n  private queryPatterns = new Map\u003Cstring, QueryPattern>();\n  private performanceHistory = new Map\u003Cstring, QueryPerformance[]>();\n  \n  constructor(config?: Partial\u003CQueryOptimizationConfig>) {\n    this.config = {\n      enableQueryCache: true,\n      cacheSize: 10000,\n      cacheTTL: 300000, // 5 minutes\n      enableQueryRewriting: true,\n      enableIndexSuggestions: true,\n      parallelExecutionThreshold: 100, // ms\n      queryTimeoutMs: 30000,\n      ...config\n    };\n  }\n  \n  async optimizeQuery(\n    query: string,\n    params: any[],\n    context: QueryContext\n  ): Promise\u003COptimizedQuery> {\n    const startTime = Date.now();\n    \n    // Step 1: Check query cache\n    if (this.config.enableQueryCache) {\n      const cached = await this.checkQueryCache(query, params);\n      if (cached) {\n        return {\n          originalQuery: query,\n          optimizedQuery: query,\n          cacheHit: true,\n          result: cached,\n          optimizationTime: Date.now() - startTime\n        };\n      }\n    }\n    \n    // Step 2: Analyze query pattern\n    const pattern = await this.analyzeQueryPattern(query);\n    \n    // Step 3: Apply query rewriting if beneficial\n    let optimizedQuery = query;\n    if (this.config.enableQueryRewriting && pattern.canOptimize) {\n      optimizedQuery = await this.rewriteQuery(query, pattern, context);\n    }\n    \n    // Step 4: Determine execution strategy\n    const executionStrategy = await this.determineExecutionStrategy(\n      optimizedQuery,\n      params,\n      pattern\n    );\n    \n    // Step 5: Execute with optimization\n    const result = await this.executeOptimized(\n      optimizedQuery,\n      params,\n      executionStrategy\n    );\n    \n    // Step 6: Cache result if appropriate\n    if (this.shouldCacheResult(pattern, result)) {\n      await this.cacheQueryResult(query, params, result);\n    }\n    \n    // Step 7: Update performance metrics\n    await this.updatePerformanceMetrics(query, pattern, result);\n    \n    return {\n      originalQuery: query,\n      optimizedQuery,\n      cacheHit: false,\n      result,\n      executionStrategy,\n      optimizationTime: Date.now() - startTime\n    };\n  }\n  \n  private async analyzeQueryPattern(query: string): Promise\u003CQueryPattern> {\n    const normalizedQuery = this.normalizeQuery(query);\n    \n    // Check for known patterns\n    const existingPattern = this.queryPatterns.get(normalizedQuery);\n    if (existingPattern) {\n      return existingPattern;\n    }\n    \n    // Analyze new pattern\n    const pattern: QueryPattern = {\n      id: crypto.randomUUID(),\n      normalizedQuery,\n      type: this.classifyQueryType(query),\n      complexity: this.calculateQueryComplexity(query),\n      tables: this.extractTables(query),\n      joins: this.extractJoins(query),\n      filters: this.extractFilters(query),\n      aggregations: this.extractAggregations(query),\n      canOptimize: false,\n      optimizations: [],\n      avgExecutionTime: 0,\n      executionCount: 0\n    };\n    \n    // Identify optimization opportunities\n    pattern.optimizations = await this.identifyOptimizations(pattern);\n    pattern.canOptimize = pattern.optimizations.length > 0;\n    \n    // Cache pattern\n    this.queryPatterns.set(normalizedQuery, pattern);\n    \n    return pattern;\n  }\n  \n  private async identifyOptimizations(pattern: QueryPattern): Promise\u003CQueryOptimization[]> {\n    const optimizations: QueryOptimization[] = [];\n    \n    // Index optimization opportunities\n    if (pattern.filters.length > 0) {\n      const missingIndexes = await this.findMissingIndexes(pattern);\n      for (const index of missingIndexes) {\n        optimizations.push({\n          type: 'add_index',\n          description: `Add index on ${index.columns.join(', ')} for table ${index.table}`,\n          estimatedImprovement: index.estimatedImprovement,\n          implementation: index.ddl\n        });\n      }\n    }\n    \n    // Join order optimization\n    if (pattern.joins.length > 1) {\n      const optimalJoinOrder = await this.calculateOptimalJoinOrder(pattern.joins);\n      if (optimalJoinOrder.improvement > 0.1) {\n        optimizations.push({\n          type: 'reorder_joins',\n          description: 'Reorder joins for optimal execution',\n          estimatedImprovement: optimalJoinOrder.improvement,\n          implementation: optimalJoinOrder.rewrittenQuery\n        });\n      }\n    }\n    \n    // Subquery optimization\n    const subqueryOptimizations = await this.analyzeSubqueries(pattern);\n    optimizations.push(...subqueryOptimizations);\n    \n    // Aggregation optimization\n    if (pattern.aggregations.length > 0) {\n      const aggOptimizations = await this.optimizeAggregations(pattern);\n      optimizations.push(...aggOptimizations);\n    }\n    \n    return optimizations;\n  }\n  \n  private async rewriteQuery(\n    query: string,\n    pattern: QueryPattern,\n    context: QueryContext\n  ): Promise\u003Cstring> {\n    let rewrittenQuery = query;\n    \n    for (const optimization of pattern.optimizations) {\n      switch (optimization.type) {\n        case 'reorder_joins':\n          rewrittenQuery = optimization.implementation;\n          break;\n          \n        case 'eliminate_subquery':\n          rewrittenQuery = await this.eliminateSubquery(rewrittenQuery, optimization);\n          break;\n          \n        case 'add_exists_clause':\n          rewrittenQuery = await this.addExistsClause(rewrittenQuery, optimization);\n          break;\n          \n        case 'push_down_predicates':\n          rewrittenQuery = await this.pushDownPredicates(rewrittenQuery, optimization);\n          break;\n      }\n    }\n    \n    return rewrittenQuery;\n  }\n  \n  async performanceAnalysis(): Promise\u003CPerformanceAnalysisReport> {\n    const report: PerformanceAnalysisReport = {\n      timestamp: new Date(),\n      queryPatterns: [],\n      bottlenecks: [],\n      recommendations: [],\n      trends: await this.analyzeTrends()\n    };\n    \n    // Analyze query patterns\n    for (const [query, pattern] of this.queryPatterns) {\n      const analysis = await this.analyzePatternPerformance(pattern);\n      report.queryPatterns.push(analysis);\n      \n      // Identify bottlenecks\n      if (analysis.avgExecutionTime > 1000) { // > 1 second\n        report.bottlenecks.push({\n          type: 'slow_query',\n          pattern: query,\n          avgTime: analysis.avgExecutionTime,\n          frequency: analysis.executionCount,\n          severity: 'high'\n        });\n      }\n    }\n    \n    // Generate recommendations\n    report.recommendations = await this.generatePerformanceRecommendations(report);\n    \n    return report;\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Connection Pool Optimization\">\n```typescript\nexport class ConnectionPoolOptimizer {\n  private pools = new Map\u003Cstring, DatabasePool>();\n  private metrics: PoolMetricsCollector;\n  private optimizer: PoolSizeOptimizer;\n  \n  constructor() {\n    this.metrics = new PoolMetricsCollector();\n    this.optimizer = new PoolSizeOptimizer();\n    this.startOptimizationLoop();\n  }\n  \n  async optimizePools(): Promise\u003CPoolOptimizationResult> {\n    const optimizations: PoolOptimization[] = [];\n    \n    for (const [poolName, pool] of this.pools) {\n      const metrics = await this.metrics.getPoolMetrics(poolName);\n      const optimization = await this.optimizer.analyzePool(poolName, metrics);\n      \n      if (optimization.recommendedChanges.length > 0) {\n        optimizations.push(optimization);\n        \n        // Apply optimizations if they're safe\n        if (optimization.safeToApply) {\n          await this.applyPoolOptimization(poolName, optimization);\n        }\n      }\n    }\n    \n    return {\n      timestamp: new Date(),\n      optimizations,\n      totalPools: this.pools.size,\n      optimizedPools: optimizations.length\n    };\n  }\n  \n  private async applyPoolOptimization(\n    poolName: string,\n    optimization: PoolOptimization\n  ): Promise\u003Cvoid> {\n    const pool = this.pools.get(poolName);\n    if (!pool) return;\n    \n    for (const change of optimization.recommendedChanges) {\n      switch (change.type) {\n        case 'increase_max_connections':\n          await pool.setMaxConnections(change.newValue);\n          logger.info(`Increased ${poolName} max connections to ${change.newValue}`);\n          break;\n          \n        case 'decrease_max_connections':\n          await pool.setMaxConnections(change.newValue);\n          logger.info(`Decreased ${poolName} max connections to ${change.newValue}`);\n          break;\n          \n        case 'adjust_idle_timeout':\n          await pool.setIdleTimeout(change.newValue);\n          logger.info(`Adjusted ${poolName} idle timeout to ${change.newValue}ms`);\n          break;\n          \n        case 'adjust_acquire_timeout':\n          await pool.setAcquireTimeout(change.newValue);\n          logger.info(`Adjusted ${poolName} acquire timeout to ${change.newValue}ms`);\n          break;\n      }\n    }\n  }\n  \n  private startOptimizationLoop(): void {\n    setInterval(async () => {\n      try {\n        await this.optimizePools();\n      } catch (error) {\n        logger.error('Pool optimization failed:', error);\n      }\n    }, 300000); // Every 5 minutes\n  }\n}\n\nexport class PoolSizeOptimizer {\n  async analyzePool(poolName: string, metrics: PoolMetrics): Promise\u003CPoolOptimization> {\n    const recommendations: PoolRecommendation[] = [];\n    let safeToApply = true;\n    \n    // Analyze utilization patterns\n    const utilization = metrics.activeConnections / metrics.maxConnections;\n    const queueTime = metrics.avgQueueTime;\n    const errorRate = metrics.connectionErrors / metrics.totalConnections;\n    \n    // High utilization with queuing suggests need for more connections\n    if (utilization > 0.8 && queueTime > 50) {\n      const newMax = Math.min(\n        metrics.maxConnections * 1.5,\n        this.getMaxAllowedConnections(poolName)\n      );\n      \n      recommendations.push({\n        type: 'increase_max_connections',\n        currentValue: metrics.maxConnections,\n        newValue: Math.floor(newMax),\n        reason: `High utilization (${(utilization * 100).toFixed(1)}%) with ${queueTime}ms queue time`,\n        estimatedImprovement: this.calculateExpectedImprovement(utilization, queueTime),\n        risk: 'low'\n      });\n    }\n    \n    // Low utilization suggests over-provisioning\n    if (utilization \u003C 0.2 && metrics.maxConnections > this.getMinConnections(poolName)) {\n      const newMax = Math.max(\n        metrics.maxConnections * 0.7,\n        this.getMinConnections(poolName)\n      );\n      \n      recommendations.push({\n        type: 'decrease_max_connections',\n        currentValue: metrics.maxConnections,\n        newValue: Math.floor(newMax),\n        reason: `Low utilization (${(utilization * 100).toFixed(1)}%) suggests over-provisioning`,\n        estimatedImprovement: 0.1,\n        risk: 'medium'\n      });\n      \n      safeToApply = false; // Reducing connections requires more careful consideration\n    }\n    \n    // High error rate suggests connection issues\n    if (errorRate > 0.05) {\n      recommendations.push({\n        type: 'investigate_errors',\n        currentValue: errorRate,\n        newValue: 0.01,\n        reason: `High connection error rate (${(errorRate * 100).toFixed(2)}%)`,\n        estimatedImprovement: 0.5,\n        risk: 'high'\n      });\n      \n      safeToApply = false;\n    }\n    \n    return {\n      poolName,\n      recommendedChanges: recommendations,\n      safeToApply,\n      priority: this.calculateOptimizationPriority(recommendations),\n      estimatedImpact: this.calculateEstimatedImpact(recommendations)\n    };\n  }\n  \n  private calculateExpectedImprovement(utilization: number, queueTime: number): number {\n    // Higher utilization and longer queue times = more improvement potential\n    const utilizationFactor = Math.max(0, utilization - 0.7) / 0.3;\n    const queueTimeFactor = Math.min(1, queueTime / 100);\n    \n    return utilizationFactor * queueTimeFactor;\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Caching Strategy\">\n```typescript\nexport class MultiLayerCacheSystem {\n  private queryCache: QueryCache;\n  private resultCache: ResultCache;\n  private embeddingCache: EmbeddingCache;\n  private connectionCache: ConnectionCache;\n  \n  constructor() {\n    this.queryCache = new QueryCache({\n      maxSize: 10000,\n      ttl: 300000, // 5 minutes\n      strategy: 'lru-with-frequency'\n    });\n    \n    this.resultCache = new ResultCache({\n      maxSize: 5000,\n      ttl: 600000, // 10 minutes\n      strategy: 'adaptive-ttl'\n    });\n    \n    this.embeddingCache = new EmbeddingCache({\n      maxSize: 50000,\n      ttl: 3600000, // 1 hour\n      strategy: 'lru'\n    });\n    \n    this.connectionCache = new ConnectionCache({\n      warmupConnections: 5,\n      maxIdleTime: 300000,\n      healthCheckInterval: 60000\n    });\n  }\n  \n  async cacheQuery(\n    query: string,\n    params: any[],\n    result: QueryResult,\n    metadata?: CacheMetadata\n  ): Promise\u003Cvoid> {\n    const cacheKey = this.generateCacheKey(query, params);\n    \n    // Determine TTL based on query characteristics\n    const ttl = this.calculateAdaptiveTTL(query, result, metadata);\n    \n    // Cache with different strategies based on query type\n    if (this.isFrequentQuery(query)) {\n      await this.queryCache.set(cacheKey, result, ttl * 2); // Longer TTL for frequent queries\n    } else if (this.isExpensiveQuery(query, result)) {\n      await this.queryCache.set(cacheKey, result, ttl * 1.5); // Longer TTL for expensive queries\n    } else {\n      await this.queryCache.set(cacheKey, result, ttl);\n    }\n  }\n  \n  async getCachedQuery(query: string, params: any[]): Promise\u003CQueryResult | null> {\n    const cacheKey = this.generateCacheKey(query, params);\n    \n    // Try different cache layers in order of speed\n    let result = await this.queryCache.get(cacheKey);\n    if (result) {\n      this.recordCacheHit('query', 'l1');\n      return result;\n    }\n    \n    result = await this.resultCache.get(cacheKey);\n    if (result) {\n      this.recordCacheHit('query', 'l2');\n      // Promote to faster cache\n      await this.queryCache.set(cacheKey, result);\n      return result;\n    }\n    \n    this.recordCacheMiss('query');\n    return null;\n  }\n  \n  private calculateAdaptiveTTL(\n    query: string,\n    result: QueryResult,\n    metadata?: CacheMetadata\n  ): number {\n    let baseTTL = 300000; // 5 minutes\n    \n    // Adjust based on query characteristics\n    if (this.isStaticDataQuery(query)) {\n      baseTTL *= 4; // Static data can be cached longer\n    }\n    \n    if (this.isUserSpecificQuery(query)) {\n      baseTTL *= 0.5; // User-specific data should be cached shorter\n    }\n    \n    if (result.rowCount > 1000) {\n      baseTTL *= 2; // Large results benefit from longer caching\n    }\n    \n    // Adjust based on access patterns\n    if (metadata?.accessFrequency === 'high') {\n      baseTTL *= 1.5;\n    }\n    \n    return baseTTL;\n  }\n  \n  async optimizeCaches(): Promise\u003CCacheOptimizationReport> {\n    const report: CacheOptimizationReport = {\n      timestamp: new Date(),\n      optimizations: [],\n      hitRates: await this.calculateHitRates(),\n      memoryUsage: await this.calculateMemoryUsage(),\n      recommendations: []\n    };\n    \n    // Analyze hit rates and adjust cache sizes\n    for (const [cacheName, hitRate] of Object.entries(report.hitRates)) {\n      if (hitRate \u003C 0.7) {\n        report.recommendations.push({\n          type: 'increase_cache_size',\n          cache: cacheName,\n          currentHitRate: hitRate,\n          recommendedAction: `Increase ${cacheName} cache size by 50%`\n        });\n      }\n      \n      if (hitRate > 0.95) {\n        report.recommendations.push({\n          type: 'optimize_eviction_policy',\n          cache: cacheName,\n          currentHitRate: hitRate,\n          recommendedAction: `Consider more aggressive eviction for ${cacheName}`\n        });\n      }\n    }\n    \n    // Implement automatic optimizations\n    await this.implementAutomaticOptimizations(report.recommendations);\n    \n    return report;\n  }\n  \n  private async implementAutomaticOptimizations(\n    recommendations: CacheRecommendation[]\n  ): Promise\u003Cvoid> {\n    for (const rec of recommendations) {\n      if (rec.type === 'increase_cache_size' && rec.currentHitRate \u003C 0.5) {\n        // Only auto-implement for very poor hit rates\n        try {\n          await this.increaseCacheSize(rec.cache, 1.3);\n          logger.info(`Automatically increased ${rec.cache} cache size by 30%`);\n        } catch (error) {\n          logger.warn(`Failed to auto-optimize ${rec.cache}:`, error);\n        }\n      }\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📊 Real-time Performance Monitoring\n\nComprehensive monitoring system tracks all aspects of database performance:\n\n\u003CTabs>\n  \u003CTabItem label=\"Performance Dashboard\">\n```typescript\nexport class PerformanceDashboard {\n  private metricsCollector: MetricsCollector;\n  private alertSystem: AlertSystem;\n  private trendAnalyzer: TrendAnalyzer;\n  \n  async generateDashboardData(): Promise\u003CDashboardData> {\n    const [\n      currentMetrics,\n      historicalTrends,\n      activeAlerts,\n      systemHealth\n    ] = await Promise.all([\n      this.metricsCollector.getCurrentMetrics(),\n      this.trendAnalyzer.getRecentTrends(3600000), // Last hour\n      this.alertSystem.getActiveAlerts(),\n      this.calculateSystemHealth()\n    ]);\n    \n    return {\n      timestamp: new Date(),\n      systemHealth,\n      currentMetrics: {\n        queries: {\n          totalQueriesPerSecond: currentMetrics.queryRate,\n          avgResponseTime: currentMetrics.avgResponseTime,\n          slowQueries: currentMetrics.slowQueries,\n          errorRate: currentMetrics.errorRate\n        },\n        connections: {\n          totalPools: currentMetrics.totalPools,\n          activeConnections: currentMetrics.activeConnections,\n          utilization: currentMetrics.poolUtilization,\n          queueTime: currentMetrics.avgQueueTime\n        },\n        cache: {\n          hitRate: currentMetrics.cacheHitRate,\n          memoryUsage: currentMetrics.cacheMemoryUsage,\n          evictionsPerSecond: currentMetrics.evictionRate\n        },\n        storage: {\n          diskUsage: currentMetrics.diskUsage,\n          indexEfficiency: currentMetrics.indexEfficiency,\n          tableStats: currentMetrics.tableStats\n        }\n      },\n      trends: {\n        responseTimeTrend: historicalTrends.responseTime,\n        throughputTrend: historicalTrends.throughput,\n        errorTrend: historicalTrends.errors,\n        utilizationTrend: historicalTrends.utilization\n      },\n      alerts: activeAlerts,\n      recommendations: await this.generateRecommendations(currentMetrics, historicalTrends)\n    };\n  }\n  \n  private async calculateSystemHealth(): Promise\u003CSystemHealth> {\n    const healthChecks = await Promise.all([\n      this.checkConnectionPoolHealth(),\n      this.checkQueryPerformanceHealth(),\n      this.checkCacheHealth(),\n      this.checkStorageHealth()\n    ]);\n    \n    const overallScore = healthChecks.reduce((sum, check) => sum + check.score, 0) / healthChecks.length;\n    \n    return {\n      overallScore,\n      status: this.determineHealthStatus(overallScore),\n      components: healthChecks,\n      lastChecked: new Date()\n    };\n  }\n  \n  private async checkConnectionPoolHealth(): Promise\u003CHealthCheck> {\n    const metrics = await this.metricsCollector.getPoolMetrics();\n    \n    let score = 1.0;\n    const issues: string[] = [];\n    \n    // Check utilization\n    if (metrics.utilization > 0.9) {\n      score -= 0.3;\n      issues.push('High connection pool utilization');\n    }\n    \n    // Check queue times\n    if (metrics.avgQueueTime > 100) {\n      score -= 0.2;\n      issues.push('High connection queue times');\n    }\n    \n    // Check error rate\n    if (metrics.errorRate > 0.05) {\n      score -= 0.4;\n      issues.push('High connection error rate');\n    }\n    \n    return {\n      component: 'Connection Pools',\n      score: Math.max(0, score),\n      status: score > 0.8 ? 'healthy' : score > 0.5 ? 'degraded' : 'critical',\n      issues,\n      metrics: {\n        utilization: metrics.utilization,\n        queueTime: metrics.avgQueueTime,\n        errorRate: metrics.errorRate\n      }\n    };\n  }\n  \n  async createPerformanceReport(): Promise\u003CPerformanceReport> {\n    const reportPeriod = 24 * 60 * 60 * 1000; // 24 hours\n    const endTime = new Date();\n    const startTime = new Date(endTime.getTime() - reportPeriod);\n    \n    const [\n      queryStats,\n      connectionStats,\n      cacheStats,\n      slowQueries,\n      topBottlenecks\n    ] = await Promise.all([\n      this.analyzeQueryPerformance(startTime, endTime),\n      this.analyzeConnectionPerformance(startTime, endTime),\n      this.analyzeCachePerformance(startTime, endTime),\n      this.identifySlowQueries(startTime, endTime),\n      this.identifyTopBottlenecks(startTime, endTime)\n    ]);\n    \n    const recommendations = await this.generatePerformanceRecommendations({\n      queryStats,\n      connectionStats,\n      cacheStats,\n      slowQueries,\n      topBottlenecks\n    });\n    \n    return {\n      reportPeriod: { start: startTime, end: endTime },\n      summary: {\n        totalQueries: queryStats.totalQueries,\n        avgResponseTime: queryStats.avgResponseTime,\n        slowQueryCount: slowQueries.length,\n        errorRate: queryStats.errorRate,\n        cacheHitRate: cacheStats.hitRate,\n        connectionUtilization: connectionStats.avgUtilization\n      },\n      queryStats,\n      connectionStats,\n      cacheStats,\n      slowQueries: slowQueries.slice(0, 10), // Top 10 slow queries\n      topBottlenecks: topBottlenecks.slice(0, 5), // Top 5 bottlenecks\n      recommendations,\n      generatedAt: new Date()\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Auto-healing System\">\n```typescript\nexport class AutoHealingSystem {\n  private monitors: PerformanceMonitor[] = [];\n  private healingActions: HealingAction[] = [];\n  private healingHistory: HealingEvent[] = [];\n  \n  constructor() {\n    this.initializeMonitors();\n    this.initializeHealingActions();\n    this.startMonitoring();\n  }\n  \n  private initializeHealingActions(): void {\n    this.healingActions = [\n      {\n        name: 'increase_connection_pool',\n        condition: (metrics) => metrics.poolUtilization > 0.9 && metrics.queueTime > 100,\n        action: async (context) => await this.increaseConnectionPool(context),\n        cooldown: 300000, // 5 minutes\n        severity: 'medium'\n      },\n      {\n        name: 'restart_slow_connections',\n        condition: (metrics) => metrics.avgConnectionTime > 5000,\n        action: async (context) => await this.restartSlowConnections(context),\n        cooldown: 600000, // 10 minutes\n        severity: 'high'\n      },\n      {\n        name: 'clear_query_cache',\n        condition: (metrics) => metrics.cacheHitRate \u003C 0.3 && metrics.cacheSize > 0.8 * metrics.maxCacheSize,\n        action: async (context) => await this.clearUnderperformingCache(context),\n        cooldown: 180000, // 3 minutes\n        severity: 'low'\n      },\n      {\n        name: 'kill_long_running_queries',\n        condition: (metrics) => metrics.longRunningQueries > 5,\n        action: async (context) => await this.killLongRunningQueries(context),\n        cooldown: 120000, // 2 minutes\n        severity: 'high'\n      },\n      {\n        name: 'optimize_slow_queries',\n        condition: (metrics) => metrics.slowQueryCount > 10 && metrics.avgResponseTime > 1000,\n        action: async (context) => await this.optimizeSlowQueries(context),\n        cooldown: 3600000, // 1 hour\n        severity: 'medium'\n      }\n    ];\n  }\n  \n  private startMonitoring(): void {\n    setInterval(async () => {\n      try {\n        await this.checkSystemHealth();\n      } catch (error) {\n        logger.error('Auto-healing check failed:', error);\n      }\n    }, 30000); // Check every 30 seconds\n  }\n  \n  private async checkSystemHealth(): Promise\u003Cvoid> {\n    const metrics = await this.collectCurrentMetrics();\n    const activeIssues: SystemIssue[] = [];\n    \n    // Check each healing action condition\n    for (const healingAction of this.healingActions) {\n      if (this.isInCooldown(healingAction)) {\n        continue;\n      }\n      \n      if (healingAction.condition(metrics)) {\n        activeIssues.push({\n          type: healingAction.name,\n          severity: healingAction.severity,\n          metrics: this.extractRelevantMetrics(metrics, healingAction),\n          detectedAt: new Date()\n        });\n      }\n    }\n    \n    // Execute healing actions for critical issues\n    for (const issue of activeIssues) {\n      if (issue.severity === 'high' || issue.severity === 'critical') {\n        await this.executeHealingAction(issue);\n      }\n    }\n    \n    // Log issues for analysis\n    if (activeIssues.length > 0) {\n      logger.warn('System issues detected:', activeIssues.map(i => i.type));\n    }\n  }\n  \n  private async executeHealingAction(issue: SystemIssue): Promise\u003Cvoid> {\n    const healingAction = this.healingActions.find(action => action.name === issue.type);\n    if (!healingAction) {\n      return;\n    }\n    \n    const healingEvent: HealingEvent = {\n      id: crypto.randomUUID(),\n      actionName: healingAction.name,\n      triggeredAt: new Date(),\n      issue,\n      status: 'executing',\n      attempts: 1\n    };\n    \n    try {\n      logger.info(`Executing auto-healing action: ${healingAction.name}`);\n      \n      const context: HealingContext = {\n        issue,\n        metrics: issue.metrics,\n        previousAttempts: this.getPreviousAttempts(healingAction.name)\n      };\n      \n      await healingAction.action(context);\n      \n      healingEvent.status = 'success';\n      healingEvent.completedAt = new Date();\n      healingEvent.result = 'Action completed successfully';\n      \n      // Set cooldown\n      this.setCooldown(healingAction);\n      \n      logger.info(`Auto-healing action completed: ${healingAction.name}`);\n      \n    } catch (error) {\n      healingEvent.status = 'failed';\n      healingEvent.completedAt = new Date();\n      healingEvent.error = error.message;\n      \n      logger.error(`Auto-healing action failed: ${healingAction.name}`, error);\n      \n      // Consider escalating if multiple failures\n      if (healingEvent.attempts >= 3) {\n        await this.escalateIssue(issue, healingEvent);\n      }\n    } finally {\n      this.healingHistory.push(healingEvent);\n      \n      // Keep only recent history\n      if (this.healingHistory.length > 1000) {\n        this.healingHistory = this.healingHistory.slice(-1000);\n      }\n    }\n  }\n  \n  private async increaseConnectionPool(context: HealingContext): Promise\u003Cvoid> {\n    const poolName = context.issue.metrics.poolName;\n    const currentSize = context.issue.metrics.maxConnections;\n    const newSize = Math.min(currentSize * 1.5, 25); // Max 25 connections\n    \n    const poolManager = this.getPoolManager();\n    await poolManager.updatePoolSize(poolName, Math.floor(newSize));\n    \n    logger.info(`Increased ${poolName} pool size from ${currentSize} to ${Math.floor(newSize)}`);\n  }\n  \n  private async clearUnderperformingCache(context: HealingContext): Promise\u003Cvoid> {\n    const cacheManager = this.getCacheManager();\n    \n    // Clear cache entries with low hit rates\n    await cacheManager.clearLowPerformingEntries(0.2); // Clear entries with \u003C20% hit rate\n    \n    logger.info('Cleared underperforming cache entries');\n  }\n  \n  private async killLongRunningQueries(context: HealingContext): Promise\u003Cvoid> {\n    const queryManager = this.getQueryManager();\n    const threshold = 300000; // 5 minutes\n    \n    const killedQueries = await queryManager.killLongRunningQueries(threshold);\n    \n    logger.info(`Killed ${killedQueries.length} long-running queries`);\n  }\n  \n  async getHealingReport(): Promise\u003CHealingReport> {\n    const recentHistory = this.healingHistory.filter(\n      event => event.triggeredAt.getTime() > Date.now() - 24 * 60 * 60 * 1000 // Last 24 hours\n    );\n    \n    const successfulActions = recentHistory.filter(event => event.status === 'success');\n    const failedActions = recentHistory.filter(event => event.status === 'failed');\n    \n    return {\n      reportPeriod: { hours: 24 },\n      totalActions: recentHistory.length,\n      successfulActions: successfulActions.length,\n      failedActions: failedActions.length,\n      successRate: recentHistory.length > 0 \n        ? successfulActions.length / recentHistory.length \n        : 0,\n      topIssues: this.getTopIssues(recentHistory),\n      actionFrequency: this.calculateActionFrequency(recentHistory),\n      recommendations: this.generateHealingRecommendations(recentHistory),\n      generatedAt: new Date()\n    };\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## 📈 Performance Benchmarks\n\nNUBI's optimized database system delivers exceptional performance across all operation types:\n\n\u003Cdiv class=\"benchmark-showcase\">\n  \u003Cdiv class=\"benchmark-grid\">\n    \u003Cdiv class=\"benchmark-item transaction-pool\">\n      \u003Ch3>🚀 Transaction Pool Performance\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">35ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Response Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">1,200+\u003C/span>\n          \u003Cspan class=\"stat-label\">Queries/Second\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.9%\u003C/span>\n          \u003Cspan class=\"stat-label\">Success Rate\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">95%\u003C/span>\n          \u003Cspan class=\"stat-label\">Cache Hit Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n    \n    \u003Cdiv class=\"benchmark-item session-pool\">\n      \u003Ch3>🧠 Session Pool Performance\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">150ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Response Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">200+\u003C/span>\n          \u003Cspan class=\"stat-label\">Complex Queries/Second\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.7%\u003C/span>\n          \u003Cspan class=\"stat-label\">Success Rate\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">88%\u003C/span>\n          \u003Cspan class=\"stat-label\">Cache Hit Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n    \n    \u003Cdiv class=\"benchmark-item vector-operations\">\n      \u003Ch3>🔍 Vector Operations\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">220ms\u003C/span>\n          \u003Cspan class=\"stat-label\">Semantic Search Time\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">50+\u003C/span>\n          \u003Cspan class=\"stat-label\">Vector Queries/Second\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">0.85\u003C/span>\n          \u003Cspan class=\"stat-label\">Average Relevance\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">92%\u003C/span>\n          \u003Cspan class=\"stat-label\">Embedding Cache Hit\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n    \n    \u003Cdiv class=\"benchmark-item system-health\">\n      \u003Ch3>📊 System Health\u003C/h3>\n      \u003Cdiv class=\"benchmark-stats\">\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">98.5%\u003C/span>\n          \u003Cspan class=\"stat-label\">Overall Uptime\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">0.02%\u003C/span>\n          \u003Cspan class=\"stat-label\">Error Rate\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">15s\u003C/span>\n          \u003Cspan class=\"stat-label\">Auto-healing Response\u003C/span>\n        \u003C/div>\n        \u003Cdiv class=\"stat\">\n          \u003Cspan class=\"stat-value\">99.8%\u003C/span>\n          \u003Cspan class=\"stat-label\">Healing Success Rate\u003C/span>\n        \u003C/div>\n      \u003C/div>\n    \u003C/div>\n  \u003C/div>\n\u003C/div>\n\n## 🔧 Optimization Checklist\n\n\u003Cdiv class=\"optimization-checklist\">\n  \u003Ch3>🎯 Performance Optimization Checklist\u003C/h3>\n  \n  \u003Cdiv class=\"checklist-section\">\n    \u003Ch4>📊 Query Optimization\u003C/h4>\n    \u003Cul>\n      \u003Cli>✅ Intelligent query caching with adaptive TTL\u003C/li>\n      \u003Cli>✅ Automatic query rewriting for optimal execution\u003C/li>\n      \u003Cli>✅ Index recommendations based on query patterns\u003C/li>\n      \u003Cli>✅ Parallel execution for independent operations\u003C/li>\n      \u003Cli>✅ Query timeout and resource limit enforcement\u003C/li>\n    \u003C/ul>\n  \u003C/div>\n  \n  \u003Cdiv class=\"checklist-section\">\n    \u003Ch4>🔗 Connection Management\u003C/h4>\n    \u003Cul>\n      \u003Cli>✅ Dual-pool architecture for optimal routing\u003C/li>\n      \u003Cli>✅ Auto-scaling connection pools based on load\u003C/li>\n      \u003Cli>✅ Connection health monitoring and recovery\u003C/li>\n      \u003Cli>✅ Queue time optimization and alerting\u003C/li>\n      \u003Cli>✅ Resource leak detection and prevention\u003C/li>\n    \u003C/ul>\n  \u003C/div>\n  \n  \u003Cdiv class=\"checklist-section\">\n    \u003Ch4>💾 Caching Strategy\u003C/h4>\n    \u003Cul>\n      \u003Cli>✅ Multi-layer caching with intelligent eviction\u003C/li>\n      \u003Cli>✅ Embedding cache for vector operations\u003C/li>\n      \u003Cli>✅ Query result caching with dependency tracking\u003C/li>\n      \u003Cli>✅ Connection warming and preemptive caching\u003C/li>\n      \u003Cli>✅ Cache performance monitoring and optimization\u003C/li>\n    \u003C/ul>\n  \u003C/div>\n  \n  \u003Cdiv class=\"checklist-section\">\n    \u003Ch4>🔍 Monitoring & Alerting\u003C/h4>\n    \u003Cul>\n      \u003Cli>✅ Real-time performance dashboard\u003C/li>\n      \u003Cli>✅ Automatic bottleneck detection\u003C/li>\n      \u003Cli>✅ Performance regression alerting\u003C/li>\n      \u003Cli>✅ Predictive scaling recommendations\u003C/li>\n      \u003Cli>✅ Auto-healing system with success tracking\u003C/li>\n    \u003C/ul>\n  \u003C/div>\n\u003C/div>\n\n---\n\n\u003Cdiv class=\"nubi-note\">\n  \u003Cstrong>🚀 Performance Benefits:\u003C/strong> NUBI's comprehensive performance optimization system ensures consistent sub-100ms response times, automatic scaling and healing, intelligent caching, and proactive monitoring that maintains optimal database performance under all conditions.\n\u003C/div>\n\n\u003CAside type=\"tip\">\n  **Database Complete**: You've now explored NUBI's complete database system. Continue with the [Telegram Raids](/telegram-raids/overview/) section to understand the raid coordination capabilities.\n\u003C/Aside>","src/content/docs/database/performance.mdx","f9f733746f58ff30","database/performance.mdx","telegram-raids/coordination",{"id":186,"data":188,"body":195,"filePath":196,"digest":197,"legacyId":198,"deferredRender":16},{"title":189,"description":190,"editUrl":16,"head":191,"template":47,"sidebar":192,"pagefind":16,"draft":35},"Raid Coordination","Advanced raid coordination system with multi-platform orchestration and intelligent target selection",[],{"order":193,"hidden":35,"attrs":194},1,{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nNUBI's raid coordination system orchestrates complex multi-platform social media campaigns with intelligent target selection, engagement verification, and real-time performance tracking.\n\n## System Architecture\n\nThe coordination system operates through multiple interconnected services that work together to execute sophisticated raid strategies:\n\n```mermaid\ngraph TB\n    subgraph \"Raid Coordination Layer\"\n        RC[RaidCoordinator]\n        UIF[UserInitiatedRaidFlow]\n        RF[RaidFlow]\n        RT[RaidTracker]\n    end\n    \n    subgraph \"Intelligence Layer\"\n        LDS[LinkDetectionService]\n        EV[EngagementVerifier]\n        MS[ModerationService]\n    end\n    \n    subgraph \"External Platforms\"\n        TG[Telegram]\n        X[X/Twitter]\n        DC[Discord]\n        WS[WebSocket]\n    end\n    \n    RC --> UIF\n    RC --> RF\n    RC --> RT\n    UIF --> LDS\n    RF --> EV\n    RT --> MS\n    \n    RC --> TG\n    RC --> X\n    RC --> DC\n    RC --> WS\n```\n\n## Core Components\n\n### RaidCoordinator\n\nThe central orchestration service that manages all raid operations:\n\n\u003CTabs>\n  \u003CTabItem label=\"TypeScript Interface\">\n```typescript\ninterface RaidCoordinator {\n  // Raid lifecycle management\n  initiateRaid(config: RaidConfiguration): Promise\u003CRaidSession>\n  pauseRaid(raidId: string): Promise\u003Cvoid>\n  resumeRaid(raidId: string): Promise\u003Cvoid>\n  terminateRaid(raidId: string): Promise\u003CRaidResult>\n  \n  // Target selection and analysis\n  analyzeTarget(url: string): Promise\u003CTargetAnalysis>\n  selectOptimalTiming(target: Target): Promise\u003CTimingStrategy>\n  calculateEngagementPotential(target: Target): Promise\u003Cnumber>\n  \n  // Multi-platform coordination\n  coordinateAcrossPlatforms(raid: RaidSession): Promise\u003Cvoid>\n  syncPlatformActions(platforms: Platform[]): Promise\u003CSyncResult>\n  \n  // Real-time monitoring\n  monitorRaidProgress(raidId: string): Promise\u003CRaidMetrics>\n  adjustStrategy(raidId: string, metrics: RaidMetrics): Promise\u003Cvoid>\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Configuration\">\n```yaml\nraid_coordination:\n  max_concurrent_raids: 5\n  default_duration_minutes: 30\n  min_participants: 10\n  max_participants: 500\n  \n  target_analysis:\n    engagement_threshold: 0.7\n    sentiment_analysis: true\n    bot_detection: true\n    spam_filtering: true\n  \n  timing_strategy:\n    peak_hours: [10, 14, 18, 20]\n    timezone_optimization: true\n    competitor_avoidance: true\n  \n  platform_weights:\n    telegram: 0.4\n    twitter: 0.35\n    discord: 0.2\n    websocket: 0.05\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Implementation\">\n```typescript\nclass RaidCoordinator implements Service {\n  constructor(\n    private messageBus: MessageBusService,\n    private analytics: AnalyticsService,\n    private database: DatabaseConnectionManager\n  ) {}\n  \n  async initiateRaid(config: RaidConfiguration): Promise\u003CRaidSession> {\n    // 1. Validate raid configuration\n    const validation = await this.validateRaidConfig(config)\n    if (!validation.valid) {\n      throw new Error(`Invalid raid config: ${validation.errors.join(', ')}`)\n    }\n    \n    // 2. Analyze target and optimize timing\n    const targetAnalysis = await this.analyzeTarget(config.target)\n    const timing = await this.selectOptimalTiming(targetAnalysis)\n    \n    // 3. Create raid session with participants\n    const session = await this.createRaidSession({\n      ...config,\n      analysis: targetAnalysis,\n      timing,\n      status: 'preparing'\n    })\n    \n    // 4. Coordinate across platforms\n    await this.coordinateAcrossPlatforms(session)\n    \n    // 5. Begin monitoring and execution\n    await this.startRaidMonitoring(session.id)\n    \n    return session\n  }\n  \n  private async coordinateAcrossPlatforms(session: RaidSession): Promise\u003Cvoid> {\n    const platforms = session.config.platforms || ['telegram', 'twitter']\n    const coordinationPromises = platforms.map(platform => \n      this.initiatePlatformRaid(session, platform)\n    )\n    \n    await Promise.all(coordinationPromises)\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Target Analysis System\n\nAdvanced target analysis determines raid viability and optimal strategies:\n\n#### Intelligence Gathering\n\n```typescript\ninterface TargetAnalysis {\n  url: string\n  platform: string\n  contentType: 'post' | 'profile' | 'thread' | 'space'\n  \n  // Engagement metrics\n  currentEngagement: EngagementMetrics\n  historicalPerformance: HistoricalData\n  audienceInsights: AudienceProfile\n  \n  // Strategic assessment\n  raidability: number // 0-1 score\n  optimalStrategy: RaidStrategy\n  riskFactors: RiskFactor[]\n  \n  // Timing optimization\n  peakEngagementHours: number[]\n  competitorActivity: CompetitorInsight[]\n  platformSpecificFactors: PlatformFactors\n}\n\nclass TargetAnalyzer {\n  async analyzeTarget(url: string): Promise\u003CTargetAnalysis> {\n    const platformData = await this.extractPlatformData(url)\n    const engagementHistory = await this.getEngagementHistory(platformData)\n    const audienceProfile = await this.analyzeAudience(platformData)\n    \n    return {\n      ...platformData,\n      currentEngagement: await this.getCurrentMetrics(platformData),\n      historicalPerformance: engagementHistory,\n      audienceInsights: audienceProfile,\n      raidability: this.calculateRaidability(platformData, engagementHistory),\n      optimalStrategy: this.determineStrategy(platformData, audienceProfile),\n      riskFactors: this.assessRisks(platformData),\n      peakEngagementHours: this.findPeakHours(engagementHistory),\n      competitorActivity: await this.analyzeCompetitors(platformData),\n      platformSpecificFactors: this.getPlatformFactors(platformData.platform)\n    }\n  }\n}\n```\n\n#### Strategic Decision Making\n\nThe system uses machine learning to optimize raid strategies:\n\n```typescript\ninterface RaidStrategy {\n  approach: 'aggressive' | 'moderate' | 'subtle'\n  phasedExecution: Phase[]\n  contentGuidelines: ContentGuide[]\n  timingWindows: TimeWindow[]\n  participantAllocation: ParticipantAllocation\n}\n\nclass StrategyOptimizer {\n  async optimizeStrategy(\n    target: TargetAnalysis, \n    participants: Participant[]\n  ): Promise\u003CRaidStrategy> {\n    // Machine learning model for strategy optimization\n    const mlPrediction = await this.mlModel.predict({\n      targetMetrics: target,\n      participantProfiles: participants.map(p => p.profile),\n      historicalSuccess: await this.getHistoricalSuccessData()\n    })\n    \n    return {\n      approach: this.determineApproach(mlPrediction),\n      phasedExecution: this.createPhases(target, participants),\n      contentGuidelines: this.generateContentGuides(target),\n      timingWindows: this.calculateOptimalWindows(target),\n      participantAllocation: this.allocateParticipants(participants, target)\n    }\n  }\n}\n```\n\n## Multi-Platform Orchestration\n\n### Platform-Specific Coordination\n\nEach platform requires specialized coordination logic:\n\n\u003CTabs>\n  \u003CTabItem label=\"Telegram\">\n```typescript\nclass TelegramRaidCoordinator {\n  async coordinateRaid(session: RaidSession): Promise\u003Cvoid> {\n    // 1. Create private coordination channel\n    const coordChannel = await this.createCoordinationChannel(session.id)\n    \n    // 2. Invite verified participants\n    await this.inviteParticipants(coordChannel, session.participants)\n    \n    // 3. Distribute raid instructions with timing\n    await this.distributeInstructions(coordChannel, {\n      target: session.target,\n      strategy: session.strategy,\n      timing: session.timing,\n      contentGuidelines: session.contentGuidelines\n    })\n    \n    // 4. Monitor participation and engagement\n    this.startParticipationMonitoring(coordChannel, session)\n  }\n  \n  private async createCoordinationChannel(raidId: string): Promise\u003CChatId> {\n    const channel = await this.telegram.createGroup({\n      title: `🎯 Raid ${raidId.slice(0, 8)}`,\n      description: 'Temporary coordination channel - will be deleted after raid',\n      permissions: {\n        can_send_messages: true,\n        can_send_media: false,\n        can_add_web_page_previews: false\n      }\n    })\n    \n    // Schedule auto-deletion after raid completion\n    this.scheduleChannelDeletion(channel.id, raidId)\n    \n    return channel.id\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"X/Twitter\">\n```typescript\nclass TwitterRaidCoordinator {\n  async coordinateRaid(session: RaidSession): Promise\u003Cvoid> {\n    // 1. Create Twitter Space for live coordination (optional)\n    const coordinationSpace = session.config.useSpaces ? \n      await this.createCoordinationSpace(session) : null\n    \n    // 2. Send DM instructions to participants\n    await this.sendDMInstructions(session.participants, {\n      target: session.target,\n      hashtagStrategy: session.strategy.hashtags,\n      mentionStrategy: session.strategy.mentions,\n      timing: session.timing\n    })\n    \n    // 3. Monitor tweet patterns and engagement\n    this.startTwitterMonitoring(session)\n  }\n  \n  private async sendDMInstructions(\n    participants: Participant[], \n    instructions: TwitterInstructions\n  ): Promise\u003Cvoid> {\n    const dmPromises = participants.map(async participant => {\n      const personalizedInstructions = this.personalizeInstructions(\n        instructions, \n        participant\n      )\n      \n      return this.twitter.sendDM(participant.twitterId, {\n        text: this.formatInstructions(personalizedInstructions),\n        quick_reply_options: [\n          { label: '🎯 Ready', metadata: 'ready' },\n          { label: '❓ Questions', metadata: 'questions' },\n          { label: '🚫 Skip this raid', metadata: 'skip' }\n        ]\n      })\n    })\n    \n    await Promise.all(dmPromises)\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Discord\">\n```typescript\nclass DiscordRaidCoordinator {\n  async coordinateRaid(session: RaidSession): Promise\u003Cvoid> {\n    // 1. Create temporary voice and text channels\n    const raidCategory = await this.createRaidCategory(session.id)\n    const textChannel = await this.createTextChannel(raidCategory, session)\n    const voiceChannel = await this.createVoiceChannel(raidCategory, session)\n    \n    // 2. Set up raid dashboard with real-time updates\n    const dashboard = await this.createRaidDashboard(textChannel, session)\n    \n    // 3. Coordinate through voice and text\n    await this.startVoiceCoordination(voiceChannel, session)\n    await this.startTextCoordination(textChannel, session)\n  }\n  \n  private async createRaidDashboard(\n    channel: TextChannel, \n    session: RaidSession\n  ): Promise\u003CMessage> {\n    const embed = new MessageEmbed()\n      .setTitle(`🎯 Raid Dashboard: ${session.id.slice(0, 8)}`)\n      .setDescription(`Target: ${session.target.url}`)\n      .addFields([\n        { name: '📊 Status', value: session.status, inline: true },\n        { name: '👥 Participants', value: session.participants.length.toString(), inline: true },\n        { name: '⏰ Phase', value: session.currentPhase || 'Preparing', inline: true },\n        { name: '🎯 Strategy', value: session.strategy.approach, inline: true },\n        { name: '📈 Progress', value: '0%', inline: true },\n        { name: '⚡ Engagement', value: 'Calculating...', inline: true }\n      ])\n      .setColor('#FFD700')\n      .setTimestamp()\n    \n    const dashboard = await channel.send({ embeds: [embed] })\n    \n    // Update dashboard every 30 seconds\n    this.startDashboardUpdates(dashboard, session)\n    \n    return dashboard\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Cross-Platform Synchronization\n\nReal-time synchronization ensures coordinated timing across all platforms:\n\n```typescript\nclass CrossPlatformSynchronizer {\n  private syncPoints: Map\u003Cstring, SyncPoint> = new Map()\n  \n  async synchronizeRaidExecution(session: RaidSession): Promise\u003Cvoid> {\n    const platforms = session.platforms\n    const syncPoint = this.createSyncPoint(session.id, platforms)\n    \n    // 1. Prepare all platforms\n    await this.prepareAllPlatforms(session, syncPoint)\n    \n    // 2. Wait for all platforms to be ready\n    await this.waitForAllPlatformsReady(syncPoint)\n    \n    // 3. Execute synchronized countdown\n    await this.executeCountdown(syncPoint, session.timing.countdown)\n    \n    // 4. Trigger simultaneous execution\n    await this.triggerExecution(syncPoint)\n    \n    // 5. Monitor cross-platform coordination\n    this.monitorCrossPlatformMetrics(session)\n  }\n  \n  private async executeCountdown(\n    syncPoint: SyncPoint, \n    countdownSeconds: number\n  ): Promise\u003Cvoid> {\n    for (let i = countdownSeconds; i > 0; i--) {\n      await this.broadcastCountdown(syncPoint, i)\n      await this.sleep(1000)\n    }\n    \n    await this.broadcastCountdown(syncPoint, 0, 'GO! 🚀')\n  }\n  \n  private async broadcastCountdown(\n    syncPoint: SyncPoint, \n    count: number, \n    message?: string\n  ): Promise\u003Cvoid> {\n    const countdownMessage = message || `${count}...`\n    \n    const broadcasts = syncPoint.platforms.map(platform => \n      this.sendCountdownToPlatform(platform, countdownMessage)\n    )\n    \n    await Promise.all(broadcasts)\n  }\n}\n```\n\n## Performance Monitoring\n\n### Real-Time Metrics\n\nThe system tracks comprehensive metrics during raid execution:\n\n```typescript\ninterface RaidMetrics {\n  // Participation metrics\n  totalParticipants: number\n  activeParticipants: number\n  participationRate: number\n  \n  // Engagement metrics\n  totalEngagements: EngagementCounts\n  engagementRate: number\n  avgTimeToEngage: number\n  \n  // Platform-specific metrics\n  platformMetrics: Map\u003Cstring, PlatformMetrics>\n  \n  // Quality metrics\n  contentQualityScore: number\n  spamDetectionRate: number\n  authenticityScore: number\n  \n  // Performance metrics\n  executionEfficiency: number\n  timingAccuracy: number\n  coordinationScore: number\n}\n\nclass RaidMetricsCollector {\n  async collectRealTimeMetrics(raidId: string): Promise\u003CRaidMetrics> {\n    const [\n      participation,\n      engagement,\n      platformData,\n      quality,\n      performance\n    ] = await Promise.all([\n      this.collectParticipationMetrics(raidId),\n      this.collectEngagementMetrics(raidId),\n      this.collectPlatformMetrics(raidId),\n      this.collectQualityMetrics(raidId),\n      this.collectPerformanceMetrics(raidId)\n    ])\n    \n    return {\n      ...participation,\n      ...engagement,\n      platformMetrics: platformData,\n      ...quality,\n      ...performance\n    }\n  }\n}\n```\n\n## Advanced Features\n\n### Adaptive Strategy Adjustment\n\nThe system can adjust strategies in real-time based on performance:\n\n```typescript\nclass AdaptiveStrategyManager {\n  async adjustStrategy(raidId: string, metrics: RaidMetrics): Promise\u003Cvoid> {\n    const adjustments = await this.analyzeNeedForAdjustment(metrics)\n    \n    if (adjustments.length === 0) return\n    \n    for (const adjustment of adjustments) {\n      switch (adjustment.type) {\n        case 'increase_intensity':\n          await this.increaseRaidIntensity(raidId, adjustment.factor)\n          break\n          \n        case 'change_content_strategy':\n          await this.updateContentStrategy(raidId, adjustment.newStrategy)\n          break\n          \n        case 'redistribute_participants':\n          await this.redistributeParticipants(raidId, adjustment.allocation)\n          break\n          \n        case 'adjust_timing':\n          await this.adjustTiming(raidId, adjustment.newTiming)\n          break\n      }\n    }\n  }\n}\n```\n\nThe coordination system represents NUBI's most sophisticated capability, orchestrating complex multi-platform campaigns with military precision while maintaining the authentic community engagement that drives successful raids.","src/content/docs/telegram-raids/coordination.mdx","14d0b615c7f7f67a","telegram-raids/coordination.mdx","telegram-raids/verification",{"id":199,"data":201,"body":208,"filePath":209,"digest":210,"legacyId":211,"deferredRender":16},{"title":202,"description":203,"editUrl":16,"head":204,"template":47,"sidebar":205,"pagefind":16,"draft":35},"Engagement Verification","Advanced verification system ensuring authentic engagement and preventing bot manipulation in raids",[],{"order":206,"hidden":35,"attrs":207},2,{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nNUBI's engagement verification system employs sophisticated AI-powered analysis to ensure authentic participation, detect bot behavior, and maintain high-quality community engagement during raids.\n\n## Verification Architecture\n\nThe multi-layered verification system operates in real-time to validate every aspect of raid participation:\n\n```mermaid\ngraph TB\n    subgraph \"Verification Pipeline\"\n        IV[Identity Verification]\n        BV[Behavioral Verification]\n        CV[Content Verification]\n        TV[Timing Verification]\n        QV[Quality Verification]\n    end\n    \n    subgraph \"AI Analysis Engine\"\n        BA[Behavioral Analysis]\n        CA[Content Analysis]\n        PA[Pattern Analysis]\n        SA[Sentiment Analysis]\n    end\n    \n    subgraph \"Detection Systems\"\n        BD[Bot Detection]\n        SD[Spam Detection]\n        AD[Automation Detection]\n        CD[Coordination Detection]\n    end\n    \n    IV --> BA\n    BV --> BD\n    CV --> CA\n    TV --> PA\n    QV --> SA\n    \n    BA --> SD\n    CA --> AD\n    PA --> CD\n    SA --> BD\n    \n    BD --> VerificationScore[Verification Score]\n    SD --> VerificationScore\n    AD --> VerificationScore\n    CD --> VerificationScore\n```\n\n## Core Verification Components\n\n### EngagementVerifier Service\n\nThe central verification service that orchestrates all validation processes:\n\n\u003CTabs>\n  \u003CTabItem label=\"Main Interface\">\n```typescript\ninterface EngagementVerifier {\n  // Real-time verification\n  verifyEngagement(engagement: RaidEngagement): Promise\u003CVerificationResult>\n  batchVerifyEngagements(engagements: RaidEngagement[]): Promise\u003CVerificationResult[]>\n  \n  // User verification\n  verifyParticipant(userId: string, platform: string): Promise\u003CUserVerificationResult>\n  updateParticipantScore(userId: string, newScore: number): Promise\u003Cvoid>\n  \n  // Behavioral analysis\n  analyzeEngagementPatterns(userId: string): Promise\u003CBehavioralProfile>\n  detectAnomalousActivity(engagement: RaidEngagement): Promise\u003CAnomalyScore>\n  \n  // Quality assessment\n  assessContentQuality(content: string): Promise\u003CQualityScore>\n  validateEngagementTiming(engagement: RaidEngagement): Promise\u003CTimingScore>\n  \n  // Bot detection\n  detectBotBehavior(userId: string): Promise\u003CBotProbability>\n  analyzeAutomationSignals(engagement: RaidEngagement): Promise\u003CAutomationFlags>\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Configuration\">\n```yaml\nengagement_verification:\n  # Scoring thresholds\n  minimum_authenticity_score: 0.7\n  minimum_quality_score: 0.6\n  maximum_bot_probability: 0.3\n  \n  # Behavioral analysis\n  behavioral_tracking:\n    pattern_window_hours: 24\n    min_historical_data: 10\n    anomaly_threshold: 0.8\n  \n  # Content analysis\n  content_analysis:\n    sentiment_required: true\n    originality_threshold: 0.5\n    spam_detection: true\n    language_validation: true\n  \n  # Bot detection\n  bot_detection:\n    response_time_analysis: true\n    pattern_recognition: true\n    metadata_analysis: true\n    cross_platform_correlation: true\n  \n  # Real-time monitoring\n  monitoring:\n    verification_timeout_ms: 5000\n    batch_size: 50\n    retry_attempts: 3\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Implementation\">\n```typescript\nclass EngagementVerifier implements Service {\n  constructor(\n    private aiService: AIAnalysisService,\n    private database: DatabaseConnectionManager,\n    private behaviorAnalyzer: BehaviorAnalyzer,\n    private contentAnalyzer: ContentAnalyzer\n  ) {}\n  \n  async verifyEngagement(engagement: RaidEngagement): Promise\u003CVerificationResult> {\n    // 1. Run parallel verification processes\n    const [\n      identityResult,\n      behaviorResult,\n      contentResult,\n      timingResult,\n      qualityResult\n    ] = await Promise.all([\n      this.verifyIdentity(engagement),\n      this.verifyBehavior(engagement),\n      this.verifyContent(engagement),\n      this.verifyTiming(engagement),\n      this.assessQuality(engagement)\n    ])\n    \n    // 2. Calculate composite verification score\n    const compositeScore = this.calculateCompositeScore({\n      identity: identityResult,\n      behavior: behaviorResult,\n      content: contentResult,\n      timing: timingResult,\n      quality: qualityResult\n    })\n    \n    // 3. Apply contextual adjustments\n    const adjustedScore = await this.applyContextualAdjustments(\n      compositeScore,\n      engagement\n    )\n    \n    // 4. Make final verification decision\n    return {\n      verified: adjustedScore.final >= this.config.minimum_authenticity_score,\n      score: adjustedScore.final,\n      confidence: adjustedScore.confidence,\n      breakdown: adjustedScore.breakdown,\n      flags: this.generateFlags(adjustedScore),\n      recommendations: this.generateRecommendations(adjustedScore)\n    }\n  }\n  \n  private async verifyIdentity(engagement: RaidEngagement): Promise\u003CIdentityScore> {\n    // Cross-platform identity verification\n    const identity = await this.identityService.resolveIdentity(\n      engagement.userId,\n      engagement.platform\n    )\n    \n    return {\n      accountAge: this.calculateAccountAgeScore(identity.accountCreated),\n      platformActivity: await this.calculateActivityScore(identity),\n      crossPlatformConsistency: await this.checkCrossPlatformConsistency(identity),\n      verificationBadges: this.checkVerificationStatus(identity),\n      reputation: await this.calculateReputationScore(identity)\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Behavioral Analysis Engine\n\nAdvanced behavioral pattern analysis to detect authentic vs. automated engagement:\n\n#### Pattern Recognition\n\n```typescript\ninterface BehavioralProfile {\n  // Timing patterns\n  engagementTimingPattern: TimingPattern\n  responseTimeDistribution: TimeDistribution\n  activityPeakHours: number[]\n  \n  // Interaction patterns\n  engagementTypes: EngagementTypeFrequency\n  contentInteractionStyle: InteractionStyle\n  platformUsagePattern: PlatformUsage\n  \n  // Social patterns\n  networkConnectivity: NetworkMetrics\n  communityParticipation: CommunityMetrics\n  influenceMetrics: InfluenceScore\n  \n  // Authenticity indicators\n  humanLikeVariation: VariationScore\n  naturalLanguageUse: LanguageNaturalness\n  contextualRelevance: RelevanceScore\n}\n\nclass BehavioralAnalyzer {\n  async analyzeBehaviorPattern(userId: string): Promise\u003CBehavioralProfile> {\n    // Collect behavioral data over time window\n    const behaviorData = await this.collectBehavioralData(userId, {\n      windowHours: 24 * 7, // 7 days\n      minDataPoints: 20\n    })\n    \n    // Analyze timing patterns\n    const timingAnalysis = this.analyzeTimingPatterns(behaviorData.interactions)\n    \n    // Analyze interaction patterns\n    const interactionAnalysis = this.analyzeInteractionPatterns(behaviorData)\n    \n    // Analyze social patterns\n    const socialAnalysis = await this.analyzeSocialPatterns(userId, behaviorData)\n    \n    // Calculate authenticity indicators\n    const authenticityScores = this.calculateAuthenticityScores(behaviorData)\n    \n    return {\n      engagementTimingPattern: timingAnalysis.pattern,\n      responseTimeDistribution: timingAnalysis.distribution,\n      activityPeakHours: timingAnalysis.peakHours,\n      engagementTypes: interactionAnalysis.types,\n      contentInteractionStyle: interactionAnalysis.style,\n      platformUsagePattern: interactionAnalysis.platformUsage,\n      networkConnectivity: socialAnalysis.connectivity,\n      communityParticipation: socialAnalysis.participation,\n      influenceMetrics: socialAnalysis.influence,\n      humanLikeVariation: authenticityScores.variation,\n      naturalLanguageUse: authenticityScores.language,\n      contextualRelevance: authenticityScores.relevance\n    }\n  }\n  \n  private analyzeTimingPatterns(interactions: Interaction[]): TimingAnalysis {\n    // Detect human-like timing variations\n    const responseTimes = interactions.map(i => i.responseTime)\n    const timingVariation = this.calculateVariationScore(responseTimes)\n    \n    // Identify activity patterns\n    const hourlyActivity = this.groupByHour(interactions)\n    const peakHours = this.identifyPeakHours(hourlyActivity)\n    \n    // Check for automation signatures\n    const automationSignals = this.detectAutomationTiming(responseTimes)\n    \n    return {\n      pattern: this.classifyTimingPattern(timingVariation, automationSignals),\n      distribution: this.createDistribution(responseTimes),\n      peakHours,\n      automationScore: automationSignals.score\n    }\n  }\n}\n```\n\n#### Anomaly Detection\n\nThe system uses machine learning to detect unusual patterns:\n\n```typescript\nclass AnomalyDetector {\n  private mlModel: AnomalyDetectionModel\n  \n  async detectAnomalousActivity(\n    engagement: RaidEngagement,\n    userProfile: BehavioralProfile\n  ): Promise\u003CAnomalyScore> {\n    // Extract features for ML analysis\n    const features = this.extractAnomalyFeatures(engagement, userProfile)\n    \n    // Run ML-based anomaly detection\n    const mlScore = await this.mlModel.detectAnomalies(features)\n    \n    // Apply rule-based anomaly checks\n    const ruleBasedScore = this.applyAnomalyRules(engagement, userProfile)\n    \n    // Combine scores with confidence weighting\n    const combinedScore = this.combineAnomalyScores(mlScore, ruleBasedScore)\n    \n    return {\n      anomalyProbability: combinedScore.probability,\n      confidence: combinedScore.confidence,\n      detectedAnomalies: combinedScore.anomalies,\n      explanation: this.generateExplanation(combinedScore),\n      severity: this.calculateSeverity(combinedScore)\n    }\n  }\n  \n  private extractAnomalyFeatures(\n    engagement: RaidEngagement,\n    profile: BehavioralProfile\n  ): AnomalyFeatures {\n    return {\n      // Timing anomalies\n      responseTimeDeviation: this.calculateTimeDeviation(\n        engagement.responseTime,\n        profile.responseTimeDistribution\n      ),\n      \n      // Content anomalies\n      contentSimilarityToProfile: this.calculateContentSimilarity(\n        engagement.content,\n        profile.contentInteractionStyle\n      ),\n      \n      // Behavioral anomalies\n      engagementTypeDeviation: this.calculateEngagementDeviation(\n        engagement.type,\n        profile.engagementTypes\n      ),\n      \n      // Context anomalies\n      contextualRelevance: this.calculateContextualFit(\n        engagement,\n        profile.contextualRelevance\n      )\n    }\n  }\n}\n```\n\n### Content Quality Assessment\n\nSophisticated content analysis to ensure meaningful engagement:\n\n\u003CTabs>\n  \u003CTabItem label=\"Quality Metrics\">\n```typescript\ninterface ContentQuality {\n  // Originality metrics\n  originalityScore: number\n  duplicateDetectionScore: number\n  templateUsageScore: number\n  \n  // Relevance metrics\n  contextualRelevance: number\n  topicAlignment: number\n  conversationalFit: number\n  \n  // Language quality\n  grammarScore: number\n  vocabularyRichness: number\n  sentimentAppropriate: number\n  \n  // Engagement value\n  discussionPotential: number\n  informationalValue: number\n  entertainmentValue: number\n}\n\nclass ContentQualityAnalyzer {\n  async assessContentQuality(content: string): Promise\u003CContentQuality> {\n    // Run parallel quality assessments\n    const [\n      originalityAssessment,\n      relevanceAssessment,\n      languageAssessment,\n      valueAssessment\n    ] = await Promise.all([\n      this.assessOriginality(content),\n      this.assessRelevance(content),\n      this.assessLanguageQuality(content),\n      this.assessEngagementValue(content)\n    ])\n    \n    return {\n      originalityScore: originalityAssessment.originality,\n      duplicateDetectionScore: originalityAssessment.duplicateScore,\n      templateUsageScore: originalityAssessment.templateScore,\n      contextualRelevance: relevanceAssessment.contextual,\n      topicAlignment: relevanceAssessment.topicAlignment,\n      conversationalFit: relevanceAssessment.conversational,\n      grammarScore: languageAssessment.grammar,\n      vocabularyRichness: languageAssessment.vocabulary,\n      sentimentAppropriate: languageAssessment.sentiment,\n      discussionPotential: valueAssessment.discussion,\n      informationalValue: valueAssessment.informational,\n      entertainmentValue: valueAssessment.entertainment\n    }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"AI Analysis\">\n```typescript\nclass AIContentAnalyzer {\n  async analyzeContentWithAI(content: string): Promise\u003CAIContentAnalysis> {\n    // Use multiple AI models for comprehensive analysis\n    const [\n      sentimentAnalysis,\n      topicAnalysis,\n      qualityAnalysis,\n      authenticityAnalysis\n    ] = await Promise.all([\n      this.analyzeSentiment(content),\n      this.analyzeTopics(content),\n      this.analyzeQuality(content),\n      this.analyzeAuthenticity(content)\n    ])\n    \n    return {\n      sentiment: sentimentAnalysis,\n      topics: topicAnalysis.topics,\n      topicConfidence: topicAnalysis.confidence,\n      qualityScore: qualityAnalysis.overall,\n      qualityBreakdown: qualityAnalysis.breakdown,\n      authenticityScore: authenticityAnalysis.score,\n      aiGeneratedProbability: authenticityAnalysis.aiProbability,\n      humanLikeFeatures: authenticityAnalysis.humanFeatures\n    }\n  }\n  \n  private async analyzeAuthenticity(content: string): Promise\u003CAuthenticityAnalysis> {\n    // Detect AI-generated content\n    const aiDetectionScore = await this.aiDetectionModel.predict(content)\n    \n    // Analyze human-like features\n    const humanFeatures = {\n      typos: this.countTypos(content),\n      casualLanguage: this.detectCasualLanguage(content),\n      personalTouches: this.detectPersonalTouches(content),\n      emotionalExpression: this.detectEmotionalExpression(content),\n      colloquialisms: this.detectColloquialisms(content)\n    }\n    \n    // Calculate overall authenticity\n    const authenticityScore = this.calculateAuthenticityScore(\n      aiDetectionScore,\n      humanFeatures\n    )\n    \n    return {\n      score: authenticityScore,\n      aiProbability: aiDetectionScore,\n      humanFeatures,\n      confidence: this.calculateConfidence(aiDetectionScore, humanFeatures)\n    }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Spam Detection\">\n```typescript\nclass SpamDetector {\n  async detectSpam(content: string, context: EngagementContext): Promise\u003CSpamScore> {\n    // Multiple spam detection approaches\n    const [\n      keywordBasedScore,\n      patternBasedScore,\n      contextBasedScore,\n      behavioralScore\n    ] = await Promise.all([\n      this.checkSpamKeywords(content),\n      this.checkSpamPatterns(content),\n      this.checkContextualSpam(content, context),\n      this.checkBehavioralSpam(context.userId)\n    ])\n    \n    // Combine scores with weighted average\n    const combinedScore = this.combineSpamScores({\n      keyword: keywordBasedScore,\n      pattern: patternBasedScore,\n      contextual: contextBasedScore,\n      behavioral: behavioralScore\n    })\n    \n    return {\n      isSpam: combinedScore.score > this.config.spamThreshold,\n      spamScore: combinedScore.score,\n      confidence: combinedScore.confidence,\n      detectedTypes: combinedScore.types,\n      explanation: this.generateSpamExplanation(combinedScore)\n    }\n  }\n  \n  private checkSpamPatterns(content: string): PatternSpamScore {\n    const patterns = [\n      // Excessive repetition\n      this.checkExcessiveRepetition(content),\n      \n      // Promotional language\n      this.checkPromotionalLanguage(content),\n      \n      // Generic responses\n      this.checkGenericResponses(content),\n      \n      // Link spam\n      this.checkLinkSpam(content),\n      \n      // Emoji spam\n      this.checkEmojiSpam(content)\n    ]\n    \n    return this.aggregatePatternScores(patterns)\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Bot Detection System\n\n### Advanced Bot Detection\n\nMulti-layered approach to identify automated accounts and behavior:\n\n```typescript\nclass BotDetector {\n  async detectBotBehavior(userId: string): Promise\u003CBotDetectionResult> {\n    // Collect comprehensive user data\n    const userData = await this.collectUserData(userId)\n    \n    // Run parallel bot detection algorithms\n    const [\n      profileAnalysis,\n      behaviorAnalysis,\n      networkAnalysis,\n      contentAnalysis,\n      timingAnalysis\n    ] = await Promise.all([\n      this.analyzeProfile(userData.profile),\n      this.analyzeBehavior(userData.interactions),\n      this.analyzeNetwork(userData.connections),\n      this.analyzeContent(userData.content),\n      this.analyzeTiming(userData.timestamps)\n    ])\n    \n    // Machine learning bot classification\n    const mlPrediction = await this.mlBotClassifier.predict({\n      profile: profileAnalysis,\n      behavior: behaviorAnalysis,\n      network: networkAnalysis,\n      content: contentAnalysis,\n      timing: timingAnalysis\n    })\n    \n    // Combine rule-based and ML approaches\n    const finalScore = this.combineBotScores({\n      ml: mlPrediction,\n      profile: profileAnalysis.botScore,\n      behavior: behaviorAnalysis.botScore,\n      network: networkAnalysis.botScore,\n      content: contentAnalysis.botScore,\n      timing: timingAnalysis.botScore\n    })\n    \n    return {\n      botProbability: finalScore.probability,\n      confidence: finalScore.confidence,\n      botType: finalScore.detectedBotType,\n      evidence: finalScore.evidence,\n      recommendation: this.generateBotRecommendation(finalScore)\n    }\n  }\n  \n  private analyzeProfile(profile: UserProfile): ProfileBotAnalysis {\n    return {\n      // Account characteristics\n      suspiciousAccountAge: this.checkSuspiciousAge(profile.createdAt),\n      genericProfilePicture: this.checkGenericAvatar(profile.avatar),\n      incompleteProfile: this.checkProfileCompleteness(profile),\n      \n      // Username patterns\n      generatedUsernamePattern: this.checkGeneratedUsername(profile.username),\n      numberSuffixPattern: this.checkNumberSuffix(profile.username),\n      \n      // Bio analysis\n      genericBio: this.checkGenericBio(profile.bio),\n      promotionalBio: this.checkPromotionalBio(profile.bio),\n      \n      // Verification status\n      lackOfVerification: this.checkVerificationStatus(profile),\n      \n      botScore: 0 // Calculated from above factors\n    }\n  }\n}\n```\n\n### Real-Time Verification Pipeline\n\nContinuous verification during raid execution:\n\n```typescript\nclass RealTimeVerificationPipeline {\n  private verificationQueue: VerificationQueue\n  private activeVerifications: Map\u003Cstring, VerificationProcess> = new Map()\n  \n  async processEngagementStream(\n    engagementStream: AsyncIterable\u003CRaidEngagement>\n  ): Promise\u003Cvoid> {\n    for await (const engagement of engagementStream) {\n      // Queue engagement for verification\n      await this.verificationQueue.enqueue({\n        engagement,\n        priority: this.calculateVerificationPriority(engagement),\n        timestamp: Date.now()\n      })\n      \n      // Process verifications in parallel\n      this.processVerificationBatch()\n    }\n  }\n  \n  private async processVerificationBatch(): Promise\u003Cvoid> {\n    const batch = await this.verificationQueue.dequeueBatch(\n      this.config.batchSize\n    )\n    \n    const verificationPromises = batch.map(async item => {\n      const verificationId = `${item.engagement.userId}-${Date.now()}`\n      \n      try {\n        // Start verification process\n        const process = this.startVerificationProcess(\n          verificationId,\n          item.engagement\n        )\n        this.activeVerifications.set(verificationId, process)\n        \n        // Run verification\n        const result = await this.verifyEngagement(item.engagement)\n        \n        // Handle result\n        await this.handleVerificationResult(item.engagement, result)\n        \n        return result\n      } catch (error) {\n        logger.error(`Verification failed for ${verificationId}:`, error)\n        return this.createFailureResult(item.engagement, error)\n      } finally {\n        // Clean up\n        this.activeVerifications.delete(verificationId)\n      }\n    })\n    \n    await Promise.all(verificationPromises)\n  }\n  \n  private calculateVerificationPriority(engagement: RaidEngagement): number {\n    let priority = 1.0\n    \n    // Higher priority for suspicious patterns\n    if (engagement.responseTime \u003C 1000) priority += 0.5\n    if (engagement.content.length \u003C 10) priority += 0.3\n    \n    // Higher priority for high-value targets\n    if (engagement.targetValue > 1000) priority += 0.2\n    \n    // Higher priority for new users\n    if (engagement.userAccountAge \u003C 30) priority += 0.4\n    \n    return Math.min(priority, 2.0) // Cap at 2.0\n  }\n}\n```\n\n## Quality Assurance\n\n### Continuous Learning System\n\nThe verification system continuously improves through feedback loops:\n\n```typescript\nclass VerificationLearningSystem {\n  async updateVerificationModels(\n    verificationResults: VerificationResult[],\n    actualOutcomes: OutcomeData[]\n  ): Promise\u003Cvoid> {\n    // Analyze verification accuracy\n    const accuracyMetrics = this.analyzeAccuracy(\n      verificationResults,\n      actualOutcomes\n    )\n    \n    // Identify improvement opportunities\n    const improvements = this.identifyImprovements(accuracyMetrics)\n    \n    // Update ML models\n    if (improvements.mlModelUpdate) {\n      await this.updateMLModels(improvements.trainingData)\n    }\n    \n    // Update rule-based systems\n    if (improvements.ruleUpdates) {\n      await this.updateVerificationRules(improvements.ruleUpdates)\n    }\n    \n    // Update thresholds\n    if (improvements.thresholdAdjustments) {\n      await this.updateThresholds(improvements.thresholdAdjustments)\n    }\n  }\n}\n```\n\nThe engagement verification system represents the quality backbone of NUBI's raid operations, ensuring that every interaction maintains the authentic community engagement that makes raids effective while preventing abuse and maintaining platform relationships.","src/content/docs/telegram-raids/verification.mdx","b92228b04f0a23fa","telegram-raids/verification.mdx","telegram-raids/leaderboards",{"id":212,"data":214,"body":221,"filePath":222,"digest":223,"legacyId":224,"deferredRender":16},{"title":215,"description":216,"editUrl":16,"head":217,"template":47,"sidebar":218,"pagefind":16,"draft":35},"Leaderboards & Gamification","Dynamic leaderboard system with sophisticated scoring algorithms and community gamification features",[],{"order":219,"hidden":35,"attrs":220},3,{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nNUBI's leaderboard system transforms raid participation into an engaging competitive experience through dynamic scoring, seasonal competitions, and multi-dimensional achievement tracking.\n\n## Leaderboard Architecture\n\nThe gamification system operates through multiple interconnected scoring engines that create comprehensive competition frameworks:\n\n```mermaid\ngraph TB\n    subgraph \"Scoring Engine\"\n        SE[ScoreEngine]\n        PA[PointAllocator]\n        MM[MultiplierManager]\n        BD[BonusDistributor]\n    end\n    \n    subgraph \"Leaderboard Types\"\n        GL[Global Leaderboard]\n        RL[Raid Leaderboard]\n        SL[Seasonal Leaderboard]\n        TL[Team Leaderboard]\n        AL[Achievement Leaderboard]\n    end\n    \n    subgraph \"Achievement System\"\n        AT[AchievementTracker]\n        BM[BadgeManager]\n        RM[ReputationManager]\n        SM[StreakManager]\n    end\n    \n    subgraph \"Analytics & Rewards\"\n        PA_Analytics[Performance Analytics]\n        RD[Reward Distribution]\n        RN[Ranking Engine]\n    end\n    \n    SE --> PA\n    SE --> MM\n    SE --> BD\n    \n    PA --> GL\n    PA --> RL\n    PA --> SL\n    PA --> TL\n    PA --> AL\n    \n    AT --> BM\n    AT --> RM\n    AT --> SM\n    \n    GL --> PA_Analytics\n    RL --> RD\n    SL --> RN\n```\n\n## Core Scoring System\n\n### LeaderboardService\n\nThe central service managing all leaderboard operations:\n\n\u003CTabs>\n  \u003CTabItem label=\"Main Service\">\n```typescript\ninterface LeaderboardService {\n  // Score management\n  updateScore(userId: string, scoreData: ScoreUpdate): Promise\u003Cvoid>\n  calculateRaidScore(raidParticipation: RaidParticipation): Promise\u003Cnumber>\n  adjustScoreForQuality(baseScore: number, qualityMetrics: QualityMetrics): Promise\u003Cnumber>\n  \n  // Leaderboard queries\n  getGlobalLeaderboard(options: LeaderboardOptions): Promise\u003CLeaderboardEntry[]>\n  getRaidLeaderboard(raidId: string): Promise\u003CRaidLeaderboardEntry[]>\n  getSeasonalLeaderboard(season: string): Promise\u003CSeasonalEntry[]>\n  getUserRanking(userId: string): Promise\u003CUserRankingDetails>\n  \n  // Achievement tracking\n  processAchievements(userId: string, activity: ActivityData): Promise\u003CAchievement[]>\n  awardBadge(userId: string, badgeId: string): Promise\u003Cvoid>\n  updateStreak(userId: string, activityType: string): Promise\u003CStreakUpdate>\n  \n  // Competition management\n  createSeason(seasonConfig: SeasonConfig): Promise\u003CSeason>\n  createTournament(tournamentConfig: TournamentConfig): Promise\u003CTournament>\n  calculateRewards(leaderboardType: string, timeframe: string): Promise\u003CRewardDistribution>\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Configuration\">\n```yaml\nleaderboard_system:\n  # Global settings\n  update_frequency_seconds: 30\n  cache_duration_minutes: 5\n  max_entries_per_board: 1000\n  \n  # Scoring configuration\n  scoring:\n    base_engagement_points: 10\n    quality_multiplier_range: [0.5, 2.0]\n    timing_bonus_percentage: 20\n    streak_bonus_cap: 100\n    team_collaboration_bonus: 15\n    \n  # Achievement system\n  achievements:\n    enable_dynamic_achievements: true\n    achievement_point_multiplier: 1.5\n    badge_rarity_scoring: true\n    reputation_decay_days: 30\n  \n  # Seasonal competition\n  seasons:\n    duration_days: 30\n    overlap_days: 7\n    reward_tiers: [100, 50, 25, 10, 5]\n    decay_factor: 0.1\n  \n  # Real-time updates\n  realtime:\n    enable_websocket_updates: true\n    update_threshold_points: 5\n    broadcast_top_n: 50\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Implementation\">\n```typescript\nclass LeaderboardService implements Service {\n  constructor(\n    private database: DatabaseConnectionManager,\n    private scoreCalculator: ScoreCalculator,\n    private achievementTracker: AchievementTracker,\n    private realtimeUpdater: RealtimeUpdater\n  ) {}\n  \n  async updateScore(userId: string, scoreData: ScoreUpdate): Promise\u003Cvoid> {\n    // 1. Calculate base score\n    const baseScore = await this.scoreCalculator.calculateBaseScore(scoreData)\n    \n    // 2. Apply quality multipliers\n    const qualityAdjustedScore = await this.applyQualityMultipliers(\n      baseScore,\n      scoreData.qualityMetrics\n    )\n    \n    // 3. Apply contextual bonuses\n    const finalScore = await this.applyContextualBonuses(\n      qualityAdjustedScore,\n      scoreData\n    )\n    \n    // 4. Update user score in database\n    await this.updateUserScore(userId, finalScore, scoreData.context)\n    \n    // 5. Process achievements\n    const newAchievements = await this.achievementTracker.processActivity(\n      userId,\n      scoreData\n    )\n    \n    // 6. Update real-time leaderboards\n    await this.updateRealtimeBoards(userId, finalScore, newAchievements)\n    \n    // 7. Check for ranking changes and broadcast\n    await this.checkAndBroadcastRankingChanges(userId)\n  }\n  \n  private async applyQualityMultipliers(\n    baseScore: number,\n    quality: QualityMetrics\n  ): Promise\u003Cnumber> {\n    let multiplier = 1.0\n    \n    // Content quality multiplier\n    multiplier *= 0.5 + (quality.contentQuality * 1.5)\n    \n    // Authenticity multiplier\n    multiplier *= 0.7 + (quality.authenticityScore * 0.6)\n    \n    // Engagement quality multiplier\n    multiplier *= 0.8 + (quality.engagementValue * 0.4)\n    \n    // Timing quality multiplier\n    if (quality.optimalTiming) {\n      multiplier *= 1.2\n    }\n    \n    // Cap multiplier range\n    multiplier = Math.max(0.5, Math.min(2.0, multiplier))\n    \n    return Math.round(baseScore * multiplier)\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Dynamic Scoring Algorithm\n\nSophisticated multi-factor scoring that rewards quality participation:\n\n```typescript\ninterface ScoreFactors {\n  // Base engagement factors\n  engagementType: EngagementType\n  engagementValue: number\n  targetValue: number\n  \n  // Quality factors\n  contentQuality: number\n  originalityScore: number\n  relevanceScore: number\n  authenticityScore: number\n  \n  // Timing factors\n  responseTime: number\n  optimalTiming: boolean\n  raidPhaseBonus: number\n  \n  // Social factors\n  networkEffect: number\n  viralityPotential: number\n  communityResonance: number\n  \n  // Performance factors\n  consistencyScore: number\n  streakMultiplier: number\n  achievementBonus: number\n}\n\nclass AdvancedScoreCalculator {\n  async calculateComprehensiveScore(\n    participation: RaidParticipation,\n    context: RaidContext\n  ): Promise\u003CDetailedScore> {\n    // 1. Calculate base score from engagement\n    const baseScore = this.calculateBaseEngagementScore(participation)\n    \n    // 2. Apply quality multipliers\n    const qualityScore = await this.applyQualityFactors(baseScore, participation)\n    \n    // 3. Apply timing bonuses\n    const timingScore = this.applyTimingFactors(qualityScore, participation, context)\n    \n    // 4. Apply social amplification\n    const socialScore = await this.applySocialFactors(timingScore, participation)\n    \n    // 5. Apply performance bonuses\n    const performanceScore = await this.applyPerformanceFactors(\n      socialScore,\n      participation.userId\n    )\n    \n    // 6. Apply contextual adjustments\n    const contextualScore = this.applyContextualAdjustments(\n      performanceScore,\n      context\n    )\n    \n    return {\n      finalScore: contextualScore,\n      breakdown: {\n        base: baseScore,\n        quality: qualityScore - baseScore,\n        timing: timingScore - qualityScore,\n        social: socialScore - timingScore,\n        performance: performanceScore - socialScore,\n        contextual: contextualScore - performanceScore\n      },\n      multipliers: this.getAppliedMultipliers(),\n      bonuses: this.getAppliedBonuses()\n    }\n  }\n  \n  private async applySocialFactors(\n    currentScore: number,\n    participation: RaidParticipation\n  ): Promise\u003Cnumber> {\n    // Network effect calculation\n    const networkBonus = await this.calculateNetworkEffect(participation.userId)\n    \n    // Virality potential\n    const viralityBonus = await this.calculateViralityPotential(\n      participation.content,\n      participation.targetMetrics\n    )\n    \n    // Community resonance\n    const resonanceBonus = await this.calculateCommunityResonance(\n      participation.content,\n      participation.communityContext\n    )\n    \n    const socialMultiplier = 1 + (\n      (networkBonus + viralityBonus + resonanceBonus) / 100\n    )\n    \n    return Math.round(currentScore * socialMultiplier)\n  }\n  \n  private async calculateViralityPotential(\n    content: string,\n    targetMetrics: TargetMetrics\n  ): Promise\u003Cnumber> {\n    // Analyze content for viral characteristics\n    const viralFactors = {\n      emotionalTrigger: this.analyzeEmotionalTrigger(content),\n      shareability: this.analyzeShareability(content),\n      memePotential: this.analyzeMemePotential(content),\n      controversyLevel: this.analyzeControversyLevel(content),\n      timeliness: this.analyzeTimeliness(content, targetMetrics.trendingTopics)\n    }\n    \n    // Weight factors based on platform and context\n    return this.weightViralFactors(viralFactors, targetMetrics.platform)\n  }\n}\n```\n\n## Multi-Dimensional Leaderboards\n\n### Global Leaderboard System\n\nComprehensive ranking across all activities and timeframes:\n\n\u003CTabs>\n  \u003CTabItem label=\"Global Rankings\">\n```typescript\ninterface GlobalLeaderboard {\n  // Overall rankings\n  overallRanking: LeaderboardEntry[]\n  weeklyRanking: LeaderboardEntry[]\n  monthlyRanking: LeaderboardEntry[]\n  \n  // Specialized rankings\n  qualityLeaders: QualityLeaderEntry[]\n  consistencyLeaders: ConsistencyLeaderEntry[]\n  innovationLeaders: InnovationLeaderEntry[]\n  \n  // Achievement-based rankings\n  achievementLeaders: AchievementLeaderEntry[]\n  badgeCollectors: BadgeCollectorEntry[]\n  streakMasters: StreakMasterEntry[]\n  \n  // Community impact rankings\n  influenceLeaders: InfluenceLeaderEntry[]\n  mentoshipLeaders: MentorshipLeaderEntry[]\n  collaborationLeaders: CollaborationLeaderEntry[]\n}\n\nclass GlobalLeaderboardManager {\n  async generateGlobalLeaderboard(): Promise\u003CGlobalLeaderboard> {\n    // Run parallel queries for different ranking types\n    const [\n      overall,\n      specialized,\n      achievements,\n      communityImpact\n    ] = await Promise.all([\n      this.generateOverallRankings(),\n      this.generateSpecializedRankings(),\n      this.generateAchievementRankings(),\n      this.generateCommunityImpactRankings()\n    ])\n    \n    return {\n      ...overall,\n      ...specialized,\n      ...achievements,\n      ...communityImpact\n    }\n  }\n  \n  private async generateOverallRankings(): Promise\u003COverallRankings> {\n    // Complex query combining multiple scoring factors\n    const query = `\n      WITH user_scores AS (\n        SELECT \n          user_id,\n          SUM(CASE \n            WHEN created_at >= NOW() - INTERVAL '7 days' \n            THEN score * 1.5 \n            ELSE score \n          END) as weighted_score,\n          COUNT(DISTINCT raid_id) as raids_participated,\n          AVG(quality_score) as avg_quality,\n          MAX(streak_length) as max_streak,\n          SUM(achievement_points) as total_achievement_points\n        FROM user_scores \n        WHERE created_at >= NOW() - INTERVAL '30 days'\n        GROUP BY user_id\n        HAVING COUNT(*) >= 5  -- Minimum activity requirement\n      ),\n      ranked_users AS (\n        SELECT \n          *,\n          ROW_NUMBER() OVER (ORDER BY weighted_score DESC) as global_rank,\n          PERCENT_RANK() OVER (ORDER BY weighted_score DESC) as percentile\n        FROM user_scores\n      )\n      SELECT * FROM ranked_users \n      WHERE global_rank \u003C= 1000\n      ORDER BY weighted_score DESC\n    `\n    \n    const results = await this.database.query(query)\n    return this.formatLeaderboardResults(results)\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Raid-Specific\">\n```typescript\ninterface RaidLeaderboard {\n  raidId: string\n  participants: RaidParticipant[]\n  mvpParticipant: RaidParticipant\n  topPerformers: RaidParticipant[]\n  \n  // Performance categories\n  fastestResponders: RaidParticipant[]\n  highestQuality: RaidParticipant[]\n  mostEngagement: RaidParticipant[]\n  bestTeamPlayers: RaidParticipant[]\n  \n  // Raid statistics\n  totalParticipants: number\n  averageScore: number\n  raidEffectiveness: number\n  communityImpact: number\n}\n\nclass RaidLeaderboardManager {\n  async generateRaidLeaderboard(raidId: string): Promise\u003CRaidLeaderboard> {\n    // Get all raid participants with detailed metrics\n    const participants = await this.getRaidParticipants(raidId)\n    \n    // Calculate comprehensive raid metrics\n    const raidMetrics = await this.calculateRaidMetrics(raidId, participants)\n    \n    // Generate category-specific rankings\n    const categoryRankings = this.generateCategoryRankings(participants)\n    \n    // Identify MVP based on overall contribution\n    const mvp = this.identifyMVP(participants, raidMetrics)\n    \n    return {\n      raidId,\n      participants: participants.sort((a, b) => b.totalScore - a.totalScore),\n      mvpParticipant: mvp,\n      topPerformers: participants.slice(0, 10),\n      fastestResponders: categoryRankings.fastest,\n      highestQuality: categoryRankings.quality,\n      mostEngagement: categoryRankings.engagement,\n      bestTeamPlayers: categoryRankings.teamwork,\n      totalParticipants: participants.length,\n      averageScore: raidMetrics.averageScore,\n      raidEffectiveness: raidMetrics.effectiveness,\n      communityImpact: raidMetrics.communityImpact\n    }\n  }\n  \n  private identifyMVP(\n    participants: RaidParticipant[], \n    metrics: RaidMetrics\n  ): RaidParticipant {\n    // Complex MVP calculation considering multiple factors\n    const mvpScores = participants.map(participant => {\n      const mvpScore = (\n        participant.totalScore * 0.4 +                    // Raw performance\n        participant.qualityScore * 0.25 +                 // Quality contribution\n        participant.teamCollaboration * 0.15 +            // Team collaboration\n        participant.leadershipMoments * 0.1 +             // Leadership moments\n        participant.innovativeContributions * 0.1         // Innovation\n      ) * (1 + participant.consistencyBonus)               // Consistency multiplier\n      \n      return {\n        participant,\n        mvpScore,\n        breakdown: {\n          performance: participant.totalScore * 0.4,\n          quality: participant.qualityScore * 0.25,\n          collaboration: participant.teamCollaboration * 0.15,\n          leadership: participant.leadershipMoments * 0.1,\n          innovation: participant.innovativeContributions * 0.1,\n          consistency: participant.consistencyBonus\n        }\n      }\n    })\n    \n    return mvpScores.sort((a, b) => b.mvpScore - a.mvpScore)[0].participant\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Seasonal Competitions\">\n```typescript\ninterface SeasonalCompetition {\n  seasonId: string\n  startDate: Date\n  endDate: Date\n  theme: string\n  \n  // Competition structure\n  divisions: Division[]\n  tournaments: Tournament[]\n  specialEvents: SpecialEvent[]\n  \n  // Rewards system\n  rewardTiers: RewardTier[]\n  seasonalAchievements: SeasonalAchievement[]\n  exclusiveRewards: ExclusiveReward[]\n}\n\nclass SeasonalCompetitionManager {\n  async createSeason(config: SeasonConfig): Promise\u003CSeasonalCompetition> {\n    // Create season structure\n    const season = await this.database.transaction(async (tx) => {\n      // Create base season\n      const seasonData = await tx.query(`\n        INSERT INTO seasons (theme, start_date, end_date, config)\n        VALUES ($1, $2, $3, $4)\n        RETURNING *\n      `, [config.theme, config.startDate, config.endDate, config])\n      \n      // Create divisions based on user skill levels\n      const divisions = await this.createDivisions(tx, seasonData.id, config)\n      \n      // Schedule tournaments throughout season\n      const tournaments = await this.scheduleTournaments(tx, seasonData.id, config)\n      \n      // Create seasonal achievements\n      const achievements = await this.createSeasonalAchievements(\n        tx, \n        seasonData.id, \n        config\n      )\n      \n      return {\n        ...seasonData,\n        divisions,\n        tournaments,\n        seasonalAchievements: achievements\n      }\n    })\n    \n    // Initialize real-time tracking\n    await this.initializeSeasonalTracking(season.id)\n    \n    return season\n  }\n  \n  private async createDivisions(\n    tx: DatabaseTransaction,\n    seasonId: string,\n    config: SeasonConfig\n  ): Promise\u003CDivision[]> {\n    // Analyze user performance to create balanced divisions\n    const userStats = await this.getUserPerformanceStats()\n    const divisionBreakpoints = this.calculateDivisionBreakpoints(userStats)\n    \n    const divisions = []\n    for (let i = 0; i \u003C config.divisionCount; i++) {\n      const division = await tx.query(`\n        INSERT INTO divisions (season_id, name, min_score, max_score, tier)\n        VALUES ($1, $2, $3, $4, $5)\n        RETURNING *\n      `, [\n        seasonId,\n        config.divisionNames[i],\n        divisionBreakpoints[i].min,\n        divisionBreakpoints[i].max,\n        i + 1\n      ])\n      \n      divisions.push(division)\n    }\n    \n    return divisions\n  }\n  \n  async processSeasonalRewards(seasonId: string): Promise\u003CRewardDistribution> {\n    // Get final season standings\n    const standings = await this.getFinalStandings(seasonId)\n    \n    // Calculate rewards based on performance tiers\n    const rewards = await this.calculateSeasonalRewards(standings)\n    \n    // Distribute rewards\n    const distribution = await this.distributeRewards(rewards)\n    \n    // Generate season summary report\n    await this.generateSeasonSummary(seasonId, standings, distribution)\n    \n    return distribution\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Achievement System\n\n### Dynamic Achievement Tracking\n\nComprehensive achievement system that adapts to user behavior:\n\n```typescript\ninterface Achievement {\n  id: string\n  name: string\n  description: string\n  category: AchievementCategory\n  difficulty: 'bronze' | 'silver' | 'gold' | 'platinum' | 'legendary'\n  \n  // Requirements\n  requirements: AchievementRequirement[]\n  pointValue: number\n  badgeReward?: BadgeReward\n  \n  // Progress tracking\n  progress: AchievementProgress\n  unlockDate?: Date\n  rarity: number // Percentage of users who have unlocked\n}\n\nclass DynamicAchievementSystem {\n  private achievementTemplates: Map\u003Cstring, AchievementTemplate> = new Map()\n  private userProgressCache: Map\u003Cstring, UserProgress> = new Map()\n  \n  async initializeAchievements(): Promise\u003Cvoid> {\n    // Load base achievement templates\n    await this.loadBaseAchievements()\n    \n    // Generate dynamic achievements based on community behavior\n    await this.generateDynamicAchievements()\n    \n    // Initialize tracking for all users\n    await this.initializeUserTracking()\n  }\n  \n  private async generateDynamicAchievements(): Promise\u003Cvoid> {\n    // Analyze community patterns to create relevant achievements\n    const communityPatterns = await this.analyzeCommunityPatterns()\n    \n    for (const pattern of communityPatterns) {\n      if (pattern.significance > 0.7) {\n        const achievement = this.createAchievementFromPattern(pattern)\n        await this.registerDynamicAchievement(achievement)\n      }\n    }\n  }\n  \n  async trackUserActivity(userId: string, activity: ActivityData): Promise\u003CAchievement[]> {\n    // Get user's current progress\n    const userProgress = await this.getUserProgress(userId)\n    \n    // Check all applicable achievements\n    const applicableAchievements = await this.getApplicableAchievements(\n      activity,\n      userProgress\n    )\n    \n    const unlockedAchievements: Achievement[] = []\n    \n    for (const achievement of applicableAchievements) {\n      // Update progress\n      const newProgress = await this.updateAchievementProgress(\n        userId,\n        achievement.id,\n        activity\n      )\n      \n      // Check if achievement is now unlocked\n      if (this.isAchievementUnlocked(newProgress)) {\n        const unlockedAchievement = await this.unlockAchievement(\n          userId,\n          achievement.id\n        )\n        unlockedAchievements.push(unlockedAchievement)\n        \n        // Trigger unlock celebration\n        await this.triggerAchievementCelebration(userId, unlockedAchievement)\n      }\n    }\n    \n    return unlockedAchievements\n  }\n}\n```\n\n### Specialized Achievement Categories\n\n\u003CTabs>\n  \u003CTabItem label=\"Performance Achievements\">\n```typescript\nconst PERFORMANCE_ACHIEVEMENTS = {\n  // Score-based achievements\n  SCORE_MILESTONES: {\n    FIRST_HUNDRED: { threshold: 100, points: 50 },\n    THOUSAND_CLUB: { threshold: 1000, points: 200 },\n    TEN_THOUSAND: { threshold: 10000, points: 500 },\n    SCORE_LEGEND: { threshold: 50000, points: 1000 }\n  },\n  \n  // Streak achievements\n  STREAK_MASTERS: {\n    CONSISTENT_RAIDER: { streakDays: 7, points: 100 },\n    DEDICATION: { streakDays: 30, points: 300 },\n    UNSTOPPABLE: { streakDays: 100, points: 750 },\n    LEGENDARY_STREAK: { streakDays: 365, points: 2000 }\n  },\n  \n  // Quality achievements\n  QUALITY_EXCELLENCE: {\n    QUALITY_CONTRIBUTOR: { averageQuality: 0.8, minRaids: 50 },\n    EXCELLENCE_STANDARD: { averageQuality: 0.9, minRaids: 100 },\n    PERFECTION_SEEKER: { perfectScores: 25 },\n    QUALITY_LEGEND: { perfectScores: 100, averageQuality: 0.95 }\n  }\n}\n\nclass PerformanceAchievementTracker {\n  async checkPerformanceAchievements(\n    userId: string,\n    newScore: number,\n    qualityScore: number\n  ): Promise\u003CAchievement[]> {\n    const unlockedAchievements: Achievement[] = []\n    \n    // Check score milestones\n    const totalScore = await this.getUserTotalScore(userId)\n    const scoreMilestone = this.checkScoreMilestone(totalScore)\n    if (scoreMilestone) {\n      unlockedAchievements.push(scoreMilestone)\n    }\n    \n    // Check quality achievements\n    const qualityStats = await this.getUserQualityStats(userId)\n    const qualityAchievement = this.checkQualityAchievement(qualityStats)\n    if (qualityAchievement) {\n      unlockedAchievements.push(qualityAchievement)\n    }\n    \n    // Check streak achievements\n    const currentStreak = await this.getUserStreak(userId)\n    const streakAchievement = this.checkStreakAchievement(currentStreak)\n    if (streakAchievement) {\n      unlockedAchievements.push(streakAchievement)\n    }\n    \n    return unlockedAchievements\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Social Achievements\">\n```typescript\nconst SOCIAL_ACHIEVEMENTS = {\n  // Community building\n  COMMUNITY_BUILDER: {\n    WELCOMER: { newUsersHelped: 10, points: 150 },\n    MENTOR: { newUsersHelped: 50, points: 400 },\n    COMMUNITY_PILLAR: { newUsersHelped: 200, points: 1000 }\n  },\n  \n  // Collaboration\n  TEAM_PLAYER: {\n    COLLABORATOR: { teamRaids: 25, points: 200 },\n    TEAM_CAPTAIN: { leadershipMoments: 10, points: 300 },\n    SYNERGY_MASTER: { collaborationScore: 0.9, teamRaids: 100 }\n  },\n  \n  // Innovation\n  INNOVATION_LEADER: {\n    CREATIVE_CONTRIBUTOR: { uniqueStrategies: 5, points: 250 },\n    TRENDSETTER: { strategiesCopied: 25, points: 500 },\n    INNOVATION_GENIUS: { gameChangingStrategies: 3, points: 1000 }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Special Event Achievements\">\n```typescript\nconst EVENT_ACHIEVEMENTS = {\n  // Seasonal events\n  SEASONAL_CHAMPIONS: {\n    SPRING_WARRIOR: { seasonWins: 1, season: 'spring' },\n    SUMMER_LEGEND: { seasonRank: 'top-10', season: 'summer' },\n    AUTUMN_MASTER: { seasonPoints: 5000, season: 'autumn' },\n    WINTER_CHAMPION: { seasonMVP: true, season: 'winter' }\n  },\n  \n  // Tournament achievements\n  TOURNAMENT_GLORY: {\n    TOURNAMENT_PARTICIPANT: { tournamentsJoined: 1 },\n    SEMI_FINALIST: { tournamentReached: 'semifinals' },\n    FINALIST: { tournamentReached: 'finals' },\n    TOURNAMENT_CHAMPION: { tournamentsWon: 1 },\n    MULTI_CHAMPION: { tournamentsWon: 5 }\n  },\n  \n  // Special raids\n  SPECIAL_OPERATIONS: {\n    NIGHT_RAIDER: { nightRaids: 10 },\n    WEEKEND_WARRIOR: { weekendRaids: 25 },\n    PRIME_TIME_PLAYER: { primeTimeRaids: 50 },\n    GLOBAL_COORDINATOR: { multiPlatformRaids: 15 }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Real-Time Updates & Visualization\n\n### Live Leaderboard Updates\n\nWebSocket-powered real-time leaderboard updates:\n\n```typescript\nclass RealtimeLeaderboardUpdater {\n  private wsConnections: Map\u003Cstring, WebSocketConnection> = new Map()\n  private updateQueues: Map\u003Cstring, UpdateQueue> = new Map()\n  \n  async broadcastLeaderboardUpdate(update: LeaderboardUpdate): Promise\u003Cvoid> {\n    // Determine affected leaderboards\n    const affectedBoards = this.determineAffectedLeaderboards(update)\n    \n    // Generate update messages for each board\n    const updateMessages = await Promise.all(\n      affectedBoards.map(board => this.generateUpdateMessage(board, update))\n    )\n    \n    // Broadcast to all connected clients\n    for (const message of updateMessages) {\n      await this.broadcastToBoard(message.boardId, message.data)\n    }\n    \n    // Update cached leaderboard data\n    await this.updateLeaderboardCache(affectedBoards, update)\n  }\n  \n  private async broadcastToBoard(boardId: string, data: UpdateData): Promise\u003Cvoid> {\n    const subscribers = this.getSubscribers(boardId)\n    \n    const broadcastPromises = subscribers.map(async connection => {\n      try {\n        await connection.send({\n          type: 'leaderboard_update',\n          boardId,\n          data,\n          timestamp: Date.now()\n        })\n      } catch (error) {\n        // Handle disconnected clients\n        this.handleConnectionError(connection, error)\n      }\n    })\n    \n    await Promise.all(broadcastPromises)\n  }\n}\n```\n\nThe leaderboard and gamification system creates a compelling competitive environment that motivates sustained participation while maintaining focus on quality and authentic community engagement, making raids both effective and enjoyable for all participants.","src/content/docs/telegram-raids/leaderboards.mdx","dfbd32fdfd9df0c8","telegram-raids/leaderboards.mdx","api-reference/websocket-events",{"id":225,"data":227,"body":233,"filePath":234,"digest":235,"legacyId":236,"deferredRender":16},{"title":228,"description":229,"editUrl":16,"head":230,"template":47,"sidebar":231,"pagefind":16,"draft":35},"WebSocket Events","Complete WebSocket API reference for real-time communication with NUBI's multi-transport messaging system",[],{"order":193,"hidden":35,"attrs":232},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nNUBI's WebSocket API provides real-time bidirectional communication for raid coordination, live updates, and interactive features across all supported platforms.\n\n## Connection Management\n\n### Establishing Connection\n\nConnect to NUBI's WebSocket server using the following endpoint patterns:\n\n\u003CTabs>\n  \u003CTabItem label=\"Connection URLs\">\n```typescript\n// Development\nconst devSocket = io('ws://localhost:3000', {\n  transports: ['websocket', 'polling'],\n  forceNew: true\n})\n\n// Production\nconst prodSocket = io('wss://api.anubis.chat', {\n  transports: ['websocket'],\n  secure: true,\n  rejectUnauthorized: true\n})\n\n// With authentication\nconst authSocket = io('wss://api.anubis.chat', {\n  auth: {\n    token: 'your-jwt-token',\n    userId: 'user-id',\n    platform: 'telegram|discord|twitter|web'\n  },\n  query: {\n    version: '1.0',\n    features: ['raids', 'leaderboards', 'realtime']\n  }\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Connection Events\">\n```typescript\n// Connection lifecycle events\nsocket.on('connect', () => {\n  console.log('Connected to NUBI WebSocket')\n  console.log('Socket ID:', socket.id)\n})\n\nsocket.on('disconnect', (reason) => {\n  console.log('Disconnected:', reason)\n  // Reasons: 'io server disconnect', 'io client disconnect', \n  //          'ping timeout', 'transport close', 'transport error'\n})\n\nsocket.on('connect_error', (error) => {\n  console.error('Connection error:', error.message)\n  // Handle authentication failures, network issues, etc.\n})\n\nsocket.on('reconnect', (attemptNumber) => {\n  console.log('Reconnected after', attemptNumber, 'attempts')\n})\n\n// Authentication events\nsocket.on('authenticated', (userData) => {\n  console.log('Authentication successful:', userData)\n  // userData contains user profile, permissions, session info\n})\n\nsocket.on('authentication_error', (error) => {\n  console.error('Authentication failed:', error)\n  // Handle invalid tokens, expired sessions, etc.\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Client Configuration\">\n```typescript\ninterface SocketConfig {\n  // Connection options\n  url: string\n  transports: ('websocket' | 'polling')[]\n  timeout: number\n  forceNew: boolean\n  \n  // Authentication\n  auth?: {\n    token: string\n    userId: string\n    platform: string\n    permissions?: string[]\n  }\n  \n  // Features to enable\n  features: {\n    raids: boolean\n    leaderboards: boolean\n    realtime: boolean\n    analytics: boolean\n  }\n  \n  // Retry configuration\n  reconnection: boolean\n  reconnectionAttempts: number\n  reconnectionDelay: number\n}\n\n// Example configuration\nconst socketConfig: SocketConfig = {\n  url: process.env.WEBSOCKET_URL || 'ws://localhost:3000',\n  transports: ['websocket', 'polling'],\n  timeout: 20000,\n  forceNew: false,\n  \n  auth: {\n    token: await getAuthToken(),\n    userId: getCurrentUserId(),\n    platform: 'web',\n    permissions: ['raids:join', 'leaderboards:view']\n  },\n  \n  features: {\n    raids: true,\n    leaderboards: true,\n    realtime: true,\n    analytics: false\n  },\n  \n  reconnection: true,\n  reconnectionAttempts: 5,\n  reconnectionDelay: 1000\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Raid Coordination Events\n\n### Raid Lifecycle Events\n\nReal-time raid coordination through WebSocket events:\n\n\u003CTabs>\n  \u003CTabItem label=\"Raid Management\">\n```typescript\n// Join a raid room for coordination\nsocket.emit('raid:join', {\n  raidId: 'raid_abc123',\n  userId: 'user_456',\n  capabilities: {\n    platforms: ['telegram', 'twitter'],\n    timezone: 'UTC-5',\n    availableUntil: '2024-01-01T20:00:00Z'\n  }\n})\n\n// Server response\nsocket.on('raid:joined', (data) => {\n  console.log('Joined raid:', data)\n  // data: { raidId, participantCount, strategy, timing, instructions }\n})\n\n// Leave raid room\nsocket.emit('raid:leave', {\n  raidId: 'raid_abc123',\n  userId: 'user_456',\n  reason: 'voluntary' // 'voluntary', 'timeout', 'removed'\n})\n\n// Real-time raid updates\nsocket.on('raid:update', (update) => {\n  switch (update.type) {\n    case 'participant_joined':\n      console.log('New participant:', update.participant)\n      break\n    case 'participant_left':\n      console.log('Participant left:', update.participant)\n      break\n    case 'strategy_updated':\n      console.log('Strategy changed:', update.strategy)\n      break\n    case 'timing_changed':\n      console.log('Timing updated:', update.timing)\n      break\n    case 'phase_changed':\n      console.log('Raid phase:', update.phase)\n      break\n  }\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Raid Execution\">\n```typescript\n// Pre-raid countdown events\nsocket.on('raid:countdown', (data) => {\n  const { secondsRemaining, message, phase } = data\n  \n  if (phase === 'preparation') {\n    displayCountdown(secondsRemaining, 'Preparing...')\n  } else if (phase === 'execution') {\n    displayCountdown(secondsRemaining, 'Get ready!')\n  }\n})\n\n// Raid execution commands\nsocket.on('raid:execute', (command) => {\n  switch (command.action) {\n    case 'engage_now':\n      executeEngagement(command.target, command.strategy)\n      break\n    case 'pause_engagement':\n      pauseCurrentEngagement()\n      break\n    case 'adjust_strategy':\n      updateEngagementStrategy(command.newStrategy)\n      break\n    case 'emergency_stop':\n      stopAllEngagement(command.reason)\n      break\n  }\n})\n\n// Report engagement completion\nsocket.emit('raid:engagement_completed', {\n  raidId: 'raid_abc123',\n  userId: 'user_456',\n  engagement: {\n    platform: 'twitter',\n    targetId: 'tweet_123',\n    action: 'like_and_retweet',\n    timestamp: Date.now(),\n    success: true,\n    response: 'Successfully liked and retweeted'\n  }\n})\n\n// Receive engagement feedback\nsocket.on('raid:engagement_feedback', (feedback) => {\n  const { score, quality, bonuses, nextAction } = feedback\n  updateUserScore(score)\n  displayQualityFeedback(quality)\n  if (nextAction) {\n    scheduleNextAction(nextAction)\n  }\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Raid Monitoring\">\n```typescript\n// Real-time raid metrics\nsocket.on('raid:metrics', (metrics) => {\n  const {\n    participationRate,\n    engagementRate,\n    qualityScore,\n    effectivenessScore,\n    timeRemaining,\n    currentPhase\n  } = metrics\n  \n  updateRaidDashboard({\n    participation: `${participationRate}%`,\n    engagement: `${engagementRate}/min`,\n    quality: qualityScore.toFixed(2),\n    effectiveness: `${effectivenessScore}%`,\n    timeLeft: formatTimeRemaining(timeRemaining),\n    phase: currentPhase\n  })\n})\n\n// Individual performance updates\nsocket.on('raid:performance_update', (performance) => {\n  const {\n    userId,\n    currentScore,\n    rank,\n    qualityRating,\n    streakCount,\n    achievements\n  } = performance\n  \n  if (userId === getCurrentUserId()) {\n    updatePersonalStats({\n      score: currentScore,\n      rank: `#${rank}`,\n      quality: qualityRating,\n      streak: streakCount\n    })\n    \n    // Handle new achievements\n    achievements.forEach(achievement => {\n      showAchievementUnlock(achievement)\n    })\n  }\n})\n\n// Raid completion events\nsocket.on('raid:completed', (results) => {\n  const {\n    raidId,\n    success,\n    finalMetrics,\n    leaderboard,\n    rewards,\n    summary\n  } = results\n  \n  displayRaidResults({\n    success,\n    metrics: finalMetrics,\n    yourRank: leaderboard.find(p => p.userId === getCurrentUserId())?.rank,\n    rewards: rewards.filter(r => r.userId === getCurrentUserId()),\n    summary\n  })\n})\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Leaderboard Events\n\n### Real-Time Rankings\n\nLive leaderboard updates and competitive features:\n\n\u003CTabs>\n  \u003CTabItem label=\"Leaderboard Subscriptions\">\n```typescript\n// Subscribe to leaderboard updates\nsocket.emit('leaderboard:subscribe', {\n  types: ['global', 'weekly', 'seasonal'],\n  userId: 'user_456',\n  updateFrequency: 'realtime' // 'realtime', 'moderate', 'low'\n})\n\n// Unsubscribe from updates\nsocket.emit('leaderboard:unsubscribe', {\n  types: ['global'],\n  userId: 'user_456'\n})\n\n// Leaderboard update events\nsocket.on('leaderboard:update', (update) => {\n  const { type, entries, userRank, changes } = update\n  \n  switch (type) {\n    case 'global':\n      updateGlobalLeaderboard(entries)\n      updateUserRank(userRank)\n      break\n    case 'weekly':\n      updateWeeklyLeaderboard(entries)\n      break\n    case 'seasonal':\n      updateSeasonalLeaderboard(entries)\n      break\n  }\n  \n  // Highlight ranking changes\n  changes.forEach(change => {\n    highlightRankingChange(change.userId, change.direction, change.positions)\n  })\n})\n\n// User-specific ranking events\nsocket.on('ranking:changed', (rankingChange) => {\n  const {\n    oldRank,\n    newRank,\n    leaderboardType,\n    pointsGained,\n    cause\n  } = rankingChange\n  \n  showRankingNotification({\n    direction: newRank \u003C oldRank ? 'up' : 'down',\n    positions: Math.abs(newRank - oldRank),\n    points: pointsGained,\n    reason: cause,\n    boardType: leaderboardType\n  })\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Achievement Events\">\n```typescript\n// Achievement unlock events\nsocket.on('achievement:unlocked', (achievement) => {\n  const {\n    id,\n    name,\n    description,\n    category,\n    difficulty,\n    pointValue,\n    badge,\n    rarity\n  } = achievement\n  \n  // Show achievement celebration\n  showAchievementCelebration({\n    title: name,\n    description,\n    points: `+${pointValue} points`,\n    rarity: `${rarity}% of users have this`,\n    badge: badge?.iconUrl\n  })\n  \n  // Update user's achievement collection\n  addToAchievementCollection(achievement)\n})\n\n// Achievement progress updates\nsocket.on('achievement:progress', (progress) => {\n  const {\n    achievementId,\n    currentProgress,\n    totalRequired,\n    percentComplete\n  } = progress\n  \n  updateAchievementProgress(achievementId, {\n    current: currentProgress,\n    total: totalRequired,\n    percent: percentComplete\n  })\n  \n  // Show progress milestone notifications\n  if (percentComplete >= 50 && percentComplete \u003C 75) {\n    showProgressNotification(achievementId, 'halfway')\n  } else if (percentComplete >= 75 && percentComplete \u003C 100) {\n    showProgressNotification(achievementId, 'almost_complete')\n  }\n})\n\n// Badge collection events\nsocket.on('badge:earned', (badge) => {\n  const { id, name, iconUrl, category, earnedAt } = badge\n  \n  showBadgeEarned({\n    name,\n    icon: iconUrl,\n    category,\n    timestamp: earnedAt\n  })\n  \n  addToBadgeCollection(badge)\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Competition Events\">\n```typescript\n// Tournament events\nsocket.on('tournament:started', (tournament) => {\n  const {\n    id,\n    name,\n    participants,\n    brackets,\n    rules,\n    schedule\n  } = tournament\n  \n  showTournamentNotification({\n    title: `${name} has started!`,\n    participants: participants.length,\n    yourBracket: brackets.find(b => \n      b.participants.includes(getCurrentUserId())\n    ),\n    nextMatch: schedule.nextMatch\n  })\n})\n\nsocket.on('tournament:match_ready', (match) => {\n  const { tournamentId, matchId, opponent, deadline } = match\n  \n  showMatchNotification({\n    tournamentName: tournament.name,\n    opponent: opponent.username,\n    deadline: formatDeadline(deadline),\n    action: 'Join match room'\n  })\n})\n\n// Seasonal competition events\nsocket.on('season:phase_change', (phaseData) => {\n  const { season, newPhase, timeRemaining, rewards } = phaseData\n  \n  switch (newPhase) {\n    case 'final_week':\n      showSeasonAlert('Final week! Push for rewards!')\n      break\n    case 'playoffs':\n      showSeasonAlert('Playoffs begin! Elite competition starts now.')\n      break\n    case 'ended':\n      showSeasonEnded(season.results, rewards)\n      break\n  }\n})\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Platform Integration Events\n\n### Multi-Platform Synchronization\n\nCross-platform messaging and coordination events:\n\n\u003CTabs>\n  \u003CTabItem label=\"Message Broadcasting\">\n```typescript\n// Send message to multiple platforms\nsocket.emit('message:broadcast', {\n  content: 'Check out this amazing project! 🚀',\n  platforms: ['telegram', 'discord', 'twitter'],\n  targeting: {\n    telegram: { chatId: '@anubis_community' },\n    discord: { channelId: '123456789' },\n    twitter: { hashtags: ['#AnubisChat', '#AI'] }\n  },\n  scheduling: {\n    immediate: false,\n    scheduledTime: '2024-01-01T15:00:00Z',\n    timezone: 'UTC'\n  }\n})\n\n// Message delivery confirmations\nsocket.on('message:delivered', (delivery) => {\n  const { messageId, platform, success, timestamp, response } = delivery\n  \n  updateMessageStatus(messageId, platform, {\n    status: success ? 'delivered' : 'failed',\n    deliveredAt: timestamp,\n    platformResponse: response\n  })\n})\n\n// Cross-platform message synchronization\nsocket.on('message:sync', (syncData) => {\n  const {\n    originalPlatform,\n    targetPlatforms,\n    messageContent,\n    conversationContext\n  } = syncData\n  \n  // Sync conversation across platforms\n  syncConversationState(originalPlatform, targetPlatforms, {\n    content: messageContent,\n    context: conversationContext\n  })\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Identity Linking\">\n```typescript\n// Link platform identities\nsocket.emit('identity:link', {\n  primaryUserId: 'user_456',\n  platform: 'discord',\n  platformUserId: 'discord_789',\n  verificationCode: 'ABC123'\n})\n\n// Identity linking confirmation\nsocket.on('identity:linked', (linkData) => {\n  const {\n    userId,\n    platform,\n    platformUserId,\n    linkedAt,\n    totalPlatforms\n  } = linkData\n  \n  showIdentityLinked({\n    platform,\n    platformId: platformUserId,\n    totalConnected: totalPlatforms,\n    timestamp: linkedAt\n  })\n  \n  // Update user's connected platforms\n  updateConnectedPlatforms(linkData)\n})\n\n// Identity verification events\nsocket.on('identity:verification_required', (verification) => {\n  const { platform, verificationMethod, code, expiresAt } = verification\n  \n  showVerificationPrompt({\n    platform,\n    method: verificationMethod, // 'dm', 'mention', 'reaction'\n    code,\n    expiresIn: expiresAt - Date.now()\n  })\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Platform Status\">\n```typescript\n// Platform connectivity status\nsocket.on('platform:status_change', (statusUpdate) => {\n  const { platform, status, lastSeen, capabilities } = statusUpdate\n  \n  updatePlatformStatus(platform, {\n    online: status === 'online',\n    lastActive: lastSeen,\n    features: capabilities\n  })\n  \n  // Show connectivity alerts\n  if (status === 'offline') {\n    showPlatformOfflineAlert(platform)\n  } else if (status === 'online') {\n    showPlatformOnlineAlert(platform)\n  }\n})\n\n// Platform rate limit warnings\nsocket.on('platform:rate_limit_warning', (warning) => {\n  const { platform, limitType, usage, resetAt } = warning\n  \n  showRateLimitWarning({\n    platform,\n    type: limitType, // 'messages', 'requests', 'actions'\n    currentUsage: usage,\n    resetTime: resetAt\n  })\n})\n\n// Feature availability updates\nsocket.on('platform:features_updated', (featureUpdate) => {\n  const { platform, availableFeatures, disabledFeatures } = featureUpdate\n  \n  updatePlatformFeatures(platform, {\n    available: availableFeatures,\n    disabled: disabledFeatures\n  })\n})\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Analytics & Monitoring Events\n\n### Performance Tracking\n\nReal-time analytics and system monitoring:\n\n\u003CTabs>\n  \u003CTabItem label=\"Performance Metrics\">\n```typescript\n// Subscribe to performance metrics\nsocket.emit('analytics:subscribe', {\n  metrics: ['response_time', 'success_rate', 'user_activity'],\n  interval: 30000, // 30 seconds\n  userId: 'user_456'\n})\n\n// Real-time performance data\nsocket.on('analytics:metrics', (metrics) => {\n  const {\n    responseTime,\n    successRate,\n    activeUsers,\n    raidEffectiveness,\n    systemHealth\n  } = metrics\n  \n  updatePerformanceDashboard({\n    avgResponseTime: `${responseTime}ms`,\n    successRate: `${successRate}%`,\n    activeUsers: activeUsers.count,\n    raidSuccess: `${raidEffectiveness}%`,\n    systemStatus: systemHealth.overall\n  })\n})\n\n// User activity analytics\nsocket.on('analytics:user_activity', (activity) => {\n  const {\n    totalEngagements,\n    platformBreakdown,\n    qualityTrends,\n    performanceInsights\n  } = activity\n  \n  updateActivityDashboard({\n    engagements: totalEngagements,\n    platforms: platformBreakdown,\n    qualityTrend: qualityTrends.direction,\n    insights: performanceInsights\n  })\n})\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"System Alerts\">\n```typescript\n// System health alerts\nsocket.on('system:alert', (alert) => {\n  const { level, component, message, timestamp, actionRequired } = alert\n  \n  switch (level) {\n    case 'critical':\n      showCriticalAlert(message, actionRequired)\n      break\n    case 'warning':\n      showWarningAlert(message)\n      break\n    case 'info':\n      showInfoAlert(message)\n      break\n  }\n  \n  // Log alert for debugging\n  console[level](`[${component}] ${message}`, { timestamp, alert })\n})\n\n// Maintenance notifications\nsocket.on('system:maintenance', (maintenance) => {\n  const { type, startTime, duration, affectedServices } = maintenance\n  \n  showMaintenanceNotification({\n    type, // 'scheduled', 'emergency', 'completed'\n    when: startTime,\n    duration: formatDuration(duration),\n    services: affectedServices\n  })\n})\n\n// Service availability updates\nsocket.on('system:service_status', (serviceStatus) => {\n  const { service, status, responseTime, errorRate } = serviceStatus\n  \n  updateServiceIndicator(service, {\n    online: status === 'operational',\n    latency: responseTime,\n    errors: errorRate\n  })\n})\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Error Handling & Recovery\n\n### Connection Recovery\n\nRobust error handling and automatic recovery mechanisms:\n\n```typescript\nclass WebSocketManager {\n  private socket: Socket\n  private reconnectAttempts = 0\n  private maxReconnectAttempts = 5\n  private eventQueue: QueuedEvent[] = []\n  \n  constructor(config: SocketConfig) {\n    this.initializeSocket(config)\n    this.setupErrorHandling()\n    this.setupReconnection()\n  }\n  \n  private setupErrorHandling(): void {\n    // Handle connection errors\n    this.socket.on('connect_error', (error) => {\n      console.error('Connection error:', error)\n      this.handleConnectionError(error)\n    })\n    \n    // Handle authentication errors\n    this.socket.on('authentication_error', (error) => {\n      console.error('Authentication failed:', error)\n      this.handleAuthError(error)\n    })\n    \n    // Handle server errors\n    this.socket.on('error', (error) => {\n      console.error('Server error:', error)\n      this.handleServerError(error)\n    })\n    \n    // Handle rate limiting\n    this.socket.on('rate_limited', (limitInfo) => {\n      console.warn('Rate limited:', limitInfo)\n      this.handleRateLimit(limitInfo)\n    })\n  }\n  \n  private setupReconnection(): void {\n    this.socket.on('disconnect', (reason) => {\n      console.log('Disconnected:', reason)\n      \n      if (reason === 'io server disconnect') {\n        // Server disconnected us - don't reconnect automatically\n        this.handleServerDisconnect()\n      } else {\n        // Network/client issues - attempt reconnection\n        this.attemptReconnection()\n      }\n    })\n    \n    this.socket.on('reconnect', (attemptNumber) => {\n      console.log(`Reconnected after ${attemptNumber} attempts`)\n      this.onSuccessfulReconnect()\n    })\n    \n    this.socket.on('reconnect_failed', () => {\n      console.error('Reconnection failed after maximum attempts')\n      this.handleReconnectionFailure()\n    })\n  }\n  \n  private async onSuccessfulReconnect(): Promise\u003Cvoid> {\n    // Re-authenticate if necessary\n    await this.reAuthenticate()\n    \n    // Restore subscriptions\n    await this.restoreSubscriptions()\n    \n    // Process queued events\n    await this.processEventQueue()\n    \n    // Sync any missed state\n    await this.syncMissedState()\n  }\n  \n  private async processEventQueue(): Promise\u003Cvoid> {\n    while (this.eventQueue.length > 0) {\n      const event = this.eventQueue.shift()\n      if (event && Date.now() - event.timestamp \u003C 300000) { // 5 minutes\n        try {\n          this.socket.emit(event.type, event.data)\n        } catch (error) {\n          console.error('Failed to replay queued event:', error)\n        }\n      }\n    }\n  }\n}\n```\n\nThe WebSocket API provides comprehensive real-time capabilities for all aspects of NUBI's functionality, enabling seamless coordination, live updates, and interactive features across all supported platforms.","src/content/docs/api-reference/websocket-events.mdx","148ea8161f36c81d","api-reference/websocket-events.mdx","api-reference/service-apis",{"id":237,"data":239,"body":245,"filePath":246,"digest":247,"legacyId":248,"deferredRender":16},{"title":240,"description":241,"editUrl":16,"head":242,"template":47,"sidebar":243,"pagefind":16,"draft":35},"Service APIs","Comprehensive HTTP REST API reference for NUBI's core services and functionalities",[],{"order":206,"hidden":35,"attrs":244},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nNUBI exposes powerful HTTP REST APIs for programmatic access to all core functionalities, enabling integration with external systems and custom applications.\n\n## API Authentication\n\n### Authentication Methods\n\nNUBI supports multiple authentication mechanisms for different use cases:\n\n\u003CTabs>\n  \u003CTabItem label=\"JWT Bearer Token\">\n```bash\n# Obtain authentication token\ncurl -X POST https://api.anubis.chat/auth/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"your-username\",\n    \"password\": \"your-password\",\n    \"platform\": \"api\"\n  }'\n\n# Response\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"expiresAt\": \"2024-01-01T12:00:00Z\",\n  \"refreshToken\": \"refresh-token-here\",\n  \"user\": {\n    \"id\": \"user_456\",\n    \"username\": \"your-username\",\n    \"permissions\": [\"raids:read\", \"raids:write\", \"leaderboards:read\"]\n  }\n}\n\n# Use token in subsequent requests\ncurl -X GET https://api.anubis.chat/api/v1/raids \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"API Key\">\n```bash\n# Generate API key (requires JWT authentication)\ncurl -X POST https://api.anubis.chat/api/v1/auth/api-keys \\\n  -H \"Authorization: Bearer your-jwt-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"My Application\",\n    \"permissions\": [\"raids:read\", \"leaderboards:read\"],\n    \"expiresAt\": \"2024-12-31T23:59:59Z\"\n  }'\n\n# Response\n{\n  \"apiKey\": \"nubi_ak_1234567890abcdef\",\n  \"keyId\": \"key_789\",\n  \"name\": \"My Application\",\n  \"permissions\": [\"raids:read\", \"leaderboards:read\"],\n  \"createdAt\": \"2024-01-01T00:00:00Z\",\n  \"expiresAt\": \"2024-12-31T23:59:59Z\"\n}\n\n# Use API key in requests\ncurl -X GET https://api.anubis.chat/api/v1/raids \\\n  -H \"X-API-Key: nubi_ak_1234567890abcdef\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Platform Integration\">\n```typescript\n// Platform-specific authentication for bots/integrations\ninterface PlatformAuth {\n  platform: 'telegram' | 'discord' | 'twitter'\n  credentials: {\n    telegram?: {\n      botToken: string\n      chatId?: string\n    }\n    discord?: {\n      botToken: string\n      guildId?: string\n    }\n    twitter?: {\n      bearerToken: string\n      apiKey: string\n      apiSecret: string\n      accessToken: string\n      accessTokenSecret: string\n    }\n  }\n}\n\n// Register platform integration\nconst response = await fetch('https://api.anubis.chat/api/v1/integrations', {\n  method: 'POST',\n  headers: {\n    'Authorization': 'Bearer your-jwt-token',\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    platform: 'telegram',\n    name: 'My Telegram Bot',\n    credentials: {\n      botToken: 'your-bot-token',\n      chatId: '@your-channel'\n    },\n    permissions: ['message:send', 'raids:coordinate']\n  })\n})\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Raid Management APIs\n\n### Raid Operations\n\nComplete CRUD operations for raid management:\n\n\u003CTabs>\n  \u003CTabItem label=\"Create Raid\">\n```bash\n# Create a new raid\ncurl -X POST https://api.anubis.chat/api/v1/raids \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"title\": \"Community Support Raid\",\n    \"description\": \"Support our community member'\\''s project launch\",\n    \"target\": {\n      \"url\": \"https://twitter.com/user/status/123456789\",\n      \"platform\": \"twitter\",\n      \"type\": \"post\"\n    },\n    \"strategy\": {\n      \"approach\": \"moderate\",\n      \"timeline\": {\n        \"startTime\": \"2024-01-01T15:00:00Z\",\n        \"duration\": 3600000,\n        \"phases\": [\n          {\n            \"name\": \"preparation\",\n            \"duration\": 900000,\n            \"actions\": [\"gather_participants\", \"brief_strategy\"]\n          },\n          {\n            \"name\": \"execution\",\n            \"duration\": 1800000,\n            \"actions\": [\"coordinate_engagement\", \"monitor_progress\"]\n          },\n          {\n            \"name\": \"followup\",\n            \"duration\": 900000,\n            \"actions\": [\"assess_results\", \"distribute_rewards\"]\n          }\n        ]\n      },\n      \"platforms\": [\"telegram\", \"twitter\"],\n      \"maxParticipants\": 100,\n      \"qualityRequirements\": {\n        \"minAuthenticityScore\": 0.7,\n        \"minQualityScore\": 0.6,\n        \"maxBotProbability\": 0.3\n      }\n    },\n    \"rewards\": {\n      \"basePoints\": 50,\n      \"qualityMultiplier\": 1.5,\n      \"achievements\": [\"COMMUNITY_SUPPORTER\", \"TEAM_PLAYER\"]\n    }\n  }'\n\n# Response\n{\n  \"raid\": {\n    \"id\": \"raid_abc123\",\n    \"title\": \"Community Support Raid\",\n    \"status\": \"scheduled\",\n    \"createdAt\": \"2024-01-01T10:00:00Z\",\n    \"startTime\": \"2024-01-01T15:00:00Z\",\n    \"participants\": [],\n    \"coordinationRooms\": {\n      \"telegram\": \"https://t.me/+coord_abc123\",\n      \"websocket\": \"wss://api.anubis.chat/raids/raid_abc123\"\n    }\n  },\n  \"joinInstructions\": {\n    \"telegram\": \"Use /joinraid raid_abc123 in @anubis_raids_bot\",\n    \"websocket\": \"Connect to coordination room and emit 'raid:join'\"\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Get Raids\">\n```bash\n# List all raids with filtering and pagination\ncurl -X GET \"https://api.anubis.chat/api/v1/raids?status=active&platform=twitter&limit=20&offset=0\" \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"raids\": [\n    {\n      \"id\": \"raid_abc123\",\n      \"title\": \"Community Support Raid\",\n      \"status\": \"active\",\n      \"participants\": 25,\n      \"maxParticipants\": 100,\n      \"progress\": {\n        \"phase\": \"execution\",\n        \"completionPercent\": 45,\n        \"timeRemaining\": 1800000\n      },\n      \"metrics\": {\n        \"engagementRate\": 0.85,\n        \"qualityScore\": 0.78,\n        \"effectivenessScore\": 0.82\n      }\n    }\n  ],\n  \"pagination\": {\n    \"total\": 150,\n    \"limit\": 20,\n    \"offset\": 0,\n    \"hasNext\": true,\n    \"hasPrevious\": false\n  }\n}\n\n# Get specific raid details\ncurl -X GET https://api.anubis.chat/api/v1/raids/raid_abc123 \\\n  -H \"Authorization: Bearer your-token\"\n\n# Detailed response with full raid information\n{\n  \"raid\": {\n    \"id\": \"raid_abc123\",\n    \"title\": \"Community Support Raid\",\n    \"description\": \"Support our community member's project launch\",\n    \"status\": \"active\",\n    \"target\": {\n      \"url\": \"https://twitter.com/user/status/123456789\",\n      \"platform\": \"twitter\",\n      \"analysis\": {\n        \"engagementPotential\": 0.85,\n        \"viralityScore\": 0.67,\n        \"riskAssessment\": \"low\"\n      }\n    },\n    \"strategy\": { /* full strategy object */ },\n    \"participants\": [\n      {\n        \"userId\": \"user_456\",\n        \"username\": \"participant1\",\n        \"joinedAt\": \"2024-01-01T14:30:00Z\",\n        \"status\": \"active\",\n        \"performance\": {\n          \"engagements\": 5,\n          \"qualityScore\": 0.82,\n          \"currentRank\": 3\n        }\n      }\n    ],\n    \"metrics\": {\n      \"realtime\": {\n        \"activeParticipants\": 23,\n        \"engagementsPerMinute\": 12,\n        \"averageQuality\": 0.78,\n        \"successRate\": 0.94\n      },\n      \"cumulative\": {\n        \"totalEngagements\": 145,\n        \"totalReach\": 12500,\n        \"qualityDistribution\": {\n          \"excellent\": 45,\n          \"good\": 78,\n          \"average\": 20,\n          \"poor\": 2\n        }\n      }\n    }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Raid Participation\">\n```bash\n# Join a raid\ncurl -X POST https://api.anubis.chat/api/v1/raids/raid_abc123/join \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"platforms\": [\"telegram\", \"twitter\"],\n    \"availability\": {\n      \"startTime\": \"2024-01-01T15:00:00Z\",\n      \"endTime\": \"2024-01-01T18:00:00Z\",\n      \"timezone\": \"UTC-5\"\n    },\n    \"preferences\": {\n      \"notifications\": true,\n      \"autoExecute\": false,\n      \"qualityOverSpeed\": true\n    }\n  }'\n\n# Response\n{\n  \"joined\": true,\n  \"participant\": {\n    \"userId\": \"user_456\",\n    \"joinedAt\": \"2024-01-01T14:30:00Z\",\n    \"status\": \"waiting\",\n    \"assignedRole\": \"executor\",\n    \"coordinationChannels\": {\n      \"telegram\": \"@anubis_raids_bot\",\n      \"websocket\": \"wss://api.anubis.chat/raids/raid_abc123\"\n    }\n  },\n  \"raidInfo\": {\n    \"briefing\": \"Target engagement starts at 15:00 UTC. Focus on quality interactions.\",\n    \"instructions\": [\n      \"Wait for coordination signals\",\n      \"Engage authentically with the target content\",\n      \"Report completion through designated channels\"\n    ],\n    \"timeline\": {\n      \"preparation\": \"14:45 - 15:00 UTC\",\n      \"execution\": \"15:00 - 15:30 UTC\",\n      \"cleanup\": \"15:30 - 15:45 UTC\"\n    }\n  }\n}\n\n# Leave a raid\ncurl -X POST https://api.anubis.chat/api/v1/raids/raid_abc123/leave \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"reason\": \"schedule_conflict\",\n    \"message\": \"Sorry, had to leave due to unexpected meeting\"\n  }'\n\n# Submit engagement completion\ncurl -X POST https://api.anubis.chat/api/v1/raids/raid_abc123/engagements \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"platform\": \"twitter\",\n    \"targetId\": \"tweet_123456789\",\n    \"actions\": [\"like\", \"retweet\", \"comment\"],\n    \"content\": {\n      \"comment\": \"Great project! Excited to see where this goes 🚀\"\n    },\n    \"timestamp\": \"2024-01-01T15:15:00Z\",\n    \"success\": true,\n    \"evidence\": {\n      \"screenshots\": [\"https://cdn.anubis.chat/evidence/user456_engagement1.jpg\"],\n      \"platformResponse\": {\n        \"likeId\": \"like_789\",\n        \"retweetId\": \"retweet_890\",\n        \"commentId\": \"comment_901\"\n      }\n    }\n  }'\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Leaderboard APIs\n\n### Rankings and Statistics\n\nAccess leaderboard data and user statistics:\n\n\u003CTabs>\n  \u003CTabItem label=\"Global Leaderboards\">\n```bash\n# Get global leaderboard\ncurl -X GET \"https://api.anubis.chat/api/v1/leaderboards/global?timeframe=monthly&limit=50&offset=0\" \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"leaderboard\": {\n    \"type\": \"global\",\n    \"timeframe\": \"monthly\",\n    \"generatedAt\": \"2024-01-01T12:00:00Z\",\n    \"entries\": [\n      {\n        \"rank\": 1,\n        \"userId\": \"user_123\",\n        \"username\": \"TopRaider\",\n        \"score\": 15750,\n        \"change\": {\n          \"direction\": \"up\",\n          \"positions\": 2,\n          \"since\": \"weekly\"\n        },\n        \"stats\": {\n          \"raidsParticipated\": 45,\n          \"averageQuality\": 0.89,\n          \"winRate\": 0.78,\n          \"achievements\": 23\n        },\n        \"badges\": [\"LEGENDARY_RAIDER\", \"QUALITY_MASTER\", \"STREAK_KING\"],\n        \"profile\": {\n          \"avatar\": \"https://cdn.anubis.chat/avatars/user123.jpg\",\n          \"title\": \"Raid Commander\",\n          \"joinedAt\": \"2023-06-15T10:00:00Z\"\n        }\n      }\n      // ... more entries\n    ]\n  },\n  \"userPosition\": {\n    \"rank\": 15,\n    \"score\": 8425,\n    \"percentile\": 85,\n    \"pointsToNextRank\": 125\n  },\n  \"pagination\": {\n    \"total\": 500,\n    \"limit\": 50,\n    \"offset\": 0,\n    \"hasNext\": true\n  }\n}\n\n# Get specialized leaderboards\ncurl -X GET https://api.anubis.chat/api/v1/leaderboards/quality \\\n  -H \"Authorization: Bearer your-token\"\n\ncurl -X GET https://api.anubis.chat/api/v1/leaderboards/consistency \\\n  -H \"Authorization: Bearer your-token\"\n\ncurl -X GET https://api.anubis.chat/api/v1/leaderboards/achievements \\\n  -H \"Authorization: Bearer your-token\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"User Statistics\">\n```bash\n# Get user's detailed statistics\ncurl -X GET https://api.anubis.chat/api/v1/users/user_456/stats \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"user\": {\n    \"id\": \"user_456\",\n    \"username\": \"example_user\",\n    \"profile\": {\n      \"avatar\": \"https://cdn.anubis.chat/avatars/user456.jpg\",\n      \"title\": \"Active Raider\",\n      \"joinedAt\": \"2023-08-20T14:30:00Z\"\n    }\n  },\n  \"statistics\": {\n    \"overall\": {\n      \"totalScore\": 8425,\n      \"globalRank\": 15,\n      \"percentile\": 85,\n      \"level\": 42\n    },\n    \"raids\": {\n      \"totalParticipated\": 127,\n      \"totalWon\": 98,\n      \"winRate\": 0.772,\n      \"averageRank\": 8.5,\n      \"mvpCount\": 15,\n      \"currentStreak\": 12,\n      \"longestStreak\": 28\n    },\n    \"quality\": {\n      \"averageScore\": 0.83,\n      \"qualityTrend\": \"improving\",\n      \"perfectScores\": 18,\n      \"authenticityRate\": 0.96,\n      \"contentOriginality\": 0.78\n    },\n    \"achievements\": {\n      \"total\": 47,\n      \"breakdown\": {\n        \"bronze\": 25,\n        \"silver\": 15,\n        \"gold\": 6,\n        \"platinum\": 1,\n        \"legendary\": 0\n      },\n      \"recentUnlocks\": [\n        {\n          \"id\": \"TEAM_PLAYER_GOLD\",\n          \"name\": \"Team Player - Gold\",\n          \"unlockedAt\": \"2024-01-01T10:30:00Z\"\n        }\n      ]\n    },\n    \"social\": {\n      \"followersGained\": 2500,\n      \"networkSize\": 450,\n      \"influenceScore\": 0.67,\n      \"mentorshipRating\": 4.8,\n      \"collaborationIndex\": 0.84\n    },\n    \"platforms\": {\n      \"telegram\": {\n        \"engagements\": 850,\n        \"successRate\": 0.94,\n        \"averageQuality\": 0.81\n      },\n      \"twitter\": {\n        \"engagements\": 1200,\n        \"successRate\": 0.89,\n        \"averageQuality\": 0.85\n      },\n      \"discord\": {\n        \"engagements\": 350,\n        \"successRate\": 0.97,\n        \"averageQuality\": 0.79\n      }\n    }\n  },\n  \"trends\": {\n    \"scoreProgression\": [\n      { \"date\": \"2024-01-01\", \"score\": 8425 },\n      { \"date\": \"2023-12-01\", \"score\": 7820 },\n      { \"date\": \"2023-11-01\", \"score\": 7250 }\n    ],\n    \"qualityProgression\": [\n      { \"date\": \"2024-01-01\", \"quality\": 0.83 },\n      { \"date\": \"2023-12-01\", \"quality\": 0.79 },\n      { \"date\": \"2023-11-01\", \"quality\": 0.76 }\n    ],\n    \"participationTrend\": \"stable\",\n    \"performanceTrend\": \"improving\"\n  }\n}\n\n# Compare users\ncurl -X GET \"https://api.anubis.chat/api/v1/users/compare?users=user_456,user_789\" \\\n  -H \"Authorization: Bearer your-token\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Achievements\">\n```bash\n# Get all achievements\ncurl -X GET https://api.anubis.chat/api/v1/achievements \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"achievements\": [\n    {\n      \"id\": \"FIRST_RAID\",\n      \"name\": \"Welcome Aboard\",\n      \"description\": \"Complete your first raid successfully\",\n      \"category\": \"milestone\",\n      \"difficulty\": \"bronze\",\n      \"pointValue\": 50,\n      \"requirements\": {\n        \"type\": \"raids_completed\",\n        \"threshold\": 1,\n        \"conditions\": [\"success\"]\n      },\n      \"rarity\": 0.95,\n      \"unlockRate\": \"95% of users\",\n      \"badge\": {\n        \"iconUrl\": \"https://cdn.anubis.chat/badges/first_raid.svg\",\n        \"color\": \"#CD7F32\"\n      }\n    }\n    // ... more achievements\n  ],\n  \"categories\": [\n    {\n      \"name\": \"milestone\",\n      \"displayName\": \"Milestones\",\n      \"description\": \"Major accomplishment markers\",\n      \"achievementCount\": 25\n    },\n    {\n      \"name\": \"quality\",\n      \"displayName\": \"Quality Excellence\",\n      \"description\": \"Recognition for high-quality contributions\",\n      \"achievementCount\": 15\n    }\n    // ... more categories\n  ]\n}\n\n# Get user's achievement progress\ncurl -X GET https://api.anubis.chat/api/v1/users/user_456/achievements \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response includes unlocked achievements and progress toward locked ones\n{\n  \"unlocked\": [\n    {\n      \"achievement\": {\n        \"id\": \"FIRST_RAID\",\n        \"name\": \"Welcome Aboard\",\n        // ... full achievement details\n      },\n      \"unlockedAt\": \"2023-08-20T15:45:00Z\",\n      \"rank\": 1245 // Your unlock rank among all users\n    }\n  ],\n  \"inProgress\": [\n    {\n      \"achievement\": {\n        \"id\": \"HUNDRED_RAIDS\",\n        \"name\": \"Century Mark\",\n        \"description\": \"Complete 100 successful raids\"\n      },\n      \"progress\": {\n        \"current\": 87,\n        \"required\": 100,\n        \"percentage\": 87\n      },\n      \"estimatedCompletion\": \"2024-02-15T00:00:00Z\"\n    }\n  ]\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## User Management APIs\n\n### Profile and Preferences\n\nUser account management and customization:\n\n\u003CTabs>\n  \u003CTabItem label=\"Profile Management\">\n```bash\n# Get user profile\ncurl -X GET https://api.anubis.chat/api/v1/users/user_456 \\\n  -H \"Authorization: Bearer your-token\"\n\n# Update user profile\ncurl -X PATCH https://api.anubis.chat/api/v1/users/user_456 \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"profile\": {\n      \"displayName\": \"Elite Raider\",\n      \"bio\": \"Experienced community coordinator with focus on quality engagement\",\n      \"timezone\": \"UTC-5\",\n      \"preferences\": {\n        \"notifications\": {\n          \"raidInvites\": true,\n          \"achievementUnlocks\": true,\n          \"leaderboardChanges\": false,\n          \"weeklyReports\": true\n        },\n        \"privacy\": {\n          \"showProfile\": \"public\",\n          \"showStats\": \"community_only\",\n          \"showAchievements\": \"public\"\n        },\n        \"gameplay\": {\n          \"autoJoinRecommended\": false,\n          \"preferredPlatforms\": [\"telegram\", \"twitter\"],\n          \"qualityOverSpeed\": true,\n          \"mentorNewUsers\": true\n        }\n      }\n    }\n  }'\n\n# Upload profile avatar\ncurl -X POST https://api.anubis.chat/api/v1/users/user_456/avatar \\\n  -H \"Authorization: Bearer your-token\" \\\n  -F \"avatar=@/path/to/image.jpg\" \\\n  -F \"crop={\\\"x\\\":10,\\\"y\\\":10,\\\"width\\\":200,\\\"height\\\":200}\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Platform Connections\">\n```bash\n# Get connected platforms\ncurl -X GET https://api.anubis.chat/api/v1/users/user_456/platforms \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"connectedPlatforms\": [\n    {\n      \"platform\": \"telegram\",\n      \"platformUserId\": \"123456789\",\n      \"username\": \"@example_user\",\n      \"connectedAt\": \"2023-08-20T14:30:00Z\",\n      \"verified\": true,\n      \"permissions\": [\"message:receive\", \"raids:participate\"],\n      \"status\": \"active\",\n      \"lastActivity\": \"2024-01-01T11:45:00Z\"\n    },\n    {\n      \"platform\": \"twitter\",\n      \"platformUserId\": \"twitter_987654321\",\n      \"username\": \"@example_user_tw\",\n      \"connectedAt\": \"2023-09-01T10:15:00Z\",\n      \"verified\": true,\n      \"permissions\": [\"profile:read\", \"tweets:write\", \"raids:participate\"],\n      \"status\": \"active\",\n      \"lastActivity\": \"2024-01-01T12:30:00Z\"\n    }\n  ],\n  \"availablePlatforms\": [\n    {\n      \"platform\": \"discord\",\n      \"supported\": true,\n      \"connectionUrl\": \"https://api.anubis.chat/auth/discord/connect\",\n      \"features\": [\"raids\", \"coordination\", \"voice_chat\"]\n    }\n  ]\n}\n\n# Connect new platform\ncurl -X POST https://api.anubis.chat/api/v1/users/user_456/platforms \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"platform\": \"discord\",\n    \"authCode\": \"discord-oauth-code\",\n    \"permissions\": [\"message:receive\", \"raids:participate\", \"voice:join\"]\n  }'\n\n# Disconnect platform\ncurl -X DELETE https://api.anubis.chat/api/v1/users/user_456/platforms/telegram \\\n  -H \"Authorization: Bearer your-token\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Notifications\">\n```bash\n# Get notification settings\ncurl -X GET https://api.anubis.chat/api/v1/users/user_456/notifications \\\n  -H \"Authorization: Bearer your-token\"\n\n# Update notification preferences\ncurl -X PATCH https://api.anubis.chat/api/v1/users/user_456/notifications \\\n  -H \"Authorization: Bearer your-token\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"preferences\": {\n      \"raids\": {\n        \"invitations\": {\n          \"enabled\": true,\n          \"platforms\": [\"telegram\", \"email\"],\n          \"advance_notice\": 1800000\n        },\n        \"coordination\": {\n          \"enabled\": true,\n          \"platforms\": [\"telegram\", \"websocket\"],\n          \"realtime_updates\": true\n        },\n        \"results\": {\n          \"enabled\": true,\n          \"platforms\": [\"email\"],\n          \"include_stats\": true\n        }\n      },\n      \"achievements\": {\n        \"unlocks\": {\n          \"enabled\": true,\n          \"platforms\": [\"telegram\", \"websocket\"],\n          \"celebration_level\": \"full\"\n        },\n        \"progress\": {\n          \"enabled\": false,\n          \"milestone_percentage\": 75\n        }\n      },\n      \"leaderboards\": {\n        \"rank_changes\": {\n          \"enabled\": true,\n          \"threshold\": 5,\n          \"platforms\": [\"telegram\"]\n        },\n        \"weekly_reports\": {\n          \"enabled\": true,\n          \"platforms\": [\"email\"],\n          \"day_of_week\": \"monday\"\n        }\n      }\n    }\n  }'\n\n# Get notification history\ncurl -X GET \"https://api.anubis.chat/api/v1/users/user_456/notifications/history?limit=20\" \\\n  -H \"Authorization: Bearer your-token\"\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Analytics APIs\n\n### Performance Insights\n\nDetailed analytics and performance metrics:\n\n\u003CTabs>\n  \u003CTabItem label=\"System Analytics\">\n```bash\n# Get system-wide metrics\ncurl -X GET https://api.anubis.chat/api/v1/analytics/system \\\n  -H \"Authorization: Bearer admin-token\"\n\n# Response\n{\n  \"systemMetrics\": {\n    \"activeUsers\": {\n      \"realtime\": 1250,\n      \"last24h\": 3400,\n      \"last7d\": 15600\n    },\n    \"raids\": {\n      \"active\": 12,\n      \"completed_today\": 45,\n      \"success_rate\": 0.89,\n      \"average_participants\": 28\n    },\n    \"engagement\": {\n      \"total_interactions\": 125000,\n      \"quality_average\": 0.81,\n      \"platform_breakdown\": {\n        \"telegram\": 0.45,\n        \"twitter\": 0.35,\n        \"discord\": 0.20\n      }\n    },\n    \"performance\": {\n      \"response_time\": {\n        \"average\": 120,\n        \"p95\": 280,\n        \"p99\": 450\n      },\n      \"error_rate\": 0.002,\n      \"uptime\": 0.9998\n    }\n  },\n  \"trends\": {\n    \"user_growth\": \"steady\",\n    \"engagement_trend\": \"increasing\",\n    \"quality_trend\": \"stable\",\n    \"performance_trend\": \"improving\"\n  }\n}\n\n# Get platform-specific analytics\ncurl -X GET https://api.anubis.chat/api/v1/analytics/platforms/telegram \\\n  -H \"Authorization: Bearer your-token\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"User Analytics\">\n```bash\n# Get personal analytics dashboard\ncurl -X GET https://api.anubis.chat/api/v1/analytics/users/user_456 \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"period\": \"last_30_days\",\n  \"summary\": {\n    \"raids_participated\": 15,\n    \"total_engagements\": 85,\n    \"quality_average\": 0.84,\n    \"rank_change\": 3,\n    \"achievements_unlocked\": 2,\n    \"points_earned\": 1250\n  },\n  \"detailed\": {\n    \"daily_activity\": [\n      {\n        \"date\": \"2024-01-01\",\n        \"raids\": 2,\n        \"engagements\": 8,\n        \"quality\": 0.87,\n        \"points\": 95\n      }\n      // ... more daily data\n    ],\n    \"platform_performance\": {\n      \"telegram\": {\n        \"engagements\": 35,\n        \"success_rate\": 0.94,\n        \"quality_average\": 0.82\n      },\n      \"twitter\": {\n        \"engagements\": 40,\n        \"success_rate\": 0.90,\n        \"quality_average\": 0.86\n      },\n      \"discord\": {\n        \"engagements\": 10,\n        \"success_rate\": 0.100,\n        \"quality_average\": 0.79\n      }\n    },\n    \"quality_trends\": {\n      \"improvement_areas\": [\"response_time\", \"content_originality\"],\n      \"strengths\": [\"authenticity\", \"engagement_value\"],\n      \"recommendations\": [\n        \"Focus on faster response times to improve timing scores\",\n        \"Continue excellent authentic engagement patterns\"\n      ]\n    },\n    \"comparative\": {\n      \"percentile\": 78,\n      \"above_average_metrics\": [\"quality\", \"consistency\"],\n      \"improvement_opportunities\": [\"participation_frequency\", \"multi_platform_coordination\"]\n    }\n  },\n  \"projections\": {\n    \"next_rank\": {\n      \"rank\": 12,\n      \"points_needed\": 150,\n      \"estimated_time\": \"5-7 days\"\n    },\n    \"next_achievement\": {\n      \"name\": \"Quality Master\",\n      \"progress\": 0.85,\n      \"estimated_unlock\": \"2024-01-15T00:00:00Z\"\n    }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Community Analytics\">\n```bash\n# Get community insights\ncurl -X GET https://api.anubis.chat/api/v1/analytics/community \\\n  -H \"Authorization: Bearer your-token\"\n\n# Response\n{\n  \"community\": {\n    \"health_score\": 0.87,\n    \"activity_level\": \"high\",\n    \"growth_rate\": 0.12,\n    \"engagement_quality\": 0.83\n  },\n  \"demographics\": {\n    \"user_distribution\": {\n      \"new_users\": 0.15,\n      \"regular_users\": 0.60,\n      \"veteran_users\": 0.25\n    },\n    \"platform_preferences\": {\n      \"telegram_primary\": 0.45,\n      \"twitter_primary\": 0.35,\n      \"discord_primary\": 0.15,\n      \"multi_platform\": 0.05\n    },\n    \"activity_patterns\": {\n      \"peak_hours\": [14, 18, 20],\n      \"peak_days\": [\"tuesday\", \"wednesday\", \"saturday\"],\n      \"seasonal_trends\": \"winter_increase\"\n    }\n  },\n  \"content\": {\n    \"quality_distribution\": {\n      \"excellent\": 0.25,\n      \"good\": 0.45,\n      \"average\": 0.25,\n      \"poor\": 0.05\n    },\n    \"trending_topics\": [\n      { \"topic\": \"AI innovation\", \"mentions\": 450, \"sentiment\": 0.82 },\n      { \"topic\": \"Community growth\", \"mentions\": 320, \"sentiment\": 0.89 }\n    ],\n    \"engagement_types\": {\n      \"collaborative\": 0.60,\n      \"competitive\": 0.30,\n      \"educational\": 0.10\n    }\n  },\n  \"network\": {\n    \"connectivity_score\": 0.76,\n    \"influence_distribution\": \"balanced\",\n    \"collaboration_rate\": 0.68,\n    \"mentorship_activity\": \"active\"\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Error Responses\n\n### Standard Error Format\n\nAll API errors follow a consistent format for easy handling:\n\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"One or more fields failed validation\",\n    \"details\": {\n      \"field\": \"target.url\",\n      \"reason\": \"Invalid URL format\",\n      \"provided\": \"not-a-url\",\n      \"expected\": \"Valid HTTP/HTTPS URL\"\n    },\n    \"timestamp\": \"2024-01-01T12:00:00Z\",\n    \"requestId\": \"req_abc123456\",\n    \"documentation\": \"https://docs.anubis.chat/api/errors#validation-error\"\n  }\n}\n```\n\n### Common Error Codes\n\n| Code | HTTP Status | Description |\n|------|-------------|-------------|\n| `AUTHENTICATION_REQUIRED` | 401 | No authentication token provided |\n| `INVALID_TOKEN` | 401 | Authentication token is invalid or expired |\n| `INSUFFICIENT_PERMISSIONS` | 403 | User lacks required permissions |\n| `RESOURCE_NOT_FOUND` | 404 | Requested resource does not exist |\n| `VALIDATION_ERROR` | 400 | Request data validation failed |\n| `RATE_LIMITED` | 429 | Too many requests in time window |\n| `INTERNAL_ERROR` | 500 | Unexpected server error |\n| `SERVICE_UNAVAILABLE` | 503 | Service temporarily unavailable |\n\nNUBI's Service APIs provide comprehensive programmatic access to all platform capabilities, enabling developers to build powerful integrations and custom applications on top of the NUBI ecosystem.","src/content/docs/api-reference/service-apis.mdx","8040276a51cff69e","api-reference/service-apis.mdx","api-reference/plugin-system",{"id":249,"data":251,"body":257,"filePath":258,"digest":259,"legacyId":260,"deferredRender":16},{"title":252,"description":253,"editUrl":16,"head":254,"template":47,"sidebar":255,"pagefind":16,"draft":35},"Plugin System","Comprehensive guide to NUBI's extensible plugin architecture, custom actions, evaluators, and providers",[],{"order":219,"hidden":35,"attrs":256},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nNUBI's plugin system provides a powerful extensibility framework built on ElizaOS, enabling developers to create custom actions, evaluators, providers, and complete plugin packages.\n\n## Plugin Architecture\n\n### Core Plugin Structure\n\nNUBI plugins follow the ElizaOS plugin architecture with enhanced capabilities:\n\n```mermaid\ngraph TB\n    subgraph \"Plugin System\"\n        PC[Plugin Core]\n        PM[Plugin Manager]\n        PR[Plugin Registry]\n        PL[Plugin Loader]\n    end\n    \n    subgraph \"Plugin Components\"\n        A[Actions]\n        E[Evaluators]\n        P[Providers]\n        S[Services]\n    end\n    \n    subgraph \"Runtime Environment\"\n        ER[ElizaOS Runtime]\n        NR[NUBI Runtime]\n        DB[Database]\n        MB[Message Bus]\n    end\n    \n    PC --> A\n    PC --> E\n    PC --> P\n    PC --> S\n    \n    PM --> PL\n    PM --> PR\n    PL --> PC\n    \n    A --> ER\n    E --> ER\n    P --> ER\n    S --> NR\n    \n    NR --> DB\n    NR --> MB\n```\n\n\u003CTabs>\n  \u003CTabItem label=\"Plugin Interface\">\n```typescript\nimport { Plugin } from \"@elizaos/core\"\n\ninterface NubiPlugin extends Plugin {\n  // Standard ElizaOS plugin properties\n  name: string\n  description: string\n  version: string\n  \n  // NUBI-specific extensions\n  nubiVersion: string\n  category: PluginCategory\n  permissions: PluginPermission[]\n  dependencies: PluginDependency[]\n  \n  // Component definitions\n  actions?: Action[]\n  evaluators?: Evaluator[]\n  providers?: Provider[]\n  services?: Service[]\n  \n  // Lifecycle hooks\n  onLoad?(runtime: NubiRuntime): Promise\u003Cvoid>\n  onUnload?(runtime: NubiRuntime): Promise\u003Cvoid>\n  onConfigUpdate?(config: PluginConfig): Promise\u003Cvoid>\n  \n  // Health and monitoring\n  healthCheck?(): Promise\u003CPluginHealth>\n  getMetrics?(): Promise\u003CPluginMetrics>\n}\n\ninterface PluginMetadata {\n  author: string\n  license: string\n  repository?: string\n  homepage?: string\n  keywords: string[]\n  compatibility: {\n    elizaos: string\n    nubi: string\n    node: string\n  }\n}\n\nenum PluginCategory {\n  COMMUNICATION = 'communication',\n  ANALYTICS = 'analytics',\n  AUTOMATION = 'automation',\n  SECURITY = 'security',\n  INTEGRATION = 'integration',\n  UTILITY = 'utility',\n  ENTERTAINMENT = 'entertainment'\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Plugin Example\">\n```typescript\nimport { \n  Plugin, \n  Action, \n  Evaluator, \n  Provider,\n  elizaLogger as logger \n} from \"@elizaos/core\"\nimport type { \n  NubiPlugin, \n  NubiRuntime, \n  PluginConfig \n} from \"../types\"\n\nclass CustomRaidPlugin implements NubiPlugin {\n  name = \"custom-raid-coordinator\"\n  description = \"Advanced raid coordination with custom strategies\"\n  version = \"1.0.0\"\n  nubiVersion = \"^2.0.0\"\n  category = PluginCategory.AUTOMATION\n  \n  permissions = [\n    'raids:create',\n    'raids:coordinate', \n    'messaging:broadcast',\n    'analytics:read'\n  ]\n  \n  dependencies = [\n    { name: 'nubi-core', version: '^2.0.0' },\n    { name: 'message-bus', version: '^1.5.0' }\n  ]\n  \n  actions = [\n    new CustomRaidAction(),\n    new AdvancedCoordinationAction()\n  ]\n  \n  evaluators = [\n    new RaidEffectivenessEvaluator(),\n    new ParticipantQualityEvaluator()\n  ]\n  \n  providers = [\n    new RaidStrategyProvider(),\n    new CoordinationMetricsProvider()\n  ]\n  \n  private config: PluginConfig\n  private runtime: NubiRuntime\n  \n  async onLoad(runtime: NubiRuntime): Promise\u003Cvoid> {\n    this.runtime = runtime\n    this.config = await runtime.getPluginConfig(this.name)\n    \n    // Initialize plugin services\n    await this.initializeServices()\n    \n    // Register event listeners\n    this.registerEventListeners()\n    \n    logger.info(`${this.name} v${this.version} loaded successfully`)\n  }\n  \n  async onUnload(runtime: NubiRuntime): Promise\u003Cvoid> {\n    // Cleanup resources\n    await this.cleanup()\n    logger.info(`${this.name} unloaded`)\n  }\n  \n  async healthCheck(): Promise\u003CPluginHealth> {\n    return {\n      status: 'healthy',\n      checks: {\n        database: await this.checkDatabase(),\n        services: await this.checkServices(),\n        dependencies: await this.checkDependencies()\n      },\n      timestamp: new Date().toISOString()\n    }\n  }\n  \n  private async initializeServices(): Promise\u003Cvoid> {\n    // Plugin-specific initialization logic\n    await this.setupCustomCoordination()\n    await this.initializeMetricsCollection()\n  }\n  \n  private registerEventListeners(): void {\n    this.runtime.on('raid:created', this.handleRaidCreated.bind(this))\n    this.runtime.on('raid:participant_joined', this.handleParticipantJoined.bind(this))\n  }\n  \n  private async handleRaidCreated(event: RaidCreatedEvent): Promise\u003Cvoid> {\n    // Custom raid creation handling\n    logger.info(`Custom raid coordination activated for ${event.raidId}`)\n  }\n}\n\nexport default new CustomRaidPlugin()\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Plugin Configuration\">\n```yaml\n# plugin-config.yaml\nplugins:\n  custom-raid-coordinator:\n    enabled: true\n    version: \"1.0.0\"\n    config:\n      # Plugin-specific configuration\n      coordination:\n        advanced_strategies: true\n        multi_platform_sync: true\n        real_time_analytics: true\n      \n      strategies:\n        default_approach: \"moderate\"\n        quality_threshold: 0.75\n        participation_limits:\n          min_participants: 5\n          max_participants: 200\n      \n      notifications:\n        coordinator_alerts: true\n        performance_reports: true\n        quality_warnings: true\n      \n      integrations:\n        analytics_endpoint: \"https://analytics.example.com\"\n        webhook_url: \"https://webhooks.example.com/raid-events\"\n        api_keys:\n          analytics: \"${ANALYTICS_API_KEY}\"\n          webhook: \"${WEBHOOK_SECRET}\"\n    \n    permissions:\n      - \"raids:create\"\n      - \"raids:coordinate\"\n      - \"messaging:broadcast\"\n      - \"analytics:read\"\n    \n    resources:\n      memory_limit: \"256MB\"\n      cpu_limit: \"0.5\"\n      network_timeout: 30000\n    \n    monitoring:\n      health_check_interval: 60000\n      metrics_collection: true\n      error_reporting: true\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Custom Actions\n\n### Action Development\n\nCreate custom actions that extend NUBI's capabilities:\n\n\u003CTabs>\n  \u003CTabItem label=\"Action Structure\">\n```typescript\nimport { Action, ActionExample } from \"@elizaos/core\"\nimport type { \n  Memory, \n  Message, \n  Handler, \n  HandlerCallback,\n  IAgentRuntime,\n  State\n} from \"@elizaos/core\"\n\ninterface CustomActionConfig {\n  name: string\n  description: string\n  examples: ActionExample[]\n  handler: Handler\n  validate: (runtime: IAgentRuntime, message: Message) => Promise\u003Cboolean>\n}\n\nclass AdvancedRaidAction implements Action {\n  name = \"ADVANCED_RAID_COORDINATE\"\n  description = \"Coordinate complex multi-platform raids with advanced strategies\"\n  \n  examples: ActionExample[] = [\n    [\n      {\n        user: \"{{user1}}\",\n        content: {\n          text: \"Let's coordinate a strategic raid on that viral post about AI innovation\"\n        }\n      },\n      {\n        user: \"{{agent}}\",\n        content: {\n          text: \"I'll set up an advanced coordination strategy. Analyzing target engagement patterns and optimal timing windows...\",\n          action: \"ADVANCED_RAID_COORDINATE\"\n        }\n      }\n    ]\n  ]\n  \n  async validate(\n    runtime: IAgentRuntime, \n    message: Message,\n    state?: State\n  ): Promise\u003Cboolean> {\n    // Validate user permissions\n    const hasPermission = await this.checkUserPermissions(\n      runtime, \n      message.userId, \n      ['raids:coordinate', 'advanced:strategies']\n    )\n    \n    if (!hasPermission) {\n      return false\n    }\n    \n    // Validate message contains raid coordination request\n    const coordinationKeywords = [\n      'coordinate raid', 'strategic raid', 'advanced raid',\n      'multi-platform raid', 'synchronized attack'\n    ]\n    \n    return coordinationKeywords.some(keyword => \n      message.content.text.toLowerCase().includes(keyword)\n    )\n  }\n  \n  async handler(\n    runtime: IAgentRuntime,\n    message: Message,\n    state?: State,\n    options?: any,\n    callback?: HandlerCallback\n  ): Promise\u003Cboolean> {\n    try {\n      // Extract raid parameters from message\n      const raidParams = await this.extractRaidParameters(message.content.text)\n      \n      // Analyze target for optimal strategy\n      const targetAnalysis = await this.analyzeTarget(raidParams.target)\n      \n      // Generate advanced coordination strategy\n      const strategy = await this.generateAdvancedStrategy(\n        targetAnalysis, \n        raidParams\n      )\n      \n      // Create raid with advanced configuration\n      const raid = await this.createAdvancedRaid({\n        ...raidParams,\n        strategy,\n        coordinator: message.userId,\n        createdAt: new Date()\n      })\n      \n      // Send coordination response\n      const response = await this.generateCoordinationResponse(raid, strategy)\n      \n      if (callback) {\n        callback({\n          text: response,\n          action: this.name,\n          metadata: {\n            raidId: raid.id,\n            strategy: strategy.name,\n            expectedParticipants: strategy.targetParticipants,\n            platforms: strategy.platforms\n          }\n        })\n      }\n      \n      return true\n    } catch (error) {\n      console.error('Advanced raid coordination failed:', error)\n      \n      if (callback) {\n        callback({\n          text: \"I encountered an issue setting up the advanced raid coordination. Let me try a simpler approach or check with the technical team.\",\n          error: error.message\n        })\n      }\n      \n      return false\n    }\n  }\n  \n  private async extractRaidParameters(text: string): Promise\u003CRaidParameters> {\n    // Use NLP to extract raid parameters from natural language\n    const nlpService = await this.getNLPService()\n    return nlpService.extractRaidParams(text)\n  }\n  \n  private async analyzeTarget(target: RaidTarget): Promise\u003CTargetAnalysis> {\n    // Advanced target analysis\n    const analysisService = await this.getAnalysisService()\n    return analysisService.deepAnalyze(target)\n  }\n  \n  private async generateAdvancedStrategy(\n    analysis: TargetAnalysis,\n    params: RaidParameters\n  ): Promise\u003CAdvancedStrategy> {\n    // Generate sophisticated raid strategy\n    const strategyEngine = await this.getStrategyEngine()\n    return strategyEngine.generateAdvanced(analysis, params)\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Action Registration\">\n```typescript\n// actions/index.ts\nimport { Action } from \"@elizaos/core\"\nimport { AdvancedRaidAction } from \"./advanced-raid-action\"\nimport { CustomEngagementAction } from \"./custom-engagement-action\"\nimport { IntelligentCoordinationAction } from \"./intelligent-coordination-action\"\n\nexport const customActions: Action[] = [\n  new AdvancedRaidAction(),\n  new CustomEngagementAction(),\n  new IntelligentCoordinationAction()\n]\n\n// Plugin registration\nexport class ActionPlugin implements NubiPlugin {\n  name = \"custom-actions\"\n  description = \"Collection of advanced custom actions\"\n  version = \"1.0.0\"\n  \n  actions = customActions\n  \n  async onLoad(runtime: NubiRuntime): Promise\u003Cvoid> {\n    // Register all actions with runtime\n    for (const action of this.actions) {\n      await runtime.registerAction(action)\n      logger.info(`Registered action: ${action.name}`)\n    }\n  }\n}\n\n// Usage in main plugin system\nimport { ActionPlugin } from \"./actions\"\n\nconst actionPlugin = new ActionPlugin()\nawait runtime.loadPlugin(actionPlugin)\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Action Testing\">\n```typescript\n// actions/__tests__/advanced-raid-action.test.ts\nimport { describe, it, expect, beforeEach, jest } from 'bun:test'\nimport { AdvancedRaidAction } from '../advanced-raid-action'\nimport { createMockRuntime, createMockMessage } from '../../test-utils'\n\ndescribe('AdvancedRaidAction', () => {\n  let action: AdvancedRaidAction\n  let mockRuntime: any\n  let mockMessage: any\n  \n  beforeEach(() => {\n    action = new AdvancedRaidAction()\n    mockRuntime = createMockRuntime()\n    mockMessage = createMockMessage({\n      content: { text: \"Let's coordinate a strategic raid on this viral AI post\" },\n      userId: \"user_123\"\n    })\n  })\n  \n  describe('validate', () => {\n    it('should validate valid coordination requests', async () => {\n      // Mock user permissions\n      mockRuntime.checkUserPermissions = jest.fn().mockResolvedValue(true)\n      \n      const isValid = await action.validate(mockRuntime, mockMessage)\n      expect(isValid).toBe(true)\n    })\n    \n    it('should reject requests without proper permissions', async () => {\n      mockRuntime.checkUserPermissions = jest.fn().mockResolvedValue(false)\n      \n      const isValid = await action.validate(mockRuntime, mockMessage)\n      expect(isValid).toBe(false)\n    })\n    \n    it('should reject messages without coordination keywords', async () => {\n      mockRuntime.checkUserPermissions = jest.fn().mockResolvedValue(true)\n      mockMessage.content.text = \"Just a regular message\"\n      \n      const isValid = await action.validate(mockRuntime, mockMessage)\n      expect(isValid).toBe(false)\n    })\n  })\n  \n  describe('handler', () => {\n    it('should successfully create advanced raid coordination', async () => {\n      // Mock all dependencies\n      const mockAnalysis = { viralityScore: 0.8, engagementPotential: 0.9 }\n      const mockStrategy = { name: 'viral_boost', platforms: ['telegram', 'twitter'] }\n      const mockRaid = { id: 'raid_123', status: 'created' }\n      \n      action.analyzeTarget = jest.fn().mockResolvedValue(mockAnalysis)\n      action.generateAdvancedStrategy = jest.fn().mockResolvedValue(mockStrategy)\n      action.createAdvancedRaid = jest.fn().mockResolvedValue(mockRaid)\n      \n      const callback = jest.fn()\n      const result = await action.handler(mockRuntime, mockMessage, undefined, {}, callback)\n      \n      expect(result).toBe(true)\n      expect(callback).toHaveBeenCalledWith(\n        expect.objectContaining({\n          text: expect.stringContaining('raid coordination'),\n          action: 'ADVANCED_RAID_COORDINATE',\n          metadata: expect.objectContaining({\n            raidId: 'raid_123'\n          })\n        })\n      )\n    })\n  })\n})\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Custom Evaluators\n\n### Evaluator Development\n\nBuild intelligent evaluation systems for content and behavior analysis:\n\n\u003CTabs>\n  \u003CTabItem label=\"Evaluator Structure\">\n```typescript\nimport { Evaluator } from \"@elizaos/core\"\nimport type { \n  Memory, \n  IAgentRuntime, \n  State \n} from \"@elizaos/core\"\n\nclass RaidQualityEvaluator implements Evaluator {\n  name = \"RAID_QUALITY_ASSESSMENT\"\n  description = \"Evaluate raid participation quality and effectiveness\"\n  \n  // Evaluation examples for training\n  examples = [\n    {\n      context: \"User participated in raid with high-quality engagement\",\n      messages: [\n        {\n          user: \"{{user1}}\",\n          content: { text: \"Great project! The AI innovation here is remarkable. Looking forward to seeing how this develops!\" }\n        }\n      ],\n      outcome: \"HIGH_QUALITY - Authentic, detailed, relevant engagement\"\n    },\n    {\n      context: \"User participated with generic engagement\",\n      messages: [\n        {\n          user: \"{{user1}}\",\n          content: { text: \"Nice! 👍\" }\n        }\n      ],\n      outcome: \"LOW_QUALITY - Generic, minimal effort engagement\"\n    }\n  ]\n  \n  async handler(\n    runtime: IAgentRuntime,\n    message: Memory,\n    state?: State\n  ): Promise\u003Cnumber> {\n    try {\n      // Extract engagement data from memory\n      const engagement = await this.extractEngagementData(message)\n      \n      if (!engagement) {\n        return 0 // No raid engagement detected\n      }\n      \n      // Run comprehensive quality assessment\n      const qualityMetrics = await this.assessQuality(engagement)\n      \n      // Calculate composite quality score (0-1)\n      const qualityScore = this.calculateQualityScore(qualityMetrics)\n      \n      // Store evaluation results\n      await this.storeEvaluationResults(message, qualityMetrics, qualityScore)\n      \n      return qualityScore\n      \n    } catch (error) {\n      console.error('Raid quality evaluation failed:', error)\n      return 0\n    }\n  }\n  \n  private async assessQuality(engagement: EngagementData): Promise\u003CQualityMetrics> {\n    // Multi-dimensional quality assessment\n    const [\n      contentQuality,\n      authenticityScore,\n      timingScore,\n      relevanceScore,\n      originalityScore\n    ] = await Promise.all([\n      this.assessContentQuality(engagement.content),\n      this.assessAuthenticity(engagement.content, engagement.user),\n      this.assessTiming(engagement.timestamp, engagement.raid),\n      this.assessRelevance(engagement.content, engagement.target),\n      this.assessOriginality(engagement.content, engagement.user)\n    ])\n    \n    return {\n      content: contentQuality,\n      authenticity: authenticityScore,\n      timing: timingScore,\n      relevance: relevanceScore,\n      originality: originalityScore,\n      overall: this.calculateOverallScore({\n        contentQuality,\n        authenticityScore,\n        timingScore,\n        relevanceScore,\n        originalityScore\n      })\n    }\n  }\n  \n  private async assessContentQuality(content: string): Promise\u003Cnumber> {\n    // Content quality assessment using multiple factors\n    const factors = {\n      length: this.assessLength(content),\n      complexity: this.assessComplexity(content),\n      sentiment: await this.assessSentiment(content),\n      grammar: await this.assessGrammar(content),\n      engagement: this.assessEngagementPotential(content)\n    }\n    \n    // Weighted average of quality factors\n    return (\n      factors.length * 0.15 +\n      factors.complexity * 0.25 +\n      factors.sentiment * 0.20 +\n      factors.grammar * 0.20 +\n      factors.engagement * 0.20\n    )\n  }\n  \n  private async assessAuthenticity(\n    content: string, \n    user: UserProfile\n  ): Promise\u003Cnumber> {\n    // Check for human-like characteristics\n    const humanFactors = {\n      typos: this.detectNaturalTypos(content),\n      personalStyle: await this.matchPersonalStyle(content, user),\n      emotionalExpression: this.detectEmotionalExpression(content),\n      contextualReferences: this.detectContextualReferences(content),\n      variationFromPrevious: await this.checkVariationFromPrevious(content, user)\n    }\n    \n    // Calculate authenticity based on human-like factors\n    return this.calculateAuthenticityScore(humanFactors)\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Specialized Evaluators\">\n```typescript\n// Community Impact Evaluator\nclass CommunityImpactEvaluator implements Evaluator {\n  name = \"COMMUNITY_IMPACT_ASSESSMENT\"\n  \n  async handler(runtime: IAgentRuntime, message: Memory): Promise\u003Cnumber> {\n    const impact = await this.assessCommunityImpact(message)\n    \n    return {\n      networkEffect: impact.networkGrowth,\n      engagementBoost: impact.engagementIncrease,\n      qualityInfluence: impact.qualityImprovement,\n      mentorshipValue: impact.newUserSupport,\n      collaborationIndex: impact.teamworkEnhancement\n    }\n  }\n}\n\n// Security Risk Evaluator\nclass SecurityRiskEvaluator implements Evaluator {\n  name = \"SECURITY_RISK_ASSESSMENT\"\n  \n  async handler(runtime: IAgentRuntime, message: Memory): Promise\u003Cnumber> {\n    const risks = await this.assessSecurityRisks(message)\n    \n    return {\n      maliciousContent: risks.maliciousContentScore,\n      privacyViolation: risks.privacyRiskScore,\n      platformViolation: risks.platformRiskScore,\n      reputationRisk: risks.reputationDamageRisk,\n      spamProbability: risks.spamLikelihood\n    }\n  }\n}\n\n// Performance Optimization Evaluator\nclass PerformanceOptimizationEvaluator implements Evaluator {\n  name = \"PERFORMANCE_OPTIMIZATION\"\n  \n  async handler(runtime: IAgentRuntime, message: Memory): Promise\u003Cnumber> {\n    const performance = await this.assessPerformance(message)\n    \n    return {\n      responseTime: performance.responseTimeScore,\n      resourceEfficiency: performance.resourceUsageScore,\n      coordinationEffectiveness: performance.coordinationScore,\n      outcomeQuality: performance.resultQualityScore\n    }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Evaluator Integration\">\n```typescript\n// evaluators/index.ts\nimport { Evaluator } from \"@elizaos/core\"\nimport { RaidQualityEvaluator } from \"./raid-quality-evaluator\"\nimport { CommunityImpactEvaluator } from \"./community-impact-evaluator\"\nimport { SecurityRiskEvaluator } from \"./security-risk-evaluator\"\n\nexport const customEvaluators: Evaluator[] = [\n  new RaidQualityEvaluator(),\n  new CommunityImpactEvaluator(),\n  new SecurityRiskEvaluator()\n]\n\n// Evaluator orchestration service\nclass EvaluatorOrchestrator {\n  private evaluators: Map\u003Cstring, Evaluator> = new Map()\n  \n  constructor(evaluators: Evaluator[]) {\n    evaluators.forEach(evaluator => {\n      this.evaluators.set(evaluator.name, evaluator)\n    })\n  }\n  \n  async runEvaluations(\n    runtime: IAgentRuntime, \n    message: Memory,\n    evaluatorNames?: string[]\n  ): Promise\u003CEvaluationResults> {\n    const targetEvaluators = evaluatorNames \n      ? evaluatorNames.map(name => this.evaluators.get(name)).filter(Boolean)\n      : Array.from(this.evaluators.values())\n    \n    const evaluationPromises = targetEvaluators.map(async evaluator => {\n      try {\n        const result = await evaluator.handler(runtime, message)\n        return {\n          evaluator: evaluator.name,\n          result,\n          success: true,\n          timestamp: new Date()\n        }\n      } catch (error) {\n        return {\n          evaluator: evaluator.name,\n          result: null,\n          success: false,\n          error: error.message,\n          timestamp: new Date()\n        }\n      }\n    })\n    \n    const results = await Promise.all(evaluationPromises)\n    \n    return {\n      messageId: message.id,\n      evaluations: results,\n      summary: this.generateEvaluationSummary(results),\n      completedAt: new Date()\n    }\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Custom Providers\n\n### Provider Development\n\nCreate intelligent context providers that enhance NUBI's decision-making:\n\n\u003CTabs>\n  \u003CTabItem label=\"Context Provider\">\n```typescript\nimport { Provider } from \"@elizaos/core\"\nimport type { \n  Memory, \n  IAgentRuntime, \n  State \n} from \"@elizaos/core\"\n\nclass AdvancedRaidContextProvider implements Provider {\n  name = \"ADVANCED_RAID_CONTEXT\"\n  description = \"Provide comprehensive context for advanced raid coordination\"\n  \n  async get(\n    runtime: IAgentRuntime, \n    message: Memory, \n    state?: State\n  ): Promise\u003Cstring> {\n    try {\n      // Gather comprehensive raid context\n      const context = await this.gatherRaidContext(runtime, message, state)\n      \n      // Format context for AI consumption\n      return this.formatContextForAI(context)\n      \n    } catch (error) {\n      console.error('Failed to get raid context:', error)\n      return \"Raid context temporarily unavailable.\"\n    }\n  }\n  \n  private async gatherRaidContext(\n    runtime: IAgentRuntime,\n    message: Memory,\n    state?: State\n  ): Promise\u003CRaidContextData> {\n    // Run parallel context gathering\n    const [\n      activeRaids,\n      userPerformance,\n      communityMetrics,\n      strategicInsights,\n      platformStatus\n    ] = await Promise.all([\n      this.getActiveRaids(runtime),\n      this.getUserPerformanceContext(message.userId),\n      this.getCommunityMetrics(),\n      this.getStrategicInsights(),\n      this.getPlatformStatus()\n    ])\n    \n    return {\n      activeRaids,\n      userPerformance,\n      communityMetrics,\n      strategicInsights,\n      platformStatus,\n      timestamp: new Date()\n    }\n  }\n  \n  private formatContextForAI(context: RaidContextData): string {\n    return `\nRAID COORDINATION CONTEXT\n\nCurrent Active Raids: ${context.activeRaids.length}\n${context.activeRaids.map(raid => `\n- ${raid.title}: ${raid.participants} participants, ${raid.effectiveness}% effective\n  Platform: ${raid.platform}, Phase: ${raid.currentPhase}\n  Quality Score: ${raid.qualityScore}, Time Remaining: ${raid.timeRemaining}\n`).join('')}\n\nUser Performance Context:\n- Total Raids: ${context.userPerformance.totalRaids}\n- Success Rate: ${context.userPerformance.successRate}%\n- Average Quality: ${context.userPerformance.averageQuality}\n- Current Streak: ${context.userPerformance.currentStreak}\n- Preferred Platforms: ${context.userPerformance.preferredPlatforms.join(', ')}\n\nCommunity Metrics:\n- Active Users: ${context.communityMetrics.activeUsers}\n- Community Health: ${context.communityMetrics.healthScore}\n- Engagement Rate: ${context.communityMetrics.engagementRate}%\n- Quality Trend: ${context.communityMetrics.qualityTrend}\n\nStrategic Insights:\n- Peak Activity Hours: ${context.strategicInsights.peakHours.join(', ')}\n- Trending Topics: ${context.strategicInsights.trendingTopics.join(', ')}\n- Optimal Platforms: ${context.strategicInsights.optimalPlatforms.join(', ')}\n- Success Factors: ${context.strategicInsights.successFactors.join(', ')}\n\nPlatform Status:\n${Object.entries(context.platformStatus).map(([platform, status]) => `\n- ${platform}: ${status.online ? 'Online' : 'Offline'} (${status.responseTime}ms avg)\n`).join('')}\n\nRecommendations for optimal raid coordination based on current conditions.\n    `\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Intelligence Provider\">\n```typescript\nclass IntelligenceProvider implements Provider {\n  name = \"NUBI_INTELLIGENCE\"\n  description = \"Provide AI-powered insights and recommendations\"\n  \n  private aiModel: AIModel\n  private analyticsService: AnalyticsService\n  \n  async get(\n    runtime: IAgentRuntime, \n    message: Memory, \n    state?: State\n  ): Promise\u003Cstring> {\n    // Analyze current context\n    const contextAnalysis = await this.analyzeContext(message, state)\n    \n    // Generate AI-powered insights\n    const insights = await this.generateInsights(contextAnalysis)\n    \n    // Format insights for decision-making\n    return this.formatIntelligence(insights)\n  }\n  \n  private async analyzeContext(\n    message: Memory, \n    state?: State\n  ): Promise\u003CContextAnalysis> {\n    // Multi-dimensional context analysis\n    const analysis = {\n      messageAnalysis: await this.analyzeMessage(message),\n      userBehaviorPattern: await this.analyzeUserBehavior(message.userId),\n      communityDynamics: await this.analyzeCommunityDynamics(),\n      marketConditions: await this.analyzeMarketConditions(),\n      platformTrends: await this.analyzePlatformTrends()\n    }\n    \n    return analysis\n  }\n  \n  private async generateInsights(analysis: ContextAnalysis): Promise\u003CAIInsights> {\n    // Use AI model to generate actionable insights\n    const prompt = this.constructInsightPrompt(analysis)\n    const aiResponse = await this.aiModel.generate(prompt)\n    \n    return {\n      recommendations: aiResponse.recommendations,\n      predictions: aiResponse.predictions,\n      opportunities: aiResponse.opportunities,\n      risks: aiResponse.risks,\n      confidence: aiResponse.confidence\n    }\n  }\n  \n  private formatIntelligence(insights: AIInsights): string {\n    return `\nNUBI INTELLIGENCE BRIEFING\n\nStrategic Recommendations:\n${insights.recommendations.map(rec => `• ${rec.title}: ${rec.description} (Confidence: ${rec.confidence}%)`).join('\\n')}\n\nMarket Predictions:\n${insights.predictions.map(pred => `• ${pred.event}: ${pred.probability}% chance in ${pred.timeframe}`).join('\\n')}\n\nOpportunities Identified:\n${insights.opportunities.map(opp => `• ${opp.type}: ${opp.description} (Potential: ${opp.potential})`).join('\\n')}\n\nRisk Assessment:\n${insights.risks.map(risk => `• ${risk.category}: ${risk.description} (Severity: ${risk.severity})`).join('\\n')}\n\nOverall Intelligence Confidence: ${insights.confidence}%\n    `\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Provider Registration\">\n```typescript\n// providers/index.ts\nimport { Provider } from \"@elizaos/core\"\nimport { AdvancedRaidContextProvider } from \"./raid-context-provider\"\nimport { IntelligenceProvider } from \"./intelligence-provider\"\nimport { PerformanceInsightsProvider } from \"./performance-insights-provider\"\n\nexport const customProviders: Provider[] = [\n  new AdvancedRaidContextProvider(),\n  new IntelligenceProvider(),\n  new PerformanceInsightsProvider()\n]\n\n// Provider management service\nclass ProviderManager {\n  private providers: Map\u003Cstring, Provider> = new Map()\n  private cache: Map\u003Cstring, CachedProviderResult> = new Map()\n  \n  constructor(providers: Provider[]) {\n    providers.forEach(provider => {\n      this.providers.set(provider.name, provider)\n    })\n  }\n  \n  async getContext(\n    providerName: string,\n    runtime: IAgentRuntime,\n    message: Memory,\n    state?: State,\n    useCache: boolean = true\n  ): Promise\u003Cstring> {\n    const cacheKey = `${providerName}-${message.id}`\n    \n    // Check cache first\n    if (useCache && this.cache.has(cacheKey)) {\n      const cached = this.cache.get(cacheKey)!\n      if (Date.now() - cached.timestamp \u003C 60000) { // 1 minute cache\n        return cached.result\n      }\n    }\n    \n    // Get fresh context\n    const provider = this.providers.get(providerName)\n    if (!provider) {\n      throw new Error(`Provider ${providerName} not found`)\n    }\n    \n    const result = await provider.get(runtime, message, state)\n    \n    // Cache result\n    this.cache.set(cacheKey, {\n      result,\n      timestamp: Date.now()\n    })\n    \n    return result\n  }\n  \n  async getAllContext(\n    runtime: IAgentRuntime,\n    message: Memory,\n    state?: State\n  ): Promise\u003CMap\u003Cstring, string>> {\n    const contextPromises = Array.from(this.providers.entries()).map(\n      async ([name, provider]) => {\n        try {\n          const context = await provider.get(runtime, message, state)\n          return [name, context] as [string, string]\n        } catch (error) {\n          console.error(`Provider ${name} failed:`, error)\n          return [name, `Provider ${name} temporarily unavailable`] as [string, string]\n        }\n      }\n    )\n    \n    const results = await Promise.all(contextPromises)\n    return new Map(results)\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Plugin Distribution & Installation\n\n### Plugin Package Format\n\nNUBI plugins follow a standardized package format for distribution:\n\n\u003CTabs>\n  \u003CTabItem label=\"Package Structure\">\n```\nmy-nubi-plugin/\n├── package.json                 # NPM package configuration\n├── plugin.config.yaml          # Plugin configuration schema\n├── README.md                   # Plugin documentation\n├── src/\n│   ├── index.ts                # Main plugin export\n│   ├── actions/                # Custom actions\n│   │   ├── index.ts\n│   │   └── my-action.ts\n│   ├── evaluators/            # Custom evaluators\n│   │   ├── index.ts\n│   │   └── my-evaluator.ts\n│   ├── providers/             # Custom providers\n│   │   ├── index.ts\n│   │   └── my-provider.ts\n│   └── services/              # Custom services\n│       ├── index.ts\n│       └── my-service.ts\n├── dist/                      # Compiled output\n├── tests/                     # Test files\n├── docs/                      # Documentation\n└── examples/                  # Usage examples\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Package.json\">\n```json\n{\n  \"name\": \"@nubi/my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Advanced raid coordination plugin for NUBI\",\n  \"main\": \"dist/index.js\",\n  \"types\": \"dist/index.d.ts\",\n  \"keywords\": [\"nubi\", \"plugin\", \"raid\", \"coordination\"],\n  \"author\": \"Your Name \u003Cemail@example.com>\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/username/my-nubi-plugin\"\n  },\n  \"nubi\": {\n    \"version\": \"^2.0.0\",\n    \"category\": \"automation\",\n    \"permissions\": [\n      \"raids:create\",\n      \"raids:coordinate\",\n      \"messaging:broadcast\"\n    ],\n    \"compatibility\": {\n      \"elizaos\": \"^1.0.0\",\n      \"node\": \">=18.0.0\"\n    }\n  },\n  \"dependencies\": {\n    \"@elizaos/core\": \"^1.0.0\",\n    \"@nubi/types\": \"^2.0.0\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.0.0\",\n    \"typescript\": \"^5.0.0\",\n    \"bun\": \"^1.0.0\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"test\": \"bun test\",\n    \"dev\": \"tsc --watch\",\n    \"lint\": \"eslint src/\",\n    \"prepare\": \"npm run build\"\n  },\n  \"files\": [\n    \"dist/\",\n    \"plugin.config.yaml\",\n    \"README.md\"\n  ]\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Installation Commands\">\n```bash\n# Install from NPM registry\nnpm install @nubi/my-plugin\n\n# Install from GitHub\nnpm install github:username/my-nubi-plugin\n\n# Install locally for development\nnpm install ./path/to/my-plugin\n\n# Using NUBI CLI (future feature)\nnubi plugin install @nubi/my-plugin\nnubi plugin install github:username/my-nubi-plugin\nnubi plugin install --local ./my-plugin\n\n# Plugin management\nnubi plugin list\nnubi plugin enable @nubi/my-plugin\nnubi plugin disable @nubi/my-plugin\nnubi plugin update @nubi/my-plugin\nnubi plugin remove @nubi/my-plugin\n\n# Plugin configuration\nnubi plugin config @nubi/my-plugin --key api_endpoint --value \"https://api.example.com\"\nnubi plugin config @nubi/my-plugin --file ./custom-config.yaml\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Plugin Registry\n\nNUBI maintains a curated registry of verified plugins:\n\n```typescript\n// Plugin registry interface\ninterface PluginRegistry {\n  search(query: string): Promise\u003CPluginSearchResult[]>\n  getPlugin(name: string): Promise\u003CPluginInfo>\n  publishPlugin(plugin: PluginPackage): Promise\u003CPublishResult>\n  verifyPlugin(name: string): Promise\u003CVerificationResult>\n  reportPlugin(name: string, reason: string): Promise\u003Cvoid>\n}\n\n// Example plugin search\nconst searchResults = await registry.search(\"raid coordination\")\n/*\nResults:\n[\n  {\n    name: \"@nubi/advanced-raids\",\n    description: \"Advanced raid coordination with AI strategies\",\n    author: \"NUBI Team\",\n    version: \"2.1.0\",\n    downloads: 15420,\n    rating: 4.8,\n    verified: true,\n    categories: [\"automation\", \"coordination\"],\n    lastUpdated: \"2024-01-01T00:00:00Z\"\n  }\n]\n*/\n```\n\nNUBI's plugin system provides unlimited extensibility while maintaining security, performance, and compatibility standards, enabling the community to build powerful custom functionality on top of the core platform.","src/content/docs/api-reference/plugin-system.mdx","585b1b511b883efb","api-reference/plugin-system.mdx","deployment/production-setup",{"id":261,"data":263,"body":269,"filePath":270,"digest":271,"legacyId":272,"deferredRender":16},{"title":264,"description":265,"editUrl":16,"head":266,"template":47,"sidebar":267,"pagefind":16,"draft":35},"Production Setup","Comprehensive guide for deploying NUBI to production environments with enterprise-grade reliability and security",[],{"order":193,"hidden":35,"attrs":268},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nThis guide covers deploying NUBI to production environments with enterprise-grade reliability, security, and scalability considerations.\n\n## Infrastructure Requirements\n\n### Minimum System Requirements\n\nProduction NUBI deployments require robust infrastructure to handle community load and real-time coordination:\n\n\u003CTabs>\n  \u003CTabItem label=\"Small Community (\u003C 1,000 users)\">\n```yaml\ncompute:\n  cpu: 4 cores (3.0+ GHz)\n  memory: 16 GB RAM\n  storage: 100 GB SSD\n  network: 1 Gbps connection\n\ndatabase:\n  postgresql: \n    version: \"15+\"\n    memory: 4 GB\n    storage: 50 GB SSD\n    connections: 200\n\nredis:\n  memory: 2 GB\n  storage: 10 GB\n  \nservices:\n  concurrent_raids: 10\n  websocket_connections: 500\n  api_requests_per_minute: 10000\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Medium Community (1,000 - 10,000 users)\">\n```yaml\ncompute:\n  cpu: 8 cores (3.2+ GHz)\n  memory: 32 GB RAM\n  storage: 500 GB SSD\n  network: 2 Gbps connection\n\ndatabase:\n  postgresql: \n    version: \"15+\"\n    memory: 16 GB\n    storage: 200 GB SSD\n    connections: 500\n    read_replicas: 2\n\nredis:\n  memory: 8 GB\n  storage: 50 GB\n  cluster: true\n  \nload_balancer:\n  instances: 2\n  health_checks: true\n  ssl_termination: true\n  \nservices:\n  concurrent_raids: 50\n  websocket_connections: 5000\n  api_requests_per_minute: 50000\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Large Community (10,000+ users)\">\n```yaml\ncompute:\n  application_servers: 3+\n  cpu_per_server: 16 cores (3.5+ GHz)\n  memory_per_server: 64 GB RAM\n  storage_per_server: 1 TB NVMe SSD\n  network: 10 Gbps connection\n\ndatabase:\n  postgresql: \n    version: \"15+\"\n    primary:\n      memory: 64 GB\n      storage: 1 TB NVMe SSD\n      connections: 1000\n    read_replicas: 4\n    connection_pooling: true\n  \n  redis:\n    memory: 32 GB\n    storage: 200 GB\n    cluster: true\n    nodes: 6\n    \nload_balancer:\n  instances: 3\n  auto_scaling: true\n  global_load_balancing: true\n  ddos_protection: true\n  \ncdn:\n  enabled: true\n  edge_locations: global\n  \nservices:\n  concurrent_raids: 200+\n  websocket_connections: 50000+\n  api_requests_per_minute: 500000+\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Cloud Provider Recommendations\n\nNUBI is cloud-agnostic but optimized for specific provider services:\n\n\u003CTabs>\n  \u003CTabItem label=\"AWS Deployment\">\n```yaml\n# AWS Infrastructure as Code (Terraform)\n# aws/main.tf\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\n# VPC Configuration\nresource \"aws_vpc\" \"nubi_vpc\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n  \n  tags = {\n    Name        = \"nubi-production-vpc\"\n    Environment = \"production\"\n    Project     = \"nubi\"\n  }\n}\n\n# ECS Cluster for Application\nresource \"aws_ecs_cluster\" \"nubi_cluster\" {\n  name = \"nubi-production\"\n  \n  capacity_providers = [\"FARGATE\", \"FARGATE_SPOT\"]\n  \n  default_capacity_provider_strategy {\n    capacity_provider = \"FARGATE\"\n    weight           = 1\n  }\n  \n  setting {\n    name  = \"containerInsights\"\n    value = \"enabled\"\n  }\n}\n\n# RDS PostgreSQL Database\nresource \"aws_db_instance\" \"nubi_postgres\" {\n  identifier = \"nubi-postgres-prod\"\n  \n  engine         = \"postgres\"\n  engine_version = \"15.4\"\n  instance_class = \"db.r6g.xlarge\"\n  \n  allocated_storage     = 200\n  max_allocated_storage = 1000\n  storage_type         = \"gp3\"\n  storage_encrypted    = true\n  \n  db_name  = \"nubi_production\"\n  username = \"nubi_admin\"\n  password = var.db_password\n  \n  backup_retention_period = 30\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"sun:04:00-sun:05:00\"\n  \n  multi_az = true\n  \n  vpc_security_group_ids = [aws_security_group.rds.id]\n  db_subnet_group_name   = aws_db_subnet_group.nubi_db.name\n  \n  skip_final_snapshot = false\n  final_snapshot_identifier = \"nubi-postgres-final-snapshot\"\n  \n  tags = {\n    Name        = \"nubi-production-db\"\n    Environment = \"production\"\n  }\n}\n\n# ElastiCache Redis Cluster\nresource \"aws_elasticache_replication_group\" \"nubi_redis\" {\n  replication_group_id         = \"nubi-redis-prod\"\n  description                  = \"Redis cluster for NUBI production\"\n  \n  node_type            = \"cache.r6g.xlarge\"\n  num_cache_clusters   = 3\n  port                 = 6379\n  parameter_group_name = \"default.redis7\"\n  \n  subnet_group_name  = aws_elasticache_subnet_group.nubi_cache.name\n  security_group_ids = [aws_security_group.redis.id]\n  \n  at_rest_encryption_enabled = true\n  transit_encryption_enabled = true\n  auth_token                = var.redis_auth_token\n  \n  automatic_failover_enabled = true\n  multi_az_enabled          = true\n  \n  tags = {\n    Name        = \"nubi-production-redis\"\n    Environment = \"production\"\n  }\n}\n\n# Application Load Balancer\nresource \"aws_lb\" \"nubi_alb\" {\n  name               = \"nubi-production-alb\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.alb.id]\n  subnets           = aws_subnet.public[*].id\n  \n  enable_deletion_protection = true\n  enable_http2              = true\n  \n  access_logs {\n    bucket  = aws_s3_bucket.nubi_logs.bucket\n    prefix  = \"alb\"\n    enabled = true\n  }\n  \n  tags = {\n    Name        = \"nubi-production-alb\"\n    Environment = \"production\"\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Google Cloud Platform\">\n```yaml\n# GCP Deployment Configuration\n# gcp/main.tf\n\nprovider \"google\" {\n  project = var.project_id\n  region  = var.region\n}\n\n# GKE Cluster\nresource \"google_container_cluster\" \"nubi_cluster\" {\n  name     = \"nubi-production\"\n  location = var.region\n  \n  remove_default_node_pool = true\n  initial_node_count       = 1\n  \n  network    = google_compute_network.vpc.name\n  subnetwork = google_compute_subnetwork.subnet.name\n  \n  # Security configuration\n  master_auth {\n    client_certificate_config {\n      issue_client_certificate = false\n    }\n  }\n  \n  workload_identity_config {\n    workload_pool = \"${var.project_id}.svc.id.goog\"\n  }\n  \n  # Enable network policy\n  network_policy {\n    enabled = true\n  }\n  \n  # Private cluster configuration\n  private_cluster_config {\n    enable_private_nodes    = true\n    enable_private_endpoint = false\n    master_ipv4_cidr_block = \"172.16.0.0/28\"\n  }\n  \n  ip_allocation_policy {}\n}\n\n# Node pool\nresource \"google_container_node_pool\" \"nubi_nodes\" {\n  name       = \"nubi-node-pool\"\n  location   = var.region\n  cluster    = google_container_cluster.nubi_cluster.name\n  node_count = 3\n  \n  node_config {\n    preemptible  = false\n    machine_type = \"e2-standard-8\"\n    disk_size_gb = 100\n    disk_type    = \"pd-ssd\"\n    \n    service_account = google_service_account.gke_node.email\n    oauth_scopes = [\n      \"https://www.googleapis.com/auth/cloud-platform\"\n    ]\n    \n    labels = {\n      env     = \"production\"\n      project = \"nubi\"\n    }\n  }\n  \n  autoscaling {\n    min_node_count = 3\n    max_node_count = 20\n  }\n  \n  management {\n    auto_repair  = true\n    auto_upgrade = true\n  }\n}\n\n# Cloud SQL PostgreSQL\nresource \"google_sql_database_instance\" \"nubi_postgres\" {\n  name             = \"nubi-postgres-prod\"\n  database_version = \"POSTGRES_15\"\n  region          = var.region\n  \n  settings {\n    tier = \"db-custom-8-32768\"\n    \n    disk_size         = 200\n    disk_type         = \"PD_SSD\"\n    disk_autoresize   = true\n    \n    backup_configuration {\n      enabled                        = true\n      start_time                    = \"03:00\"\n      location                      = var.region\n      point_in_time_recovery_enabled = true\n      backup_retention_settings {\n        retained_backups = 30\n      }\n    }\n    \n    ip_configuration {\n      ipv4_enabled    = false\n      private_network = google_compute_network.vpc.self_link\n    }\n    \n    database_flags {\n      name  = \"max_connections\"\n      value = \"500\"\n    }\n  }\n}\n\n# Redis Memorystore\nresource \"google_redis_instance\" \"nubi_redis\" {\n  name           = \"nubi-redis-prod\"\n  tier           = \"STANDARD_HA\"\n  memory_size_gb = 16\n  region         = var.region\n  \n  redis_version = \"REDIS_7_0\"\n  \n  authorized_network = google_compute_network.vpc.self_link\n  \n  persistence_config {\n    persistence_mode = \"RDB\"\n    rdb_snapshot_period = \"ONE_HOUR\"\n  }\n  \n  maintenance_policy {\n    weekly_maintenance_window {\n      day = \"SUNDAY\"\n      start_time {\n        hours   = 3\n        minutes = 0\n      }\n    }\n  }\n  \n  labels = {\n    environment = \"production\"\n    project     = \"nubi\"\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Azure Deployment\">\n```yaml\n# Azure Resource Manager Template\n# azure/main.bicep\n\nparam location string = resourceGroup().location\nparam environmentName string = 'production'\n\n// Container Apps Environment\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' = {\n  name: 'nubi-${environmentName}-env'\n  location: location\n  properties: {\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: logAnalyticsWorkspace.properties.customerId\n        sharedKey: logAnalyticsWorkspace.listKeys().primarySharedKey\n      }\n    }\n  }\n}\n\n// PostgreSQL Flexible Server\nresource postgresqlServer 'Microsoft.DBforPostgreSQL/flexibleServers@2022-12-01' = {\n  name: 'nubi-postgres-${environmentName}'\n  location: location\n  sku: {\n    name: 'Standard_D8s_v3'\n    tier: 'GeneralPurpose'\n  }\n  properties: {\n    version: '15'\n    administratorLogin: 'nubiadmin'\n    administratorLoginPassword: postgresPassword\n    \n    storage: {\n      storageSizeGB: 512\n      autoGrow: 'Enabled'\n    }\n    \n    backup: {\n      backupRetentionDays: 30\n      geoRedundantBackup: 'Enabled'\n    }\n    \n    highAvailability: {\n      mode: 'ZoneRedundant'\n    }\n    \n    network: {\n      delegatedSubnetResourceId: subnet.id\n      privateDnsZoneArmResourceId: privateDnsZone.id\n    }\n  }\n}\n\n// Azure Cache for Redis\nresource redisCache 'Microsoft.Cache/Redis@2022-06-01' = {\n  name: 'nubi-redis-${environmentName}'\n  location: location\n  properties: {\n    sku: {\n      name: 'Premium'\n      family: 'P'\n      capacity: 2\n    }\n    redisConfiguration: {\n      'rdb-backup-enabled': 'true'\n      'rdb-backup-frequency': '60'\n      'rdb-backup-max-snapshot-count': '1'\n    }\n    enableNonSslPort: false\n    minimumTlsVersion: '1.2'\n  }\n}\n\n// Application Gateway\nresource applicationGateway 'Microsoft.Network/applicationGateways@2022-07-01' = {\n  name: 'nubi-appgw-${environmentName}'\n  location: location\n  properties: {\n    sku: {\n      name: 'WAF_v2'\n      tier: 'WAF_v2'\n      capacity: 2\n    }\n    \n    webApplicationFirewallConfiguration: {\n      enabled: true\n      firewallMode: 'Prevention'\n      ruleSetType: 'OWASP'\n      ruleSetVersion: '3.2'\n    }\n    \n    gatewayIPConfigurations: [\n      {\n        name: 'appGatewayIpConfig'\n        properties: {\n          subnet: {\n            id: subnetAppGw.id\n          }\n        }\n      }\n    ]\n    \n    frontendIPConfigurations: [\n      {\n        name: 'appGatewayFrontendIP'\n        properties: {\n          publicIPAddress: {\n            id: publicIP.id\n          }\n        }\n      }\n    ]\n    \n    // Additional gateway configuration...\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Environment Configuration\n\n### Production Environment Variables\n\nConfigure NUBI for production with secure environment variables:\n\n\u003CTabs>\n  \u003CTabItem label=\"Core Configuration\">\n```bash\n# .env.production\n# Core Application Settings\nNODE_ENV=production\nPORT=3000\nHOST=0.0.0.0\n\n# Application URLs\nAPP_URL=https://anubis.chat\nAPI_URL=https://api.anubis.chat\nWEBSOCKET_URL=wss://api.anubis.chat\n\n# Database Configuration\nDATABASE_URL=postgresql://user:password@host:5432/nubi_production\nDATABASE_POOL_MIN=5\nDATABASE_POOL_MAX=20\nDATABASE_SSL=true\nDATABASE_SSL_REJECT_UNAUTHORIZED=true\n\n# Redis Configuration\nREDIS_URL=redis://user:password@host:6379/0\nREDIS_CLUSTER_MODE=true\nREDIS_TLS=true\n\n# ElizaOS Configuration\nELIZAOS_LOG_LEVEL=info\nELIZAOS_MEMORY_PROVIDER=database\nELIZAOS_CACHE_PROVIDER=redis\n\n# Security Settings\nJWT_SECRET=your-super-secret-jwt-key-min-64-chars-for-production-security\nJWT_EXPIRY=24h\nJWT_REFRESH_EXPIRY=7d\n\nSESSION_SECRET=your-session-secret-key-for-cookie-signing-production\nSESSION_MAX_AGE=86400000\n\nBCRYPT_ROUNDS=12\nPASSWORD_MIN_LENGTH=8\n\n# Rate Limiting\nRATE_LIMIT_WINDOW_MS=900000  # 15 minutes\nRATE_LIMIT_MAX_REQUESTS=100\nRATE_LIMIT_SKIP_SUCCESS_RESPONSES=false\n\n# CORS Configuration\nCORS_ORIGIN=https://anubis.chat,https://app.anubis.chat\nCORS_CREDENTIALS=true\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Platform Integration\">\n```bash\n# Platform API Keys\nTELEGRAM_BOT_TOKEN=your-telegram-bot-token-from-botfather\nTELEGRAM_WEBHOOK_SECRET=webhook-secret-for-security\nTELEGRAM_WEBHOOK_URL=https://api.anubis.chat/webhooks/telegram\n\nDISCORD_BOT_TOKEN=your-discord-bot-token-from-developer-portal\nDISCORD_CLIENT_ID=your-discord-application-client-id\nDISCORD_CLIENT_SECRET=your-discord-application-client-secret\nDISCORD_GUILD_ID=your-main-discord-server-id\n\nTWITTER_API_KEY=your-twitter-api-key\nTWITTER_API_SECRET=your-twitter-api-secret\nTWITTER_ACCESS_TOKEN=your-twitter-access-token\nTWITTER_ACCESS_TOKEN_SECRET=your-twitter-access-token-secret\nTWITTER_BEARER_TOKEN=your-twitter-bearer-token\n\n# External Services\nOPENAI_API_KEY=your-openai-api-key-for-ai-features\nANTHROPIC_API_KEY=your-anthropic-api-key-if-using-claude\n\n# Monitoring & Analytics\nSENTRY_DSN=https://your-sentry-dsn-for-error-tracking\nDATADOG_API_KEY=your-datadog-api-key-for-metrics\nGOOGLE_ANALYTICS_ID=your-google-analytics-tracking-id\n\n# Email Configuration (for notifications)\nSMTP_HOST=smtp.yourmailprovider.com\nSMTP_PORT=587\nSMTP_USER=noreply@anubis.chat\nSMTP_PASS=your-smtp-password\nSMTP_FROM=NUBI \u003Cnoreply@anubis.chat>\n\n# File Storage (for uploads/media)\nAWS_ACCESS_KEY_ID=your-aws-access-key\nAWS_SECRET_ACCESS_KEY=your-aws-secret-key\nAWS_REGION=us-west-2\nS3_BUCKET_NAME=nubi-production-assets\nCLOUDFRONT_DOMAIN=cdn.anubis.chat\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Performance & Scaling\">\n```bash\n# Performance Configuration\nCLUSTER_WORKERS=auto  # Use all CPU cores\nWORKER_MEMORY_LIMIT=2048\nWORKER_TIMEOUT=30000\n\n# Database Performance\nDATABASE_STATEMENT_TIMEOUT=10000\nDATABASE_QUERY_TIMEOUT=5000\nDATABASE_IDLE_TIMEOUT=30000\nDATABASE_ACQUIRE_TIMEOUT=60000\n\n# Redis Performance\nREDIS_COMMAND_TIMEOUT=5000\nREDIS_CONNECT_TIMEOUT=10000\nREDIS_RETRY_ATTEMPTS=3\nREDIS_RETRY_DELAY=200\n\n# WebSocket Configuration\nWEBSOCKET_MAX_CONNECTIONS=10000\nWEBSOCKET_PING_INTERVAL=25000\nWEBSOCKET_PING_TIMEOUT=60000\nWEBSOCKET_COMPRESS=true\n\n# HTTP Configuration\nHTTP_KEEP_ALIVE_TIMEOUT=65000\nHTTP_HEADERS_TIMEOUT=66000\nHTTP_MAX_SOCKETS=1024\nHTTP_REQUEST_TIMEOUT=120000\n\n# Caching\nCACHE_TTL_DEFAULT=300  # 5 minutes\nCACHE_TTL_LONG=3600    # 1 hour\nCACHE_TTL_SHORT=60     # 1 minute\n\n# Background Jobs\nQUEUE_CONCURRENCY=10\nQUEUE_MAX_STALLED=5\nQUEUE_RETRY_ATTEMPTS=3\nQUEUE_RETRY_DELAY=5000\n\n# Monitoring\nHEALTH_CHECK_INTERVAL=30000\nMETRICS_COLLECTION_INTERVAL=60000\nLOG_RETENTION_DAYS=30\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## SSL/TLS Configuration\n\n### Certificate Management\n\nProduction NUBI requires proper SSL/TLS certificates:\n\n\u003CTabs>\n  \u003CTabItem label=\"Let's Encrypt (Recommended)\">\n```bash\n# Install Certbot\nsudo apt-get update\nsudo apt-get install certbot python3-certbot-nginx\n\n# Generate certificates for all domains\nsudo certbot --nginx -d anubis.chat -d www.anubis.chat -d api.anubis.chat\n\n# Automatic renewal setup\necho \"0 12 * * * /usr/bin/certbot renew --quiet\" | sudo crontab -\n\n# Nginx configuration with SSL\n# /etc/nginx/sites-available/nubi-production\nserver {\n    listen 80;\n    server_name anubis.chat www.anubis.chat api.anubis.chat;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name anubis.chat www.anubis.chat;\n    \n    ssl_certificate /etc/letsencrypt/live/anubis.chat/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/anubis.chat/privkey.pem;\n    \n    # SSL configuration\n    ssl_session_timeout 1d;\n    ssl_session_cache shared:SSL:50m;\n    ssl_stapling on;\n    ssl_stapling_verify on;\n    \n    # Modern configuration\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    \n    # Security headers\n    add_header Strict-Transport-Security \"max-age=63072000\" always;\n    add_header X-Content-Type-Options nosniff;\n    add_header X-Frame-Options DENY;\n    add_header X-XSS-Protection \"1; mode=block\";\n    \n    # Proxy to Node.js application\n    location / {\n        proxy_pass http://127.0.0.1:3000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_cache_bypass $http_upgrade;\n        proxy_read_timeout 300s;\n        proxy_connect_timeout 75s;\n    }\n    \n    # WebSocket proxy\n    location /socket.io/ {\n        proxy_pass http://127.0.0.1:3000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_read_timeout 300s;\n        proxy_connect_timeout 75s;\n    }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Custom CA Certificate\">\n```bash\n# Custom certificate configuration for enterprise environments\n# Generate private key\nopenssl genrsa -out anubis.chat.key 4096\n\n# Generate certificate signing request\nopenssl req -new -key anubis.chat.key -out anubis.chat.csr -config \u003C(\ncat \u003C\u003CEOF\n[req]\ndistinguished_name = req_distinguished_name\nreq_extensions = v3_req\nprompt = no\n\n[req_distinguished_name]\nC=US\nST=State\nL=City\nO=Organization\nOU=IT Department\nCN=anubis.chat\n\n[v3_req]\nkeyUsage = keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1 = anubis.chat\nDNS.2 = www.anubis.chat\nDNS.3 = api.anubis.chat\nDNS.4 = *.anubis.chat\nEOF\n)\n\n# Submit CSR to your Certificate Authority\n# Once you receive the certificate, install it:\n\n# Nginx SSL configuration for custom certificate\nserver {\n    listen 443 ssl http2;\n    server_name anubis.chat www.anubis.chat api.anubis.chat;\n    \n    ssl_certificate /etc/ssl/certs/anubis.chat.crt;\n    ssl_certificate_key /etc/ssl/private/anubis.chat.key;\n    ssl_trusted_certificate /etc/ssl/certs/ca-bundle.crt;\n    \n    # Enhanced SSL configuration for enterprise\n    ssl_session_timeout 5m;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_tickets off;\n    \n    # OCSP stapling\n    ssl_stapling on;\n    ssl_stapling_verify on;\n    resolver 8.8.8.8 8.8.4.4 valid=300s;\n    resolver_timeout 5s;\n    \n    # Perfect Forward Secrecy\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256';\n    ssl_prefer_server_ciphers on;\n    \n    # HSTS\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n    \n    # Additional security headers\n    add_header X-Content-Type-Options nosniff always;\n    add_header X-Frame-Options DENY always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n    add_header Content-Security-Policy \"default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'\" always;\n    \n    # Rest of configuration...\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Process Management\n\n### Production Process Management\n\nUse PM2 for robust process management in production:\n\n\u003CTabs>\n  \u003CTabItem label=\"PM2 Configuration\">\n```javascript\n// ecosystem.config.js\nmodule.exports = {\n  apps: [\n    {\n      name: 'nubi-production',\n      script: 'dist/index.js',\n      instances: 'max', // Use all CPU cores\n      exec_mode: 'cluster',\n      \n      // Environment\n      env: {\n        NODE_ENV: 'production',\n        PORT: 3000\n      },\n      \n      // Performance\n      max_memory_restart: '2G',\n      min_uptime: '10s',\n      max_restarts: 10,\n      \n      // Logging\n      log_file: '/var/log/nubi/combined.log',\n      out_file: '/var/log/nubi/out.log',\n      error_file: '/var/log/nubi/error.log',\n      log_date_format: 'YYYY-MM-DD HH:mm:ss Z',\n      merge_logs: true,\n      \n      // Monitoring\n      monitoring: true,\n      pmx: true,\n      \n      // Auto restart on file changes (disable in production)\n      watch: false,\n      ignore_watch: ['node_modules', 'logs'],\n      \n      // Source maps for better error tracking\n      source_map_support: true,\n      \n      // Graceful shutdown\n      kill_timeout: 5000,\n      wait_ready: true,\n      listen_timeout: 3000,\n      \n      // Health checks\n      health_check_http: {\n        path: '/health',\n        port: 3000,\n        max_restarts: 3\n      }\n    },\n    \n    // Background job processor\n    {\n      name: 'nubi-worker',\n      script: 'dist/worker.js',\n      instances: 2,\n      exec_mode: 'fork',\n      \n      env: {\n        NODE_ENV: 'production',\n        WORKER_TYPE: 'background'\n      },\n      \n      max_memory_restart: '1G',\n      min_uptime: '10s',\n      max_restarts: 5,\n      \n      // Worker-specific logging\n      log_file: '/var/log/nubi/worker.log',\n      error_file: '/var/log/nubi/worker-error.log',\n      \n      // Cron-like restart (daily at 3 AM)\n      cron_restart: '0 3 * * *'\n    }\n  ],\n  \n  // Deployment configuration\n  deploy: {\n    production: {\n      user: 'deploy',\n      host: ['server1.anubis.chat', 'server2.anubis.chat'],\n      ref: 'origin/main',\n      repo: 'git@github.com:anubis-chat/nubi.git',\n      path: '/var/www/nubi',\n      \n      'pre-deploy-local': '',\n      'post-deploy': 'npm ci && npm run build && pm2 reload ecosystem.config.js --env production',\n      'pre-setup': '',\n      \n      // Environment variables for deployment\n      env: {\n        NODE_ENV: 'production'\n      }\n    }\n  }\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Systemd Service\">\n```ini\n# /etc/systemd/system/nubi.service\n[Unit]\nDescription=NUBI - AI Community Management Platform\nDocumentation=https://docs.anubis.chat\nAfter=network.target postgresql.service redis.service\nWants=postgresql.service redis.service\n\n[Service]\nType=notify\nUser=nubi\nGroup=nubi\nWorkingDirectory=/opt/nubi\nExecStart=/usr/bin/node dist/index.js\nExecReload=/bin/kill -USR2 $MAINPID\n\n# Environment\nEnvironment=NODE_ENV=production\nEnvironmentFile=/opt/nubi/.env.production\n\n# Process management\nRestart=always\nRestartSec=10\nStartLimitInterval=60\nStartLimitBurst=3\n\n# Resource limits\nLimitNOFILE=65536\nLimitNPROC=4096\nTasksMax=4096\n\n# Security\nNoNewPrivileges=true\nProtectSystem=strict\nProtectHome=true\nReadWritePaths=/opt/nubi/logs /opt/nubi/uploads\nPrivateTmp=true\n\n# Logging\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=nubi\n\n# Graceful shutdown\nTimeoutStopSec=30\nKillSignal=SIGTERM\nKillMode=mixed\n\n[Install]\nWantedBy=multi-user.target\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Docker Compose Production\">\n```yaml\n# docker-compose.prod.yml\nversion: '3.8'\n\nservices:\n  nubi-app:\n    image: nubi/app:latest\n    container_name: nubi-production\n    restart: unless-stopped\n    \n    ports:\n      - \"3000:3000\"\n    \n    environment:\n      - NODE_ENV=production\n    env_file:\n      - .env.production\n    \n    depends_on:\n      - postgres\n      - redis\n    \n    networks:\n      - nubi-network\n    \n    volumes:\n      - ./logs:/app/logs\n      - ./uploads:/app/uploads\n    \n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n    \n    deploy:\n      resources:\n        limits:\n          cpus: '4'\n          memory: 4G\n        reservations:\n          cpus: '2'\n          memory: 2G\n    \n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"100m\"\n        max-file: \"5\"\n  \n  postgres:\n    image: postgres:15-alpine\n    container_name: nubi-postgres\n    restart: unless-stopped\n    \n    environment:\n      POSTGRES_DB: nubi_production\n      POSTGRES_USER: nubi\n      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}\n      PGDATA: /var/lib/postgresql/data/pgdata\n    \n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./backups:/backups\n    \n    networks:\n      - nubi-network\n    \n    # Production PostgreSQL configuration\n    command: >\n      postgres\n      -c max_connections=500\n      -c shared_buffers=256MB\n      -c effective_cache_size=1GB\n      -c maintenance_work_mem=64MB\n      -c checkpoint_completion_target=0.9\n      -c wal_buffers=16MB\n      -c default_statistics_target=100\n      -c random_page_cost=1.1\n      -c effective_io_concurrency=200\n      -c work_mem=4MB\n      -c min_wal_size=1GB\n      -c max_wal_size=4GB\n  \n  redis:\n    image: redis:7-alpine\n    container_name: nubi-redis\n    restart: unless-stopped\n    \n    command: >\n      redis-server\n      --maxmemory 2gb\n      --maxmemory-policy allkeys-lru\n      --save 900 1\n      --save 300 10\n      --save 60 10000\n      --appendonly yes\n      --appendfsync everysec\n    \n    volumes:\n      - redis_data:/data\n    \n    networks:\n      - nubi-network\n  \n  # Nginx reverse proxy\n  nginx:\n    image: nginx:alpine\n    container_name: nubi-nginx\n    restart: unless-stopped\n    \n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    \n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./nginx/sites:/etc/nginx/conf.d\n      - ./ssl:/etc/ssl/certs\n      - ./logs/nginx:/var/log/nginx\n    \n    depends_on:\n      - nubi-app\n    \n    networks:\n      - nubi-network\n\nvolumes:\n  postgres_data:\n    driver: local\n  redis_data:\n    driver: local\n\nnetworks:\n  nubi-network:\n    driver: bridge\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\nThis comprehensive production setup guide ensures your NUBI deployment meets enterprise standards for reliability, security, and performance while maintaining the flexibility to scale with your community's growth.","src/content/docs/deployment/production-setup.mdx","25ddeda5f26b186e","deployment/production-setup.mdx","deployment/docker",{"id":273,"data":275,"body":281,"filePath":282,"digest":283,"legacyId":284,"deferredRender":16},{"title":276,"description":277,"editUrl":16,"head":278,"template":47,"sidebar":279,"pagefind":16,"draft":35},"Docker Deployment","Complete Docker containerization guide for NUBI with production-ready configurations and orchestration",[],{"order":206,"hidden":35,"attrs":280},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nThis guide covers containerizing NUBI with Docker for consistent deployments across development, staging, and production environments.\n\n## Docker Configuration\n\n### Multi-Stage Dockerfile\n\nOptimized Dockerfile for production builds with minimal image size:\n\n\u003CTabs>\n  \u003CTabItem label=\"Production Dockerfile\">\n```dockerfile\n# Dockerfile\nFROM node:20-alpine AS base\n\n# Install dependencies only when needed\nFROM base AS deps\nRUN apk add --no-cache libc6-compat\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json bun.lockb ./\n\n# Install dependencies with bun for faster installation\nRUN corepack enable && corepack prepare bun@latest --activate\nRUN bun install --frozen-lockfile --production\n\n# Rebuild the source code only when needed\nFROM base AS builder\nWORKDIR /app\nCOPY --from=deps /app/node_modules ./node_modules\nCOPY . .\n\n# Set build environment\nENV NODE_ENV=production\nENV NEXT_TELEMETRY_DISABLED=1\n\n# Install build dependencies\nRUN corepack enable && corepack prepare bun@latest --activate\n\n# Build the application\nRUN bun install --frozen-lockfile\nRUN bun run build\n\n# Production image, copy all the files and run the application\nFROM base AS runner\nWORKDIR /app\n\n# Create non-root user for security\nRUN addgroup --system --gid 1001 nodejs\nRUN adduser --system --uid 1001 nubiuser\n\n# Set production environment\nENV NODE_ENV=production\nENV NEXT_TELEMETRY_DISABLED=1\n\n# Copy built application\nCOPY --from=builder --chown=nubiuser:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nubiuser:nodejs /app/package*.json ./\nCOPY --from=deps --chown=nubiuser:nodejs /app/node_modules ./node_modules\n\n# Copy static assets if any\nCOPY --from=builder --chown=nubiuser:nodejs /app/public ./public\nCOPY --from=builder --chown=nubiuser:nodejs /app/config ./config\n\n# Create necessary directories\nRUN mkdir -p logs uploads && chown -R nubiuser:nodejs logs uploads\n\n# Switch to non-root user\nUSER nubiuser\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n  CMD node -e \"const http = require('http'); \\\n    const options = { \\\n      host: 'localhost', \\\n      port: process.env.PORT || 3000, \\\n      path: '/health', \\\n      timeout: 2000 \\\n    }; \\\n    const request = http.request(options, (res) => { \\\n      console.log(\\`STATUS: \\${res.statusCode}\\`); \\\n      process.exitCode = (res.statusCode === 200) ? 0 : 1; \\\n    }); \\\n    request.on('error', () => { process.exitCode = 1; }); \\\n    request.end();\"\n\n# Expose port\nEXPOSE 3000\n\n# Start the application\nCMD [\"node\", \"dist/index.js\"]\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Development Dockerfile\">\n```dockerfile\n# Dockerfile.dev\nFROM node:20-alpine\n\n# Install system dependencies\nRUN apk add --no-cache \\\n    libc6-compat \\\n    python3 \\\n    make \\\n    g++ \\\n    git\n\nWORKDIR /app\n\n# Install global tools\nRUN corepack enable && corepack prepare bun@latest --activate\nRUN npm install -g nodemon\n\n# Copy package files\nCOPY package*.json bun.lockb ./\n\n# Install all dependencies (including dev dependencies)\nRUN bun install --frozen-lockfile\n\n# Copy source code\nCOPY . .\n\n# Create necessary directories\nRUN mkdir -p logs uploads .eliza\n\n# Set development environment\nENV NODE_ENV=development\nENV PORT=3000\n\n# Expose port\nEXPOSE 3000\n\n# Enable hot reload\nVOLUME [\"/app/src\", \"/app/config\"]\n\n# Development command with hot reload\nCMD [\"bun\", \"run\", \"dev\"]\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Worker Dockerfile\">\n```dockerfile\n# Dockerfile.worker\nFROM node:20-alpine AS base\n\n# Dependencies stage\nFROM base AS deps\nRUN apk add --no-cache libc6-compat\nWORKDIR /app\nCOPY package*.json bun.lockb ./\nRUN corepack enable && corepack prepare bun@latest --activate\nRUN bun install --frozen-lockfile --production\n\n# Builder stage\nFROM base AS builder\nWORKDIR /app\nCOPY --from=deps /app/node_modules ./node_modules\nCOPY . .\n\nENV NODE_ENV=production\nRUN corepack enable && corepack prepare bun@latest --activate\nRUN bun install --frozen-lockfile\nRUN bun run build\n\n# Worker runtime\nFROM base AS runner\nWORKDIR /app\n\n# Create worker user\nRUN addgroup --system --gid 1001 worker\nRUN adduser --system --uid 1001 workeruser\n\nENV NODE_ENV=production\n\n# Copy worker-specific files\nCOPY --from=builder --chown=workeruser:worker /app/dist ./dist\nCOPY --from=builder --chown=workeruser:worker /app/package*.json ./\nCOPY --from=deps --chown=workeruser:worker /app/node_modules ./node_modules\n\n# Worker-specific directories\nRUN mkdir -p logs queue-data && chown -R workeruser:worker logs queue-data\n\nUSER workeruser\n\n# Health check for worker process\nHEALTHCHECK --interval=60s --timeout=10s --start-period=10s --retries=3 \\\n  CMD node -e \"console.log('Worker health check'); process.exit(0);\"\n\nEXPOSE 3001\n\n# Start worker process\nCMD [\"node\", \"dist/worker.js\"]\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Docker Compose Configurations\n\nComplete Docker Compose setups for different environments:\n\n\u003CTabs>\n  \u003CTabItem label=\"Development Setup\">\n```yaml\n# docker-compose.dev.yml\nversion: '3.8'\n\nservices:\n  nubi-app:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    container_name: nubi-dev\n    restart: unless-stopped\n    \n    ports:\n      - \"3000:3000\"\n      - \"9229:9229\"  # Debug port\n    \n    environment:\n      - NODE_ENV=development\n      - PORT=3000\n      - DEBUG=nubi:*\n    \n    env_file:\n      - .env.development\n    \n    volumes:\n      # Hot reload volumes\n      - ./src:/app/src\n      - ./config:/app/config\n      - ./tests:/app/tests\n      # Persistent data\n      - ./logs:/app/logs\n      - ./.eliza:/app/.eliza\n      - ./uploads:/app/uploads\n      # Node modules (avoid overwriting)\n      - /app/node_modules\n    \n    depends_on:\n      - postgres-dev\n      - redis-dev\n    \n    networks:\n      - nubi-dev-network\n    \n    # Enable debugging\n    command: [\"bun\", \"run\", \"dev:debug\"]\n\n  postgres-dev:\n    image: postgres:15-alpine\n    container_name: nubi-postgres-dev\n    restart: unless-stopped\n    \n    environment:\n      POSTGRES_DB: nubi_development\n      POSTGRES_USER: nubi_dev\n      POSTGRES_PASSWORD: dev_password\n      POSTGRES_INITDB_ARGS: \"--auth-host=scram-sha-256\"\n    \n    ports:\n      - \"5432:5432\"\n    \n    volumes:\n      - postgres_dev_data:/var/lib/postgresql/data\n      - ./docker/postgres/init:/docker-entrypoint-initdb.d\n    \n    networks:\n      - nubi-dev-network\n    \n    # Development PostgreSQL configuration\n    command: >\n      postgres\n      -c log_statement=all\n      -c log_destination=stderr\n      -c log_min_messages=info\n      -c log_min_error_statement=info\n      -c log_min_duration_statement=1000\n\n  redis-dev:\n    image: redis:7-alpine\n    container_name: nubi-redis-dev\n    restart: unless-stopped\n    \n    ports:\n      - \"6379:6379\"\n    \n    volumes:\n      - redis_dev_data:/data\n      - ./docker/redis/redis-dev.conf:/usr/local/etc/redis/redis.conf\n    \n    networks:\n      - nubi-dev-network\n    \n    command: redis-server /usr/local/etc/redis/redis.conf\n\n  # Development tools\n  adminer:\n    image: adminer:latest\n    container_name: nubi-adminer\n    restart: unless-stopped\n    ports:\n      - \"8080:8080\"\n    environment:\n      ADMINER_DEFAULT_SERVER: postgres-dev\n    networks:\n      - nubi-dev-network\n\n  redis-commander:\n    image: rediscommander/redis-commander:latest\n    container_name: nubi-redis-commander\n    restart: unless-stopped\n    ports:\n      - \"8081:8081\"\n    environment:\n      REDIS_HOSTS: local:redis-dev:6379\n    networks:\n      - nubi-dev-network\n\nvolumes:\n  postgres_dev_data:\n  redis_dev_data:\n\nnetworks:\n  nubi-dev-network:\n    driver: bridge\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Production Setup\">\n```yaml\n# docker-compose.prod.yml\nversion: '3.8'\n\nservices:\n  nubi-app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      args:\n        - NODE_ENV=production\n    image: nubi/app:latest\n    container_name: nubi-production\n    restart: unless-stopped\n    \n    ports:\n      - \"3000:3000\"\n    \n    environment:\n      - NODE_ENV=production\n      - PORT=3000\n    \n    env_file:\n      - .env.production\n    \n    volumes:\n      - ./logs:/app/logs:rw\n      - ./uploads:/app/uploads:rw\n      - /etc/localtime:/etc/localtime:ro\n    \n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    \n    networks:\n      - nubi-backend-network\n      - nubi-frontend-network\n    \n    deploy:\n      resources:\n        limits:\n          cpus: '4.0'\n          memory: 4G\n        reservations:\n          cpus: '2.0'\n          memory: 2G\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\n    \n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--no-verbose\", \"--tries=1\", \"--spider\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n    \n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"100m\"\n        max-file: \"5\"\n        compress: \"true\"\n\n  nubi-worker:\n    build:\n      context: .\n      dockerfile: Dockerfile.worker\n    image: nubi/worker:latest\n    container_name: nubi-worker\n    restart: unless-stopped\n    \n    environment:\n      - NODE_ENV=production\n      - WORKER_TYPE=background\n    \n    env_file:\n      - .env.production\n    \n    volumes:\n      - ./logs:/app/logs:rw\n      - ./queue-data:/app/queue-data:rw\n    \n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    \n    networks:\n      - nubi-backend-network\n    \n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n        reservations:\n          cpus: '1.0'\n          memory: 1G\n    \n    healthcheck:\n      test: [\"CMD\", \"node\", \"-e\", \"process.exit(0)\"]\n      interval: 60s\n      timeout: 10s\n      retries: 3\n\n  postgres:\n    image: postgres:15-alpine\n    container_name: nubi-postgres-prod\n    restart: unless-stopped\n    \n    environment:\n      POSTGRES_DB: ${DATABASE_NAME}\n      POSTGRES_USER: ${DATABASE_USER}\n      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}\n      PGDATA: /var/lib/postgresql/data/pgdata\n    \n    volumes:\n      - postgres_prod_data:/var/lib/postgresql/data\n      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf\n      - ./backups:/backups:rw\n    \n    networks:\n      - nubi-backend-network\n    \n    ports:\n      - \"127.0.0.1:5432:5432\"  # Only bind to localhost\n    \n    # Production optimized PostgreSQL\n    command: >\n      postgres\n      -c config_file=/etc/postgresql/postgresql.conf\n      -c max_connections=300\n      -c shared_buffers=1GB\n      -c effective_cache_size=3GB\n      -c maintenance_work_mem=256MB\n      -c checkpoint_completion_target=0.9\n      -c wal_buffers=16MB\n      -c default_statistics_target=100\n      -c random_page_cost=1.1\n      -c effective_io_concurrency=200\n      -c work_mem=8MB\n      -c min_wal_size=2GB\n      -c max_wal_size=8GB\n      -c max_worker_processes=8\n      -c max_parallel_workers_per_gather=4\n      -c max_parallel_workers=8\n      -c max_parallel_maintenance_workers=4\n    \n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DATABASE_USER} -d ${DATABASE_NAME}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    \n    deploy:\n      resources:\n        limits:\n          cpus: '4.0'\n          memory: 4G\n        reservations:\n          cpus: '2.0'\n          memory: 2G\n\n  redis:\n    image: redis:7-alpine\n    container_name: nubi-redis-prod\n    restart: unless-stopped\n    \n    volumes:\n      - redis_prod_data:/data\n      - ./docker/redis/redis-prod.conf:/usr/local/etc/redis/redis.conf\n    \n    networks:\n      - nubi-backend-network\n    \n    ports:\n      - \"127.0.0.1:6379:6379\"  # Only bind to localhost\n    \n    command: redis-server /usr/local/etc/redis/redis.conf\n    \n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 3s\n      retries: 5\n    \n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 512M\n\n  # Reverse proxy\n  nginx:\n    image: nginx:alpine\n    container_name: nubi-nginx-prod\n    restart: unless-stopped\n    \n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    \n    volumes:\n      - ./docker/nginx/nginx-prod.conf:/etc/nginx/nginx.conf:ro\n      - ./docker/nginx/conf.d:/etc/nginx/conf.d:ro\n      - ./ssl:/etc/nginx/ssl:ro\n      - ./logs/nginx:/var/log/nginx:rw\n      - ./static:/var/www/static:ro\n    \n    depends_on:\n      nubi-app:\n        condition: service_healthy\n    \n    networks:\n      - nubi-frontend-network\n    \n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--no-verbose\", \"--tries=1\", \"--spider\", \"http://localhost/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    \n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 512M\n\n  # Backup service\n  backup:\n    image: alpine:latest\n    container_name: nubi-backup\n    restart: \"no\"\n    \n    volumes:\n      - postgres_prod_data:/var/lib/postgresql/data:ro\n      - redis_prod_data:/var/lib/redis/data:ro\n      - ./backups:/backups:rw\n      - ./docker/backup/backup.sh:/backup.sh:ro\n    \n    networks:\n      - nubi-backend-network\n    \n    depends_on:\n      - postgres\n      - redis\n    \n    command: [\"sh\", \"/backup.sh\"]\n    \n    # Run backup daily at 2 AM\n    # Use external cron or Kubernetes CronJob for scheduling\n\nvolumes:\n  postgres_prod_data:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /data/nubi/postgres\n  \n  redis_prod_data:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /data/nubi/redis\n\nnetworks:\n  nubi-frontend-network:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.20.1.0/24\n  \n  nubi-backend-network:\n    driver: bridge\n    internal: true\n    ipam:\n      config:\n        - subnet: 172.20.2.0/24\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Testing Environment\">\n```yaml\n# docker-compose.test.yml\nversion: '3.8'\n\nservices:\n  nubi-test:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n      target: base\n    container_name: nubi-test-runner\n    \n    environment:\n      - NODE_ENV=test\n      - PORT=3001\n      - DATABASE_URL=postgresql://test_user:test_pass@postgres-test:5432/nubi_test\n      - REDIS_URL=redis://redis-test:6379/0\n    \n    volumes:\n      - ./src:/app/src:ro\n      - ./tests:/app/tests:ro\n      - ./config:/app/config:ro\n      - ./coverage:/app/coverage:rw\n      - ./test-results:/app/test-results:rw\n    \n    depends_on:\n      postgres-test:\n        condition: service_healthy\n      redis-test:\n        condition: service_healthy\n    \n    networks:\n      - nubi-test-network\n    \n    command: [\"bun\", \"run\", \"test:ci\"]\n\n  postgres-test:\n    image: postgres:15-alpine\n    container_name: nubi-postgres-test\n    \n    environment:\n      POSTGRES_DB: nubi_test\n      POSTGRES_USER: test_user\n      POSTGRES_PASSWORD: test_pass\n    \n    tmpfs:\n      - /var/lib/postgresql/data\n    \n    networks:\n      - nubi-test-network\n    \n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U test_user -d nubi_test\"]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n\n  redis-test:\n    image: redis:7-alpine\n    container_name: nubi-redis-test\n    \n    tmpfs:\n      - /data\n    \n    networks:\n      - nubi-test-network\n    \n    command: redis-server --save \"\"\n    \n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 5s\n      timeout: 3s\n      retries: 5\n\n  # Integration test services\n  nubi-integration:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    container_name: nubi-integration-test\n    \n    environment:\n      - NODE_ENV=test\n      - TEST_TYPE=integration\n    \n    volumes:\n      - ./tests/integration:/app/tests/integration:ro\n      - ./test-results:/app/test-results:rw\n    \n    depends_on:\n      nubi-test:\n        condition: service_completed_successfully\n    \n    networks:\n      - nubi-test-network\n    \n    command: [\"bun\", \"run\", \"test:integration\"]\n\n  # End-to-end test services\n  nubi-e2e:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    container_name: nubi-e2e-test\n    \n    environment:\n      - NODE_ENV=test\n      - TEST_TYPE=e2e\n      - BASE_URL=http://nubi-app:3000\n    \n    volumes:\n      - ./tests/e2e:/app/tests/e2e:ro\n      - ./test-results:/app/test-results:rw\n    \n    depends_on:\n      nubi-app:\n        condition: service_healthy\n    \n    networks:\n      - nubi-test-network\n    \n    command: [\"bun\", \"run\", \"test:e2e\"]\n\n  # Performance test services\n  nubi-perf:\n    image: loadimpact/k6:latest\n    container_name: nubi-perf-test\n    \n    volumes:\n      - ./tests/performance:/scripts:ro\n      - ./test-results:/results:rw\n    \n    depends_on:\n      nubi-app:\n        condition: service_healthy\n    \n    networks:\n      - nubi-test-network\n    \n    command: [\"run\", \"--out\", \"json=/results/performance.json\", \"/scripts/load-test.js\"]\n\nnetworks:\n  nubi-test-network:\n    driver: bridge\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Container Orchestration\n\n### Kubernetes Deployment\n\nProduction-ready Kubernetes manifests for scalable deployment:\n\n\u003CTabs>\n  \u003CTabItem label=\"Namespace & ConfigMap\">\n```yaml\n# k8s/00-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: nubi-production\n  labels:\n    name: nubi-production\n    app.kubernetes.io/name: nubi\n    app.kubernetes.io/instance: production\n\n---\n# k8s/01-configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nubi-config\n  namespace: nubi-production\ndata:\n  NODE_ENV: \"production\"\n  PORT: \"3000\"\n  LOG_LEVEL: \"info\"\n  \n  # Database configuration\n  DATABASE_POOL_MIN: \"10\"\n  DATABASE_POOL_MAX: \"50\"\n  DATABASE_SSL: \"true\"\n  \n  # Redis configuration\n  REDIS_CLUSTER_MODE: \"true\"\n  REDIS_TLS: \"true\"\n  \n  # Application configuration\n  APP_NAME: \"NUBI\"\n  APP_VERSION: \"2.0.0\"\n  \n  # Rate limiting\n  RATE_LIMIT_WINDOW_MS: \"900000\"\n  RATE_LIMIT_MAX_REQUESTS: \"100\"\n  \n  # Session configuration\n  SESSION_MAX_AGE: \"86400000\"\n  \n  # WebSocket configuration\n  WEBSOCKET_MAX_CONNECTIONS: \"10000\"\n  WEBSOCKET_PING_INTERVAL: \"25000\"\n\n---\n# k8s/02-secrets.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: nubi-secrets\n  namespace: nubi-production\ntype: Opaque\nstringData:\n  database-url: \"postgresql://user:password@postgres-service:5432/nubi_production\"\n  redis-url: \"redis://redis-service:6379/0\"\n  jwt-secret: \"your-super-secret-jwt-key-64-chars-minimum\"\n  session-secret: \"your-session-secret-key-for-production\"\n  \n  # Platform API keys\n  telegram-bot-token: \"your-telegram-bot-token\"\n  discord-bot-token: \"your-discord-bot-token\"\n  twitter-api-key: \"your-twitter-api-key\"\n  twitter-api-secret: \"your-twitter-api-secret\"\n  \n  # External service keys\n  openai-api-key: \"your-openai-api-key\"\n  sentry-dsn: \"your-sentry-dsn\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Application Deployment\">\n```yaml\n# k8s/03-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nubi-app\n  namespace: nubi-production\n  labels:\n    app.kubernetes.io/name: nubi\n    app.kubernetes.io/component: app\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: nubi\n      app.kubernetes.io/component: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: nubi\n        app.kubernetes.io/component: app\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"3000\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1001\n        runAsGroup: 1001\n        fsGroup: 1001\n      containers:\n      - name: nubi\n        image: nubi/app:latest\n        imagePullPolicy: Always\n        \n        ports:\n        - name: http\n          containerPort: 3000\n          protocol: TCP\n        \n        envFrom:\n        - configMapRef:\n            name: nubi-config\n        - secretRef:\n            name: nubi-secrets\n        \n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"2000m\"\n        \n        readinessProbe:\n          httpGet:\n            path: /health\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 3\n        \n        livenessProbe:\n          httpGet:\n            path: /health\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 10\n          successThreshold: 1\n          failureThreshold: 3\n        \n        volumeMounts:\n        - name: logs\n          mountPath: /app/logs\n        - name: uploads\n          mountPath: /app/uploads\n        \n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n      \n      volumes:\n      - name: logs\n        emptyDir:\n          sizeLimit: 5Gi\n      - name: uploads\n        persistentVolumeClaim:\n          claimName: nubi-uploads-pvc\n      \n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app.kubernetes.io/name\n                  operator: In\n                  values:\n                  - nubi\n                - key: app.kubernetes.io/component\n                  operator: In\n                  values:\n                  - app\n              topologyKey: kubernetes.io/hostname\n\n---\n# k8s/04-service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: nubi-app-service\n  namespace: nubi-production\n  labels:\n    app.kubernetes.io/name: nubi\n    app.kubernetes.io/component: app\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n  selector:\n    app.kubernetes.io/name: nubi\n    app.kubernetes.io/component: app\n\n---\n# k8s/05-ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nubi-ingress\n  namespace: nubi-production\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: \"600\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"600\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"https://anubis.chat\"\n    nginx.ingress.kubernetes.io/websocket-services: \"nubi-app-service\"\n    nginx.ingress.kubernetes.io/upstream-hash-by: \"$remote_addr\"\nspec:\n  tls:\n  - hosts:\n    - anubis.chat\n    - api.anubis.chat\n    secretName: nubi-tls\n  rules:\n  - host: anubis.chat\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nubi-app-service\n            port:\n              number: 80\n  - host: api.anubis.chat\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nubi-app-service\n            port:\n              number: 80\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Database Services\">\n```yaml\n# k8s/06-postgres.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: postgres-pvc\n  namespace: nubi-production\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: fast-ssd\n  resources:\n    requests:\n      storage: 100Gi\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\n  namespace: nubi-production\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      securityContext:\n        runAsUser: 999\n        runAsGroup: 999\n        fsGroup: 999\n      containers:\n      - name: postgres\n        image: postgres:15-alpine\n        \n        env:\n        - name: POSTGRES_DB\n          value: nubi_production\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: username\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: password\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        \n        ports:\n        - containerPort: 5432\n        \n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n        \n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n        \n        readinessProbe:\n          exec:\n            command:\n              - /bin/sh\n              - -c\n              - pg_isready -U $POSTGRES_USER -d $POSTGRES_DB -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 15\n          periodSeconds: 10\n        \n        livenessProbe:\n          exec:\n            command:\n              - /bin/sh\n              - -c\n              - pg_isready -U $POSTGRES_USER -d $POSTGRES_DB -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 45\n          periodSeconds: 30\n      \n      volumes:\n      - name: postgres-storage\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-service\n  namespace: nubi-production\nspec:\n  ports:\n  - port: 5432\n  selector:\n    app: postgres\n\n---\n# k8s/07-redis.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-pvc\n  namespace: nubi-production\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: fast-ssd\n  resources:\n    requests:\n      storage: 10Gi\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  namespace: nubi-production\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      securityContext:\n        runAsUser: 999\n        runAsGroup: 999\n        fsGroup: 999\n      containers:\n      - name: redis\n        image: redis:7-alpine\n        \n        command: [\"redis-server\"]\n        args: [\"--appendonly\", \"yes\", \"--maxmemory\", \"1gb\", \"--maxmemory-policy\", \"allkeys-lru\"]\n        \n        ports:\n        - containerPort: 6379\n        \n        volumeMounts:\n        - name: redis-storage\n          mountPath: /data\n        \n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n        \n        readinessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        \n        livenessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 30\n          periodSeconds: 30\n      \n      volumes:\n      - name: redis-storage\n        persistentVolumeClaim:\n          claimName: redis-pvc\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-service\n  namespace: nubi-production\nspec:\n  ports:\n  - port: 6379\n  selector:\n    app: redis\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Container Management\n\n### Build and Deployment Scripts\n\nAutomated scripts for container lifecycle management:\n\n\u003CTabs>\n  \u003CTabItem label=\"Build Script\">\n```bash\n#!/bin/bash\n# scripts/docker-build.sh\n\nset -e\n\n# Configuration\nREGISTRY=${DOCKER_REGISTRY:-\"nubi\"}\nVERSION=${VERSION:-$(git rev-parse --short HEAD)}\nPLATFORM=${PLATFORM:-\"linux/amd64,linux/arm64\"}\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Validate requirements\ncheck_requirements() {\n    log \"Checking requirements...\"\n    \n    if ! command -v docker &> /dev/null; then\n        error \"Docker is not installed\"\n    fi\n    \n    if ! docker buildx version &> /dev/null; then\n        error \"Docker buildx is not available\"\n    fi\n    \n    log \"Requirements check passed\"\n}\n\n# Build multi-architecture images\nbuild_images() {\n    log \"Building Docker images...\"\n    \n    # Create buildx builder if it doesn't exist\n    docker buildx create --name nubi-builder --use --bootstrap 2>/dev/null || docker buildx use nubi-builder\n    \n    # Build main application image\n    log \"Building main application image...\"\n    docker buildx build \\\n        --platform $PLATFORM \\\n        --tag ${REGISTRY}/app:${VERSION} \\\n        --tag ${REGISTRY}/app:latest \\\n        --file Dockerfile \\\n        --push \\\n        .\n    \n    # Build worker image\n    log \"Building worker image...\"\n    docker buildx build \\\n        --platform $PLATFORM \\\n        --tag ${REGISTRY}/worker:${VERSION} \\\n        --tag ${REGISTRY}/worker:latest \\\n        --file Dockerfile.worker \\\n        --push \\\n        .\n    \n    log \"Docker images built successfully\"\n}\n\n# Run tests in containers\nrun_tests() {\n    log \"Running tests in containers...\"\n    \n    # Pull latest test dependencies\n    docker-compose -f docker-compose.test.yml pull\n    \n    # Run unit tests\n    docker-compose -f docker-compose.test.yml run --rm nubi-test\n    \n    # Run integration tests\n    docker-compose -f docker-compose.test.yml run --rm nubi-integration\n    \n    # Clean up test containers\n    docker-compose -f docker-compose.test.yml down -v\n    \n    log \"All tests passed\"\n}\n\n# Security scan\nsecurity_scan() {\n    log \"Running security scan...\"\n    \n    # Install trivy if not present\n    if ! command -v trivy &> /dev/null; then\n        warn \"Trivy not found, installing...\"\n        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin\n    fi\n    \n    # Scan images for vulnerabilities\n    trivy image --severity HIGH,CRITICAL ${REGISTRY}/app:${VERSION}\n    trivy image --severity HIGH,CRITICAL ${REGISTRY}/worker:${VERSION}\n    \n    log \"Security scan completed\"\n}\n\n# Main execution\nmain() {\n    log \"Starting Docker build process...\"\n    \n    check_requirements\n    run_tests\n    build_images\n    security_scan\n    \n    log \"Docker build process completed successfully\"\n    log \"Images available:\"\n    log \"  ${REGISTRY}/app:${VERSION}\"\n    log \"  ${REGISTRY}/worker:${VERSION}\"\n}\n\n# Handle script arguments\ncase ${1:-build} in\n    \"build\")\n        main\n        ;;\n    \"test\")\n        run_tests\n        ;;\n    \"scan\")\n        security_scan\n        ;;\n    *)\n        echo \"Usage: $0 [build|test|scan]\"\n        exit 1\n        ;;\nesac\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Deployment Script\">\n```bash\n#!/bin/bash\n# scripts/docker-deploy.sh\n\nset -e\n\n# Configuration\nENVIRONMENT=${ENVIRONMENT:-\"production\"}\nREGISTRY=${DOCKER_REGISTRY:-\"nubi\"}\nVERSION=${VERSION:-\"latest\"}\nCOMPOSE_FILE=\"docker-compose.${ENVIRONMENT}.yml\"\n\n# Colors\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nRED='\\033[0;31m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Pre-deployment checks\npre_deployment_checks() {\n    log \"Running pre-deployment checks...\"\n    \n    # Check if Docker Compose file exists\n    if [[ ! -f \"$COMPOSE_FILE\" ]]; then\n        error \"Compose file $COMPOSE_FILE not found\"\n    fi\n    \n    # Check if environment file exists\n    if [[ ! -f \".env.${ENVIRONMENT}\" ]]; then\n        error \"Environment file .env.${ENVIRONMENT} not found\"\n    fi\n    \n    # Validate environment variables\n    source \".env.${ENVIRONMENT}\"\n    \n    required_vars=(\n        \"DATABASE_URL\"\n        \"REDIS_URL\"\n        \"JWT_SECRET\"\n        \"SESSION_SECRET\"\n    )\n    \n    for var in \"${required_vars[@]}\"; do\n        if [[ -z \"${!var}\" ]]; then\n            error \"Required environment variable $var is not set\"\n        fi\n    done\n    \n    log \"Pre-deployment checks passed\"\n}\n\n# Create necessary directories\nprepare_directories() {\n    log \"Preparing directories...\"\n    \n    directories=(\n        \"./logs\"\n        \"./uploads\"\n        \"./backups\"\n        \"./ssl\"\n    )\n    \n    for dir in \"${directories[@]}\"; do\n        if [[ ! -d \"$dir\" ]]; then\n            mkdir -p \"$dir\"\n            log \"Created directory: $dir\"\n        fi\n    done\n}\n\n# Pull latest images\npull_images() {\n    log \"Pulling latest images...\"\n    \n    export VERSION\n    docker-compose -f \"$COMPOSE_FILE\" pull\n    \n    log \"Images pulled successfully\"\n}\n\n# Database migrations\nrun_migrations() {\n    log \"Running database migrations...\"\n    \n    # Check if database is accessible\n    docker-compose -f \"$COMPOSE_FILE\" run --rm nubi-app \\\n        node -e \"\n            const { Pool } = require('pg');\n            const pool = new Pool({ connectionString: process.env.DATABASE_URL });\n            pool.query('SELECT NOW()')\n                .then(() => { console.log('Database connection successful'); process.exit(0); })\n                .catch(err => { console.error('Database connection failed:', err); process.exit(1); });\n        \"\n    \n    # Run migrations\n    docker-compose -f \"$COMPOSE_FILE\" run --rm nubi-app npm run migrate\n    \n    log \"Database migrations completed\"\n}\n\n# Deploy services\ndeploy_services() {\n    log \"Deploying services...\"\n    \n    # Deploy with zero-downtime strategy\n    docker-compose -f \"$COMPOSE_FILE\" up -d --remove-orphans\n    \n    # Wait for services to be healthy\n    log \"Waiting for services to be healthy...\"\n    \n    timeout=300  # 5 minutes\n    elapsed=0\n    \n    while [[ $elapsed -lt $timeout ]]; do\n        if docker-compose -f \"$COMPOSE_FILE\" ps | grep -q \"unhealthy\"; then\n            sleep 10\n            elapsed=$((elapsed + 10))\n        else\n            log \"All services are healthy\"\n            return 0\n        fi\n    done\n    \n    error \"Services failed to become healthy within $timeout seconds\"\n}\n\n# Post-deployment verification\npost_deployment_verification() {\n    log \"Running post-deployment verification...\"\n    \n    # Health check\n    if curl -f \"http://localhost/health\" > /dev/null 2>&1; then\n        log \"Health check passed\"\n    else\n        error \"Health check failed\"\n    fi\n    \n    # API check\n    if curl -f \"http://localhost/api/v1/health\" > /dev/null 2>&1; then\n        log \"API check passed\"\n    else\n        warn \"API check failed - this might be expected for some configurations\"\n    fi\n    \n    # WebSocket check\n    if curl -f \"http://localhost/socket.io/\" > /dev/null 2>&1; then\n        log \"WebSocket endpoint check passed\"\n    else\n        warn \"WebSocket endpoint check failed\"\n    fi\n    \n    log \"Post-deployment verification completed\"\n}\n\n# Cleanup old containers and images\ncleanup() {\n    log \"Cleaning up old containers and images...\"\n    \n    # Remove old containers\n    docker container prune -f\n    \n    # Remove old images (keep last 3 versions)\n    docker images \"${REGISTRY}/app\" --format \"table {{.Repository}}:{{.Tag}}\\t{{.CreatedAt}}\" | \\\n        tail -n +4 | \\\n        awk '{print $1}' | \\\n        xargs -r docker rmi\n    \n    # Remove unused volumes (be careful in production)\n    if [[ \"$ENVIRONMENT\" != \"production\" ]]; then\n        docker volume prune -f\n    fi\n    \n    log \"Cleanup completed\"\n}\n\n# Rollback function\nrollback() {\n    local previous_version=${1:-\"previous\"}\n    \n    warn \"Rolling back to version: $previous_version\"\n    \n    VERSION=\"$previous_version\" docker-compose -f \"$COMPOSE_FILE\" up -d\n    \n    log \"Rollback completed\"\n}\n\n# Main deployment function\nmain() {\n    log \"Starting deployment to $ENVIRONMENT environment...\"\n    \n    pre_deployment_checks\n    prepare_directories\n    pull_images\n    \n    if [[ \"$ENVIRONMENT\" == \"production\" ]]; then\n        run_migrations\n    fi\n    \n    deploy_services\n    post_deployment_verification\n    \n    if [[ \"$1\" != \"--no-cleanup\" ]]; then\n        cleanup\n    fi\n    \n    log \"Deployment to $ENVIRONMENT completed successfully!\"\n}\n\n# Handle script arguments\ncase ${1:-deploy} in\n    \"deploy\")\n        main \"$2\"\n        ;;\n    \"rollback\")\n        rollback \"$2\"\n        ;;\n    \"health\")\n        post_deployment_verification\n        ;;\n    \"cleanup\")\n        cleanup\n        ;;\n    *)\n        echo \"Usage: $0 [deploy|rollback|health|cleanup]\"\n        echo \"Environment: $ENVIRONMENT\"\n        exit 1\n        ;;\nesac\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\nThis comprehensive Docker deployment guide provides everything needed to containerize NUBI for any environment, from development to enterprise-scale production deployments with proper orchestration, monitoring, and security configurations.","src/content/docs/deployment/docker.mdx","25295248710d7dd1","deployment/docker.mdx","deployment/environment-variables",{"id":285,"data":287,"body":293,"filePath":294,"digest":295,"legacyId":296,"deferredRender":16},{"title":288,"description":289,"editUrl":16,"head":290,"template":47,"sidebar":291,"pagefind":16,"draft":35},"Environment Variables","Complete reference for all environment variables and configuration options required to run NUBI in any environment",[],{"order":219,"hidden":35,"attrs":292},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nThis comprehensive guide covers all environment variables needed to configure NUBI for development, staging, and production environments.\n\n## Core Configuration\n\n### Application Settings\n\nEssential variables for basic NUBI operation:\n\n\u003CTabs>\n  \u003CTabItem label=\"Required Variables\">\n```bash\n# .env (Required for all environments)\n\n# Application Identity\nNODE_ENV=production                    # Environment: development | staging | production\nAPP_NAME=NUBI                         # Application name for logging and monitoring\nAPP_VERSION=2.0.0                     # Version identifier\nPORT=3000                            # HTTP server port\nHOST=0.0.0.0                         # Bind address (0.0.0.0 for containers, localhost for local)\n\n# URLs (Critical for CORS and redirects)\nAPP_URL=https://anubis.chat           # Frontend application URL\nAPI_URL=https://api.anubis.chat       # API base URL\nWEBSOCKET_URL=wss://api.anubis.chat   # WebSocket connection URL\n\n# Database Connection (Primary data store)\nDATABASE_URL=postgresql://user:pass@localhost:5432/nubi_prod\n# Format: postgresql://[user]:[password]@[host]:[port]/[database]?[params]\n\n# Redis Connection (Caching and sessions)\nREDIS_URL=redis://localhost:6379/0\n# Format: redis://[user:pass@]host:port[/db][?options]\n\n# Security Keys (Generate unique values for production!)\nJWT_SECRET=your-jwt-secret-minimum-64-characters-for-security\nJWT_EXPIRY=24h                       # Token expiration: 15m, 1h, 24h, 7d\nJWT_REFRESH_EXPIRY=7d               # Refresh token expiration\n\nSESSION_SECRET=your-session-secret-for-cookie-signing-production\nSESSION_MAX_AGE=86400000            # Session duration in milliseconds (24h)\n\n# Password Security\nBCRYPT_ROUNDS=12                    # Hashing rounds (10-12 for production)\nPASSWORD_MIN_LENGTH=8               # Minimum password length\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Optional Variables\">\n```bash\n# Optional Configuration Variables\n\n# Logging\nLOG_LEVEL=info                      # Logging level: error | warn | info | debug | trace\nLOG_FORMAT=json                     # Log format: json | pretty | simple\nLOG_FILE_PATH=./logs/nubi.log      # Log file location (optional)\nLOG_MAX_SIZE=100mb                 # Max log file size\nLOG_MAX_FILES=10                   # Max log files to retain\n\n# Performance & Scaling\nCLUSTER_WORKERS=auto               # Number of worker processes: auto | number\nWORKER_MEMORY_LIMIT=2048           # Worker memory limit in MB\nWORKER_TIMEOUT=30000              # Worker timeout in milliseconds\n\n# Health Checks\nHEALTH_CHECK_INTERVAL=30000       # Health check interval in milliseconds\nHEALTH_CHECK_TIMEOUT=5000         # Health check timeout\n\n# Graceful Shutdown\nSHUTDOWN_TIMEOUT=10000            # Graceful shutdown timeout\nKEEP_ALIVE_TIMEOUT=5000          # Keep-alive timeout\n\n# Timezone\nTZ=UTC                            # Timezone for the application\nLOCALE=en-US                      # Default locale\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Database Configuration\n\nAdvanced database connection and performance settings:\n\n\u003CTabs>\n  \u003CTabItem label=\"PostgreSQL Settings\">\n```bash\n# PostgreSQL Configuration\n\n# Connection Pool Settings\nDATABASE_POOL_MIN=5               # Minimum pool connections\nDATABASE_POOL_MAX=20              # Maximum pool connections\nDATABASE_POOL_IDLE_TIMEOUT=30000  # Idle connection timeout (ms)\nDATABASE_POOL_ACQUIRE_TIMEOUT=60000 # Connection acquire timeout (ms)\n\n# Query Configuration  \nDATABASE_STATEMENT_TIMEOUT=10000  # Statement timeout (ms)\nDATABASE_QUERY_TIMEOUT=5000      # Individual query timeout (ms)\nDATABASE_COMMAND_TIMEOUT=30000   # Command timeout (ms)\n\n# SSL Configuration\nDATABASE_SSL=true                 # Enable SSL connection\nDATABASE_SSL_REJECT_UNAUTHORIZED=true # Reject unauthorized SSL\nDATABASE_SSL_CA_CERT_PATH=/path/to/ca-cert.pem # CA certificate path\nDATABASE_SSL_CLIENT_CERT_PATH=/path/to/client-cert.pem # Client cert\nDATABASE_SSL_CLIENT_KEY_PATH=/path/to/client-key.pem # Client key\n\n# Performance Tuning\nDATABASE_MAX_PREPARED_STATEMENTS=100 # Max prepared statements\nDATABASE_ENABLE_QUERY_LOGGING=false  # Log all queries (dev only)\nDATABASE_SLOW_QUERY_THRESHOLD=1000   # Log slow queries over N ms\n\n# Migrations\nDATABASE_MIGRATIONS_DIR=./migrations # Migrations directory\nDATABASE_MIGRATIONS_TABLE=knex_migrations # Migrations table name\nDATABASE_AUTO_MIGRATE=false         # Auto-run migrations on startup\n\n# Example connection strings for different environments:\n# Local development:\n# DATABASE_URL=postgresql://nubi:password@localhost:5432/nubi_dev\n\n# Docker compose:\n# DATABASE_URL=postgresql://nubi:password@postgres:5432/nubi_dev\n\n# Production with SSL:\n# DATABASE_URL=postgresql://user:pass@prod-host:5432/nubi_prod?sslmode=require\n\n# Amazon RDS:\n# DATABASE_URL=postgresql://user:pass@nubi.abcd1234.us-west-2.rds.amazonaws.com:5432/nubi\n\n# Google Cloud SQL:\n# DATABASE_URL=postgresql://user:pass@10.1.1.1:5432/nubi?sslmode=require\n\n# Azure Database:\n# DATABASE_URL=postgresql://user%40server:pass@server.postgres.database.azure.com:5432/nubi?sslmode=require\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Redis Settings\">\n```bash\n# Redis Configuration\n\n# Connection Settings\nREDIS_HOST=localhost              # Redis host\nREDIS_PORT=6379                  # Redis port\nREDIS_DB=0                       # Redis database number (0-15)\nREDIS_PASSWORD=your-redis-pass   # Redis password (if auth enabled)\nREDIS_USERNAME=your-redis-user   # Redis username (Redis 6+)\n\n# Advanced Connection Options\nREDIS_CONNECT_TIMEOUT=10000      # Connection timeout (ms)\nREDIS_COMMAND_TIMEOUT=5000       # Command timeout (ms)\nREDIS_RETRY_ATTEMPTS=3           # Connection retry attempts\nREDIS_RETRY_DELAY=200           # Retry delay (ms)\n\n# SSL/TLS Configuration\nREDIS_TLS=false                 # Enable TLS connection\nREDIS_TLS_CERT_PATH=/path/to/cert.pem # TLS certificate\nREDIS_TLS_KEY_PATH=/path/to/key.pem   # TLS private key\nREDIS_TLS_CA_PATH=/path/to/ca.pem     # TLS CA certificate\n\n# Cluster Configuration\nREDIS_CLUSTER_MODE=false        # Enable cluster mode\nREDIS_CLUSTER_NODES=node1:6379,node2:6379,node3:6379 # Cluster nodes\nREDIS_CLUSTER_MAX_REDIRECTIONS=16 # Max cluster redirections\n\n# Performance Settings\nREDIS_MAX_RETRIES_PER_REQUEST=3 # Max retries per request\nREDIS_KEEP_ALIVE=30000         # Keep-alive interval\nREDIS_FAMILY=4                 # IP family (4 or 6)\n\n# Memory Management\nREDIS_MAX_MEMORY_POLICY=allkeys-lru # Memory eviction policy\nREDIS_KEY_PREFIX=nubi:         # Key prefix for namespacing\n\n# Example Redis configurations:\n# Local Redis:\n# REDIS_URL=redis://localhost:6379/0\n\n# Redis with password:\n# REDIS_URL=redis://:password@localhost:6379/0\n\n# Redis with username and password (Redis 6+):\n# REDIS_URL=redis://username:password@localhost:6379/0\n\n# Redis over TLS:\n# REDIS_URL=rediss://username:password@hostname:6380/0\n\n# Amazon ElastiCache:\n# REDIS_URL=redis://clustercfg.my-cluster.abcd12.cache.amazonaws.com:6379/0\n\n# Google Cloud Memorystore:\n# REDIS_URL=redis://10.1.1.1:6379/0\n\n# Azure Cache for Redis:\n# REDIS_URL=rediss://:password@cachename.redis.cache.windows.net:6380/0\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Platform Integration\n\n### Social Media Platform APIs\n\nConfiguration for Telegram, Discord, X/Twitter, and other platform integrations:\n\n\u003CTabs>\n  \u003CTabItem label=\"Telegram Configuration\">\n```bash\n# Telegram Bot Configuration\n\n# Bot Authentication (Required)\nTELEGRAM_BOT_TOKEN=123456789:ABCdefGHIjklMNOpqrSTUvwxYZ # From @BotFather\nTELEGRAM_BOT_USERNAME=YourBotUsername                    # Bot username without @\n\n# Webhook Configuration (Production)\nTELEGRAM_WEBHOOK_URL=https://api.anubis.chat/webhooks/telegram\nTELEGRAM_WEBHOOK_SECRET=your-webhook-secret-for-verification\nTELEGRAM_WEBHOOK_PORT=8443                              # Webhook port (optional)\nTELEGRAM_USE_POLLING=false                              # Use polling instead of webhook\n\n# Bot Settings\nTELEGRAM_ADMIN_USER_IDS=123456789,987654321            # Comma-separated admin user IDs\nTELEGRAM_MAIN_CHAT_ID=@anubis_community                # Main community chat\nTELEGRAM_RAID_COORDINATION_CHAT=@anubis_raids          # Raid coordination chat\nTELEGRAM_ANNOUNCEMENTS_CHAT=@anubis_announcements      # Announcements channel\n\n# Rate Limiting\nTELEGRAM_RATE_LIMIT_MESSAGES_PER_SECOND=30            # Max messages per second\nTELEGRAM_RATE_LIMIT_MESSAGES_PER_MINUTE=20            # Max messages per minute to same chat\nTELEGRAM_RATE_LIMIT_EDITS_PER_MINUTE=1000             # Max message edits per minute\n\n# Media Settings\nTELEGRAM_MAX_FILE_SIZE=50485760                        # Max file size (48MB)\nTELEGRAM_MEDIA_CACHE_TTL=3600                         # Media cache TTL seconds\n\n# Feature Flags\nTELEGRAM_ENABLE_INLINE_QUERIES=true                   # Enable inline queries\nTELEGRAM_ENABLE_WEB_APP=false                         # Enable Telegram Web App\nTELEGRAM_ENABLE_PAYMENTS=false                        # Enable Telegram Payments\n\n# Development Settings\nTELEGRAM_TEST_ENVIRONMENT=false                       # Use test environment\nTELEGRAM_LOG_ALL_UPDATES=false                       # Log all incoming updates\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Discord Configuration\">\n```bash\n# Discord Bot Configuration\n\n# Bot Authentication (Required)\nDISCORD_BOT_TOKEN=your-discord-bot-token-here         # From Discord Developer Portal\nDISCORD_CLIENT_ID=your-discord-client-id              # Application ID\nDISCORD_CLIENT_SECRET=your-discord-client-secret      # OAuth2 client secret\n\n# Guild Settings\nDISCORD_MAIN_GUILD_ID=123456789012345678             # Primary Discord server ID\nDISCORD_ADMIN_ROLE_ID=123456789012345678             # Admin role ID\nDISCORD_MODERATOR_ROLE_ID=123456789012345678         # Moderator role ID\n\n# Channel Configuration\nDISCORD_GENERAL_CHANNEL_ID=123456789012345678        # General discussion channel\nDISCORD_RAIDS_CHANNEL_ID=123456789012345678          # Raid coordination channel\nDISCORD_ANNOUNCEMENTS_CHANNEL_ID=123456789012345678 # Announcements channel\nDISCORD_LOGS_CHANNEL_ID=123456789012345678           # Bot logs channel\n\n# Voice Channel Settings\nDISCORD_VOICE_CHANNEL_ID=123456789012345678          # Raid voice channel\nDISCORD_AUTO_JOIN_VOICE=false                        # Auto-join voice for raids\nDISCORD_VOICE_RECORD_SESSIONS=false                  # Record voice sessions\n\n# Permissions\nDISCORD_REQUIRED_PERMISSIONS=8                        # Required bot permissions bitmask\nDISCORD_SLASH_COMMANDS_GUILD_ONLY=true               # Restrict slash commands to guild\n\n# Rate Limiting\nDISCORD_RATE_LIMIT_REQUESTS_PER_SECOND=5             # Max requests per second\nDISCORD_RATE_LIMIT_BURST=10                          # Burst limit\n\n# Rich Presence\nDISCORD_RICH_PRESENCE=true                           # Enable rich presence\nDISCORD_ACTIVITY_TYPE=0                              # Activity type (0=Playing, 1=Streaming, 2=Listening, 3=Watching)\nDISCORD_ACTIVITY_NAME=Managing Community             # Activity name\n\n# Developer Settings\nDISCORD_DEVELOPER_MODE=false                         # Enable developer features\nDISCORD_LOG_GATEWAY_EVENTS=false                    # Log gateway events\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"X/Twitter Configuration\">\n```bash\n# X/Twitter API Configuration\n\n# API Credentials (Required - Twitter API v2)\nTWITTER_API_KEY=your-twitter-api-key                 # API Key\nTWITTER_API_SECRET=your-twitter-api-secret           # API Secret Key\nTWITTER_ACCESS_TOKEN=your-twitter-access-token       # Access Token\nTWITTER_ACCESS_TOKEN_SECRET=your-access-token-secret # Access Token Secret\nTWITTER_BEARER_TOKEN=your-twitter-bearer-token       # Bearer Token\n\n# API Version Settings\nTWITTER_API_VERSION=2                                # API version (1.1 or 2)\nTWITTER_API_BASE_URL=https://api.twitter.com        # API base URL\n\n# Bot Account Information\nTWITTER_BOT_USERNAME=NubiAI                         # Bot account username\nTWITTER_BOT_USER_ID=1234567890123456789             # Bot account user ID\n\n# Rate Limiting (Twitter API limits)\nTWITTER_RATE_LIMIT_TWEETS_PER_HOUR=300              # Max tweets per hour\nTWITTER_RATE_LIMIT_FOLLOWS_PER_DAY=400              # Max follows per day\nTWITTER_RATE_LIMIT_LIKES_PER_HOUR=1000              # Max likes per hour\nTWITTER_RATE_LIMIT_RETWEETS_PER_HOUR=600            # Max retweets per hour\n\n# Content Settings\nTWITTER_MAX_TWEET_LENGTH=280                         # Max tweet length\nTWITTER_ENABLE_THREADS=true                          # Enable thread creation\nTWITTER_ENABLE_MEDIA_UPLOADS=true                    # Enable media uploads\nTWITTER_MAX_MEDIA_SIZE=5242880                       # Max media size (5MB)\n\n# Webhook Configuration (Twitter API Premium/Enterprise)\nTWITTER_WEBHOOK_URL=https://api.anubis.chat/webhooks/twitter\nTWITTER_WEBHOOK_ENVIRONMENT=prod                     # Webhook environment name\nTWITTER_WEBHOOK_SECRET=your-webhook-secret           # Webhook secret\n\n# Search and Monitoring\nTWITTER_MONITOR_KEYWORDS=anubis,nubi,ai              # Keywords to monitor\nTWITTER_MONITOR_HASHTAGS=#AnubisChat,#AI             # Hashtags to monitor\nTWITTER_SENTIMENT_ANALYSIS=true                      # Enable sentiment analysis\n\n# Automation Settings\nTWITTER_AUTO_REPLY=false                             # Auto-reply to mentions\nTWITTER_AUTO_FOLLOW_BACK=false                       # Auto-follow followers\nTWITTER_SPAM_DETECTION=true                          # Enable spam detection\n\n# Content Moderation\nTWITTER_BLOCK_SPAM_ACCOUNTS=true                     # Block spam accounts\nTWITTER_FILTER_INAPPROPRIATE_CONTENT=true           # Filter inappropriate content\nTWITTER_MIN_ACCOUNT_AGE_DAYS=30                     # Min account age for interactions\n\n# Development Settings\nTWITTER_SANDBOX_MODE=false                           # Use sandbox environment\nTWITTER_LOG_API_REQUESTS=false                      # Log API requests\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## AI & External Services\n\n### AI Provider Configuration\n\nSettings for OpenAI, Anthropic, and other AI service integrations:\n\n\u003CTabs>\n  \u003CTabItem label=\"AI Services\">\n```bash\n# AI Provider Configuration\n\n# OpenAI Configuration\nOPENAI_API_KEY=your-openai-api-key-here             # OpenAI API key\nOPENAI_API_BASE_URL=https://api.openai.com/v1      # API base URL\nOPENAI_ORGANIZATION_ID=your-org-id                  # Organization ID (optional)\nOPENAI_DEFAULT_MODEL=gpt-4-turbo-preview           # Default model\nOPENAI_MAX_TOKENS=4096                              # Max tokens per request\nOPENAI_TEMPERATURE=0.7                              # Response creativity (0-1)\nOPENAI_TIMEOUT=30000                                # Request timeout (ms)\n\n# Anthropic (Claude) Configuration\nANTHROPIC_API_KEY=your-anthropic-api-key           # Anthropic API key\nANTHROPIC_API_BASE_URL=https://api.anthropic.com   # API base URL\nANTHROPIC_DEFAULT_MODEL=claude-3-opus-20240229     # Default Claude model\nANTHROPIC_MAX_TOKENS=4096                          # Max tokens per request\nANTHROPIC_TEMPERATURE=0.7                          # Response creativity\nANTHROPIC_TIMEOUT=30000                            # Request timeout (ms)\n\n# AI Feature Configuration\nAI_RESPONSE_CACHING=true                           # Cache AI responses\nAI_RESPONSE_CACHE_TTL=3600                         # Cache TTL (seconds)\nAI_RATE_LIMITING=true                              # Enable AI rate limiting\nAI_MAX_REQUESTS_PER_MINUTE=60                      # Max AI requests per minute\nAI_FALLBACK_MODEL=gpt-3.5-turbo                   # Fallback model if primary fails\n\n# Content Analysis\nAI_CONTENT_MODERATION=true                         # Enable AI content moderation\nAI_SENTIMENT_ANALYSIS=true                         # Enable sentiment analysis\nAI_LANGUAGE_DETECTION=true                         # Enable language detection\nAI_SPAM_DETECTION=true                             # Enable AI spam detection\n\n# Conversation Memory\nAI_CONVERSATION_MEMORY_ENABLED=true               # Enable conversation memory\nAI_CONVERSATION_MEMORY_TTL=86400                  # Memory TTL (24 hours)\nAI_MAX_CONVERSATION_LENGTH=50                     # Max messages in memory\n\n# Cost Management\nAI_MONTHLY_BUDGET_LIMIT=1000                      # Monthly budget limit ($)\nAI_COST_TRACKING=true                             # Track AI costs\nAI_COST_ALERT_THRESHOLD=0.8                      # Alert at 80% of budget\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Analytics & Monitoring\">\n```bash\n# Analytics and Monitoring Configuration\n\n# Sentry Error Tracking\nSENTRY_DSN=your-sentry-dsn-url                     # Sentry DSN for error tracking\nSENTRY_ENVIRONMENT=production                       # Environment name\nSENTRY_RELEASE=nubi@2.0.0                         # Release version\nSENTRY_SAMPLE_RATE=1.0                            # Error sample rate (0-1)\nSENTRY_TRACES_SAMPLE_RATE=0.1                     # Performance sample rate\nSENTRY_DEBUG=false                                 # Enable Sentry debugging\n\n# Google Analytics\nGOOGLE_ANALYTICS_ID=GA-XXXXXXXXX                  # Google Analytics tracking ID\nGOOGLE_ANALYTICS_ENHANCED_ECOMMERCE=false         # Enhanced ecommerce tracking\nGA_MEASUREMENT_ID=G-XXXXXXXXXX                    # GA4 Measurement ID\n\n# Application Performance Monitoring\nAPM_ENABLED=true                                   # Enable APM\nAPM_SERVICE_NAME=nubi                              # Service name for APM\nAPM_ENVIRONMENT=production                         # Environment name\nAPM_SERVER_URL=https://apm.company.com            # APM server URL\nAPM_SECRET_TOKEN=your-apm-secret                   # APM secret token\n\n# Metrics Collection\nMETRICS_ENABLED=true                               # Enable metrics collection\nMETRICS_PORT=9090                                  # Metrics endpoint port\nMETRICS_PATH=/metrics                              # Metrics endpoint path\nMETRICS_INTERVAL=30000                             # Metrics collection interval (ms)\n\n# Logging Services\nLOG_SHIPPING_ENABLED=false                         # Ship logs to external service\nLOG_SHIPPING_ENDPOINT=https://logs.company.com     # Log shipping endpoint\nLOG_SHIPPING_API_KEY=your-log-shipping-key         # API key for log service\n\n# Health Monitoring\nHEALTH_CHECK_ENABLED=true                          # Enable health checks\nHEALTH_CHECK_PATH=/health                          # Health check endpoint\nUPTIME_MONITORING_URL=https://monitor.company.com  # Uptime monitoring webhook\nUPTIME_CHECK_INTERVAL=60000                        # Uptime check interval (ms)\n\n# Performance Monitoring\nPERFORMANCE_MONITORING=true                        # Monitor performance metrics\nSLOW_REQUEST_THRESHOLD=5000                        # Log requests slower than N ms\nMEMORY_USAGE_ALERT_THRESHOLD=0.9                  # Alert at 90% memory usage\nCPU_USAGE_ALERT_THRESHOLD=0.8                     # Alert at 80% CPU usage\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Email & Notifications\">\n```bash\n# Email Configuration\n\n# SMTP Settings\nSMTP_HOST=smtp.gmail.com                           # SMTP server hostname\nSMTP_PORT=587                                      # SMTP port (587 for TLS, 465 for SSL)\nSMTP_SECURE=true                                   # Use TLS/SSL\nSMTP_USER=noreply@anubis.chat                     # SMTP username\nSMTP_PASS=your-app-password                       # SMTP password/app password\nSMTP_FROM=NUBI \u003Cnoreply@anubis.chat>              # From address\n\n# Email Templates\nEMAIL_TEMPLATE_DIR=./templates/email               # Email template directory\nEMAIL_TEMPLATE_ENGINE=handlebars                   # Template engine\n\n# Email Features\nEMAIL_VERIFICATION_ENABLED=true                    # Enable email verification\nEMAIL_VERIFICATION_TTL=86400                       # Verification link TTL (24 hours)\nPASSWORD_RESET_ENABLED=true                        # Enable password reset emails\nPASSWORD_RESET_TTL=3600                           # Reset link TTL (1 hour)\n\n# Notification Settings\nNOTIFICATIONS_ENABLED=true                         # Enable notifications\nNOTIFICATION_CHANNELS=email,telegram               # Notification channels\nDAILY_DIGEST_ENABLED=true                         # Send daily digest emails\nDAILY_DIGEST_TIME=09:00                           # Daily digest send time\nWEEKLY_REPORT_ENABLED=true                        # Send weekly reports\nWEEKLY_REPORT_DAY=monday                          # Weekly report day\n\n# Push Notifications (if using web push)\nPUSH_NOTIFICATIONS_ENABLED=false                   # Enable push notifications\nVAPID_PUBLIC_KEY=your-vapid-public-key             # VAPID public key\nVAPID_PRIVATE_KEY=your-vapid-private-key           # VAPID private key\nVAPID_SUBJECT=mailto:admin@anubis.chat             # VAPID subject\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Security & Performance\n\n### Security Configuration\n\nCritical security settings for production deployments:\n\n\u003CTabs>\n  \u003CTabItem label=\"Security Settings\">\n```bash\n# Security Configuration\n\n# CORS (Cross-Origin Resource Sharing)\nCORS_ORIGIN=https://anubis.chat,https://app.anubis.chat # Allowed origins\nCORS_METHODS=GET,POST,PUT,DELETE,OPTIONS              # Allowed methods\nCORS_HEADERS=Content-Type,Authorization,X-API-Key     # Allowed headers\nCORS_CREDENTIALS=true                                  # Allow credentials\nCORS_MAX_AGE=86400                                    # Preflight cache duration\n\n# Rate Limiting\nRATE_LIMIT_ENABLED=true                               # Enable rate limiting\nRATE_LIMIT_WINDOW_MS=900000                          # Rate limit window (15 minutes)\nRATE_LIMIT_MAX_REQUESTS=100                          # Max requests per window\nRATE_LIMIT_SKIP_SUCCESS_RESPONSES=false              # Skip successful responses\nRATE_LIMIT_HEADERS=true                              # Send rate limit headers\n\n# API Rate Limiting\nAPI_RATE_LIMIT_ENABLED=true                          # Enable API rate limiting\nAPI_RATE_LIMIT_REQUESTS_PER_MINUTE=60               # API requests per minute\nAPI_RATE_LIMIT_BURST=10                             # Burst allowance\n\n# Content Security Policy\nCSP_ENABLED=true                                     # Enable CSP headers\nCSP_REPORT_ONLY=false                               # Report-only mode\nCSP_REPORT_URI=/csp-report                          # CSP report endpoint\n\n# SSL/TLS Configuration\nSSL_REDIRECT=true                                    # Redirect HTTP to HTTPS\nSSL_HSTS_ENABLED=true                               # Enable HSTS headers\nSSL_HSTS_MAX_AGE=31536000                          # HSTS max age (1 year)\nSSL_HSTS_INCLUDE_SUBDOMAINS=true                   # Include subdomains in HSTS\nSSL_HSTS_PRELOAD=true                              # Include in HSTS preload list\n\n# Security Headers\nSECURITY_HEADERS_ENABLED=true                        # Enable security headers\nX_FRAME_OPTIONS=DENY                                # X-Frame-Options header\nX_CONTENT_TYPE_OPTIONS=nosniff                      # X-Content-Type-Options header\nX_XSS_PROTECTION=1; mode=block                      # X-XSS-Protection header\nREFERRER_POLICY=strict-origin-when-cross-origin     # Referrer-Policy header\n\n# Input Validation\nINPUT_VALIDATION_ENABLED=true                       # Enable input validation\nMAX_REQUEST_SIZE=10mb                               # Max request body size\nMAX_URL_LENGTH=2048                                 # Max URL length\nMAX_PARAMETER_COUNT=100                             # Max query parameters\n\n# File Upload Security\nFILE_UPLOAD_ENABLED=true                            # Enable file uploads\nFILE_UPLOAD_MAX_SIZE=5242880                        # Max file size (5MB)\nFILE_UPLOAD_ALLOWED_TYPES=image/jpeg,image/png,image/gif # Allowed MIME types\nFILE_UPLOAD_SCAN_VIRUS=false                        # Enable virus scanning\nFILE_UPLOAD_PATH=./uploads                          # Upload directory\n\n# Authentication Security\nAUTH_LOCKOUT_ENABLED=true                           # Enable account lockout\nAUTH_MAX_LOGIN_ATTEMPTS=5                           # Max failed login attempts\nAUTH_LOCKOUT_DURATION=900000                        # Lockout duration (15 minutes)\nAUTH_PASSWORD_POLICY_ENABLED=true                   # Enable password policy\nAUTH_REQUIRE_STRONG_PASSWORDS=true                  # Require strong passwords\nAUTH_2FA_ENABLED=false                              # Enable 2FA (future feature)\n\n# Data Protection\nDATA_ENCRYPTION_AT_REST=false                       # Encrypt sensitive data at rest\nDATA_ENCRYPTION_KEY=your-data-encryption-key        # Data encryption key\nDATA_RETENTION_DAYS=365                             # Data retention period\nDATA_ANONYMIZATION_ENABLED=false                    # Enable data anonymization\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Performance Settings\">\n```bash\n# Performance Configuration\n\n# HTTP Server Performance\nHTTP_KEEP_ALIVE=true                                # Enable keep-alive connections\nHTTP_KEEP_ALIVE_TIMEOUT=65000                      # Keep-alive timeout (ms)\nHTTP_HEADERS_TIMEOUT=66000                         # Headers timeout (ms)\nHTTP_MAX_HEADER_SIZE=16384                         # Max header size (16KB)\nHTTP_REQUEST_TIMEOUT=120000                        # Request timeout (2 minutes)\n\n# Connection Limits\nHTTP_MAX_SOCKETS=Infinity                          # Max sockets per host\nHTTP_MAX_TOTAL_SOCKETS=Infinity                    # Max total sockets\nHTTP_MAX_FREE_SOCKETS=256                          # Max free sockets\n\n# WebSocket Performance\nWEBSOCKET_ENABLED=true                             # Enable WebSocket server\nWEBSOCKET_MAX_CONNECTIONS=10000                    # Max concurrent connections\nWEBSOCKET_PING_INTERVAL=25000                      # Ping interval (ms)\nWEBSOCKET_PING_TIMEOUT=60000                       # Ping timeout (ms)\nWEBSOCKET_UPGRADE_TIMEOUT=10000                    # Upgrade timeout (ms)\nWEBSOCKET_COMPRESS=true                            # Enable per-message deflate\nWEBSOCKET_MAX_PAYLOAD=1048576                      # Max message size (1MB)\n\n# Caching Configuration\nCACHE_ENABLED=true                                 # Enable application caching\nCACHE_DEFAULT_TTL=300                             # Default cache TTL (5 minutes)\nCACHE_MAX_KEYS=10000                              # Max cache keys\nCACHE_CHECK_PERIOD=600                            # Cache cleanup period (10 minutes)\n\n# Static File Serving\nSTATIC_FILES_ENABLED=true                         # Serve static files\nSTATIC_FILES_PATH=./public                        # Static files directory\nSTATIC_FILES_MAX_AGE=604800                       # Static files cache age (7 days)\nSTATIC_FILES_ETAG=true                            # Enable ETags\nSTATIC_FILES_GZIP=true                            # Enable gzip compression\n\n# Compression\nCOMPRESSION_ENABLED=true                           # Enable response compression\nCOMPRESSION_LEVEL=6                               # Compression level (1-9)\nCOMPRESSION_THRESHOLD=1024                        # Min bytes to compress\nCOMPRESSION_MIME_TYPES=text/*,application/json    # MIME types to compress\n\n# Background Jobs\nQUEUE_ENABLED=true                                # Enable background job queue\nQUEUE_CONCURRENCY=10                              # Max concurrent jobs\nQUEUE_MAX_STALLED_COUNT=5                         # Max stalled jobs before fail\nQUEUE_MAX_STALLED_INTERVAL=30000                  # Stalled job check interval\nQUEUE_RETRY_ATTEMPTS=3                            # Default retry attempts\nQUEUE_RETRY_DELAY=5000                            # Retry delay (ms)\nQUEUE_REMOVE_ON_COMPLETE=100                      # Keep N completed jobs\nQUEUE_REMOVE_ON_FAIL=50                           # Keep N failed jobs\n\n# Memory Management\nMEMORY_LIMIT_ENABLED=false                        # Enable memory limiting\nMEMORY_LIMIT_MB=2048                              # Memory limit (MB)\nMEMORY_CHECK_INTERVAL=60000                       # Memory check interval (ms)\nMEMORY_GC_ENABLED=true                            # Enable garbage collection\nMEMORY_GC_INTERVAL=300000                         # GC interval (5 minutes)\n\n# CPU Management\nCPU_PROFILING_ENABLED=false                       # Enable CPU profiling\nCPU_USAGE_MONITORING=true                         # Monitor CPU usage\nCPU_USAGE_ALERT_THRESHOLD=80                      # CPU usage alert threshold (%)\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Environment-Specific Configurations\n\n### Development Environment\n\n\u003CTabs>\n  \u003CTabItem label=\"Development (.env.development)\">\n```bash\n# Development Environment Configuration\n\n# Basic Settings\nNODE_ENV=development\nAPP_URL=http://localhost:3000\nAPI_URL=http://localhost:3000\nWEBSOCKET_URL=ws://localhost:3000\n\n# Database (Local PostgreSQL)\nDATABASE_URL=postgresql://nubi:dev_password@localhost:5432/nubi_development\n\n# PGLite (Alternative for development)\nPGLITE_DATA_DIR=./.eliza/.elizadb\nUSE_PGLITE=true\n\n# Redis (Local)\nREDIS_URL=redis://localhost:6379/0\n\n# Security (Relaxed for development)\nJWT_SECRET=dev-secret-not-for-production-use-only\nSESSION_SECRET=dev-session-secret-not-secure\n\n# CORS (Allow all origins in development)\nCORS_ORIGIN=*\n\n# Rate Limiting (Disabled in development)\nRATE_LIMIT_ENABLED=false\n\n# Logging (Verbose in development)\nLOG_LEVEL=debug\nLOG_FORMAT=pretty\n\n# Hot Reloading\nHOT_RELOAD=true\nWATCH_FILES=true\n\n# Development Tools\nDEBUG_MODE=true\nPROFILER_ENABLED=true\nQUERY_LOGGING=true\n\n# Test Platform Credentials (Use test tokens)\nTELEGRAM_BOT_TOKEN=your-test-bot-token\nDISCORD_BOT_TOKEN=your-test-discord-token\n\n# Disable External Services in Development\nEMAIL_ENABLED=false\nSENTRY_ENABLED=false\nANALYTICS_ENABLED=false\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Staging (.env.staging)\">\n```bash\n# Staging Environment Configuration\n\n# Basic Settings\nNODE_ENV=staging\nAPP_URL=https://staging.anubis.chat\nAPI_URL=https://api-staging.anubis.chat\nWEBSOCKET_URL=wss://api-staging.anubis.chat\n\n# Database (Staging instance)\nDATABASE_URL=postgresql://nubi_staging:secure_pass@staging-db:5432/nubi_staging\nDATABASE_SSL=true\n\n# Redis (Staging instance)\nREDIS_URL=redis://staging-redis:6379/0\nREDIS_TLS=true\n\n# Security (Production-like security)\nJWT_SECRET=staging-jwt-secret-64-characters-minimum-secure-random-string\nSESSION_SECRET=staging-session-secret-for-cookie-security-random-string\n\n# CORS (Specific origins)\nCORS_ORIGIN=https://staging.anubis.chat\n\n# Rate Limiting (Enabled but relaxed)\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_MAX_REQUESTS=200\n\n# Logging (Info level)\nLOG_LEVEL=info\nLOG_FORMAT=json\n\n# Staging Platform Credentials\nTELEGRAM_BOT_TOKEN=staging-telegram-bot-token\nDISCORD_BOT_TOKEN=staging-discord-bot-token\nTWITTER_API_KEY=staging-twitter-api-key\n\n# Monitoring (Enable but separate from production)\nSENTRY_DSN=https://staging-sentry-dsn\nSENTRY_ENVIRONMENT=staging\n\n# Email (Use staging SMTP)\nSMTP_HOST=smtp-staging.company.com\nSMTP_USER=noreply-staging@anubis.chat\n\n# Feature Flags (Test new features)\nENABLE_EXPERIMENTAL_FEATURES=true\nBETA_FEATURES=true\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Production (.env.production)\">\n```bash\n# Production Environment Configuration\n\n# Basic Settings\nNODE_ENV=production\nAPP_URL=https://anubis.chat\nAPI_URL=https://api.anubis.chat\nWEBSOCKET_URL=wss://api.anubis.chat\n\n# Database (Production cluster)\nDATABASE_URL=postgresql://nubi_prod:ultra_secure_password@prod-db-cluster:5432/nubi_production?sslmode=require\nDATABASE_SSL=true\nDATABASE_SSL_REJECT_UNAUTHORIZED=true\nDATABASE_POOL_MIN=10\nDATABASE_POOL_MAX=50\n\n# Redis (Production cluster)\nREDIS_URL=rediss://prod-redis-cluster:6380/0\nREDIS_CLUSTER_MODE=true\nREDIS_TLS=true\n\n# Security (Maximum security)\nJWT_SECRET=production-jwt-secret-ultra-secure-64-character-minimum-random-key\nSESSION_SECRET=production-session-secret-ultra-secure-random-key-for-cookies\nBCRYPT_ROUNDS=12\n\n# CORS (Strict origins)\nCORS_ORIGIN=https://anubis.chat,https://app.anubis.chat\n\n# Rate Limiting (Strict)\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_MAX_REQUESTS=100\nAPI_RATE_LIMIT_REQUESTS_PER_MINUTE=60\n\n# Logging (Optimized for production)\nLOG_LEVEL=info\nLOG_FORMAT=json\n\n# SSL/Security Headers\nSSL_REDIRECT=true\nSSL_HSTS_ENABLED=true\nSECURITY_HEADERS_ENABLED=true\n\n# Production Platform Credentials\nTELEGRAM_BOT_TOKEN=production-telegram-bot-token\nDISCORD_BOT_TOKEN=production-discord-bot-token\nTWITTER_API_KEY=production-twitter-api-key\n\n# Monitoring (Full monitoring)\nSENTRY_DSN=https://production-sentry-dsn\nSENTRY_ENVIRONMENT=production\nGOOGLE_ANALYTICS_ID=GA-PRODUCTION-ID\n\n# Email (Production SMTP)\nSMTP_HOST=smtp.sendgrid.net\nSMTP_USER=apikey\nSMTP_FROM=NUBI \u003Cnoreply@anubis.chat>\n\n# Performance (Optimized)\nCLUSTER_WORKERS=auto\nCOMPRESSION_ENABLED=true\nCACHE_ENABLED=true\nQUEUE_CONCURRENCY=20\n\n# Feature Flags (Stable features only)\nENABLE_EXPERIMENTAL_FEATURES=false\nBETA_FEATURES=false\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Environment Validation\n\n### Configuration Validation Script\n\nScript to validate environment configuration before startup:\n\n```bash\n#!/bin/bash\n# scripts/validate-env.sh\n\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[VALIDATE] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[ERROR] $1${NC}\"\n    exit 1\n}\n\n# Load environment file\nENV_FILE=${ENV_FILE:-.env}\nif [[ -f \"$ENV_FILE\" ]]; then\n    log \"Loading environment from $ENV_FILE\"\n    source \"$ENV_FILE\"\nelse\n    warn \"Environment file $ENV_FILE not found, using system environment\"\nfi\n\n# Required variables check\ncheck_required() {\n    local var_name=$1\n    local var_value=${!var_name}\n    \n    if [[ -z \"$var_value\" ]]; then\n        error \"Required environment variable $var_name is not set\"\n    else\n        log \"✓ $var_name is set\"\n    fi\n}\n\n# URL validation\nvalidate_url() {\n    local var_name=$1\n    local url=${!var_name}\n    \n    if [[ ! \"$url\" =~ ^https?:// ]]; then\n        error \"$var_name must be a valid URL starting with http:// or https://\"\n    else\n        log \"✓ $var_name is a valid URL\"\n    fi\n}\n\n# Database connection check\ncheck_database() {\n    log \"Checking database connection...\"\n    \n    if [[ -z \"$DATABASE_URL\" ]]; then\n        error \"DATABASE_URL is required\"\n    fi\n    \n    # Test database connection\n    if command -v psql &> /dev/null; then\n        if psql \"$DATABASE_URL\" -c \"SELECT 1;\" &> /dev/null; then\n            log \"✓ Database connection successful\"\n        else\n            error \"✗ Database connection failed\"\n        fi\n    else\n        warn \"psql not found, skipping database connection test\"\n    fi\n}\n\n# Redis connection check\ncheck_redis() {\n    log \"Checking Redis connection...\"\n    \n    if [[ -z \"$REDIS_URL\" ]]; then\n        error \"REDIS_URL is required\"\n    fi\n    \n    # Test Redis connection\n    if command -v redis-cli &> /dev/null; then\n        local redis_host=$(echo \"$REDIS_URL\" | sed -n 's/.*\\/\\/\\([^:@]*\\):.*/\\1/p')\n        local redis_port=$(echo \"$REDIS_URL\" | sed -n 's/.*:\\([0-9]*\\).*/\\1/p')\n        \n        if redis-cli -h \"$redis_host\" -p \"$redis_port\" ping &> /dev/null; then\n            log \"✓ Redis connection successful\"\n        else\n            error \"✗ Redis connection failed\"\n        fi\n    else\n        warn \"redis-cli not found, skipping Redis connection test\"\n    fi\n}\n\n# Security validation\nvalidate_security() {\n    log \"Validating security configuration...\"\n    \n    # JWT Secret validation\n    if [[ ${#JWT_SECRET} -lt 64 ]]; then\n        error \"JWT_SECRET must be at least 64 characters long\"\n    else\n        log \"✓ JWT_SECRET length is adequate\"\n    fi\n    \n    # Session Secret validation\n    if [[ ${#SESSION_SECRET} -lt 32 ]]; then\n        error \"SESSION_SECRET must be at least 32 characters long\"\n    else\n        log \"✓ SESSION_SECRET length is adequate\"\n    fi\n    \n    # Production security checks\n    if [[ \"$NODE_ENV\" == \"production\" ]]; then\n        if [[ \"$JWT_SECRET\" == *\"dev\"* ]] || [[ \"$JWT_SECRET\" == *\"test\"* ]]; then\n            error \"Production JWT_SECRET should not contain 'dev' or 'test'\"\n        fi\n        \n        if [[ \"$CORS_ORIGIN\" == \"*\" ]]; then\n            error \"CORS_ORIGIN should not be '*' in production\"\n        fi\n        \n        if [[ \"$SSL_REDIRECT\" != \"true\" ]]; then\n            warn \"SSL_REDIRECT should be enabled in production\"\n        fi\n    fi\n}\n\n# Main validation\nmain() {\n    log \"Starting environment validation for NODE_ENV=${NODE_ENV:-development}\"\n    \n    # Check required variables\n    check_required NODE_ENV\n    check_required PORT\n    check_required DATABASE_URL\n    check_required REDIS_URL\n    check_required JWT_SECRET\n    check_required SESSION_SECRET\n    \n    # Validate URLs\n    if [[ -n \"$APP_URL\" ]]; then\n        validate_url APP_URL\n    fi\n    if [[ -n \"$API_URL\" ]]; then\n        validate_url API_URL\n    fi\n    \n    # Check service connections\n    check_database\n    check_redis\n    \n    # Validate security\n    validate_security\n    \n    log \"Environment validation completed successfully!\"\n}\n\nmain \"$@\"\n```\n\nThis comprehensive environment variables reference ensures your NUBI deployment is properly configured for any environment, from local development to enterprise production setups.","src/content/docs/deployment/environment-variables.mdx","41b53306d81da0d7","deployment/environment-variables.mdx","deployment/monitoring",{"id":297,"data":299,"body":306,"filePath":307,"digest":308,"legacyId":309,"deferredRender":16},{"title":300,"description":301,"editUrl":16,"head":302,"template":47,"sidebar":303,"pagefind":16,"draft":35},"Monitoring & Observability","Complete monitoring, logging, and observability setup for NUBI production deployments with metrics, alerts, and dashboards",[],{"order":304,"hidden":35,"attrs":305},4,{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\nComprehensive monitoring and observability setup ensures your NUBI deployment maintains optimal performance, reliability, and user experience at scale.\n\n## Observability Stack\n\n### Core Monitoring Architecture\n\nNUBI's monitoring system uses industry-standard tools for complete observability:\n\n```mermaid\ngraph TB\n    subgraph \"Application Layer\"\n        NUBI[NUBI Application]\n        WORKER[Background Workers]\n        DB[(PostgreSQL)]\n        REDIS[(Redis)]\n    end\n    \n    subgraph \"Metrics Collection\"\n        PROM[Prometheus]\n        NODE[Node Exporter]\n        POSTGRES[PostgreSQL Exporter]\n        REDIS_EXP[Redis Exporter]\n    end\n    \n    subgraph \"Logging Stack\"\n        LOKI[Loki]\n        PROMTAIL[Promtail]\n        GRAFANA[Grafana]\n    end\n    \n    subgraph \"Tracing\"\n        JAEGER[Jaeger]\n        OTEL[OpenTelemetry]\n    end\n    \n    subgraph \"Alerting\"\n        AM[Alertmanager]\n        SLACK[Slack]\n        EMAIL[Email]\n        PD[PagerDuty]\n    end\n    \n    NUBI --> PROM\n    WORKER --> PROM\n    DB --> POSTGRES\n    REDIS --> REDIS_EXP\n    \n    NUBI --> OTEL\n    OTEL --> JAEGER\n    \n    NUBI --> PROMTAIL\n    PROMTAIL --> LOKI\n    \n    PROM --> AM\n    AM --> SLACK\n    AM --> EMAIL\n    AM --> PD\n    \n    LOKI --> GRAFANA\n    PROM --> GRAFANA\n    JAEGER --> GRAFANA\n```\n\n\u003CTabs>\n  \u003CTabItem label=\"Docker Compose Monitoring\">\n```yaml\n# docker-compose.monitoring.yml\nversion: '3.8'\n\nservices:\n  # Prometheus for metrics collection\n  prometheus:\n    image: prom/prometheus:latest\n    container_name: nubi-prometheus\n    restart: unless-stopped\n    \n    ports:\n      - \"9090:9090\"\n    \n    volumes:\n      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - ./monitoring/prometheus/rules:/etc/prometheus/rules:ro\n      - prometheus_data:/prometheus\n    \n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--storage.tsdb.retention.time=30d'\n      - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n      - '--web.console.templates=/usr/share/prometheus/consoles'\n      - '--web.enable-lifecycle'\n      - '--web.enable-admin-api'\n      - '--log.level=info'\n    \n    networks:\n      - nubi-monitoring\n\n  # Grafana for visualization\n  grafana:\n    image: grafana/grafana:latest\n    container_name: nubi-grafana\n    restart: unless-stopped\n    \n    ports:\n      - \"3001:3000\"\n    \n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}\n      - GF_INSTALL_PLUGINS=redis-datasource,postgres-datasource\n    \n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro\n      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro\n    \n    networks:\n      - nubi-monitoring\n\n  # Loki for log aggregation\n  loki:\n    image: grafana/loki:latest\n    container_name: nubi-loki\n    restart: unless-stopped\n    \n    ports:\n      - \"3100:3100\"\n    \n    volumes:\n      - ./monitoring/loki/loki.yml:/etc/loki/local-config.yaml:ro\n      - loki_data:/loki\n    \n    command: -config.file=/etc/loki/local-config.yaml\n    \n    networks:\n      - nubi-monitoring\n\n  # Promtail for log shipping\n  promtail:\n    image: grafana/promtail:latest\n    container_name: nubi-promtail\n    restart: unless-stopped\n    \n    volumes:\n      - ./monitoring/promtail/promtail.yml:/etc/promtail/config.yml:ro\n      - ./logs:/var/log/nubi:ro\n      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n    \n    command: -config.file=/etc/promtail/config.yml\n    \n    networks:\n      - nubi-monitoring\n\n  # Alertmanager for alerting\n  alertmanager:\n    image: prom/alertmanager:latest\n    container_name: nubi-alertmanager\n    restart: unless-stopped\n    \n    ports:\n      - \"9093:9093\"\n    \n    volumes:\n      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro\n      - alertmanager_data:/alertmanager\n    \n    networks:\n      - nubi-monitoring\n\n  # Node Exporter for system metrics\n  node-exporter:\n    image: prom/node-exporter:latest\n    container_name: nubi-node-exporter\n    restart: unless-stopped\n    \n    ports:\n      - \"9100:9100\"\n    \n    volumes:\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n      - /:/rootfs:ro\n    \n    command:\n      - '--path.procfs=/host/proc'\n      - '--path.rootfs=/rootfs'\n      - '--path.sysfs=/host/sys'\n      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'\n    \n    networks:\n      - nubi-monitoring\n\n  # PostgreSQL Exporter\n  postgres-exporter:\n    image: prometheuscommunity/postgres-exporter:latest\n    container_name: nubi-postgres-exporter\n    restart: unless-stopped\n    \n    ports:\n      - \"9187:9187\"\n    \n    environment:\n      DATA_SOURCE_NAME: ${DATABASE_URL}\n    \n    networks:\n      - nubi-monitoring\n\n  # Redis Exporter\n  redis-exporter:\n    image: oliver006/redis_exporter:latest\n    container_name: nubi-redis-exporter\n    restart: unless-stopped\n    \n    ports:\n      - \"9121:9121\"\n    \n    environment:\n      REDIS_ADDR: redis://redis:6379\n    \n    networks:\n      - nubi-monitoring\n\n  # Jaeger for distributed tracing\n  jaeger:\n    image: jaegertracing/all-in-one:latest\n    container_name: nubi-jaeger\n    restart: unless-stopped\n    \n    ports:\n      - \"16686:16686\"\n      - \"14268:14268\"\n    \n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n    \n    networks:\n      - nubi-monitoring\n\nvolumes:\n  prometheus_data:\n  grafana_data:\n  loki_data:\n  alertmanager_data:\n\nnetworks:\n  nubi-monitoring:\n    driver: bridge\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Kubernetes Monitoring\">\n```yaml\n# k8s/monitoring/namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: nubi-monitoring\n\n---\n# k8s/monitoring/prometheus.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prometheus\n  namespace: nubi-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prometheus\n  template:\n    metadata:\n      labels:\n        app: prometheus\n    spec:\n      containers:\n      - name: prometheus\n        image: prom/prometheus:latest\n        ports:\n        - containerPort: 9090\n        volumeMounts:\n        - name: prometheus-config\n          mountPath: /etc/prometheus\n        - name: prometheus-storage\n          mountPath: /prometheus\n        args:\n          - '--config.file=/etc/prometheus/prometheus.yml'\n          - '--storage.tsdb.path=/prometheus'\n          - '--storage.tsdb.retention.time=30d'\n          - '--web.enable-lifecycle'\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n      volumes:\n      - name: prometheus-config\n        configMap:\n          name: prometheus-config\n      - name: prometheus-storage\n        persistentVolumeClaim:\n          claimName: prometheus-pvc\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: prometheus-service\n  namespace: nubi-monitoring\nspec:\n  selector:\n    app: prometheus\n  ports:\n  - port: 9090\n    targetPort: 9090\n  type: ClusterIP\n\n---\n# k8s/monitoring/grafana.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: nubi-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:latest\n        ports:\n        - containerPort: 3000\n        env:\n        - name: GF_SECURITY_ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: grafana-secret\n              key: admin-password\n        volumeMounts:\n        - name: grafana-storage\n          mountPath: /var/lib/grafana\n        - name: grafana-config\n          mountPath: /etc/grafana/provisioning\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: grafana-pvc\n      - name: grafana-config\n        configMap:\n          name: grafana-config\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: grafana-service\n  namespace: nubi-monitoring\nspec:\n  selector:\n    app: grafana\n  ports:\n  - port: 3000\n    targetPort: 3000\n  type: LoadBalancer\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Application Metrics\n\n### Custom Metrics Implementation\n\nNUBI exposes comprehensive application metrics for monitoring business and technical KPIs:\n\n\u003CTabs>\n  \u003CTabItem label=\"Metrics Collector\">\n```typescript\n// src/monitoring/metrics-collector.ts\nimport { Registry, Counter, Histogram, Gauge } from 'prom-client'\nimport { logger } from '@elizaos/core'\n\nclass NubiMetricsCollector {\n  private registry: Registry\n  private metrics: Map\u003Cstring, any> = new Map()\n  \n  constructor() {\n    this.registry = new Registry()\n    this.initializeMetrics()\n  }\n  \n  private initializeMetrics(): void {\n    // HTTP Request Metrics\n    this.metrics.set('http_requests_total', new Counter({\n      name: 'nubi_http_requests_total',\n      help: 'Total number of HTTP requests',\n      labelNames: ['method', 'route', 'status_code'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('http_request_duration', new Histogram({\n      name: 'nubi_http_request_duration_seconds',\n      help: 'HTTP request duration in seconds',\n      labelNames: ['method', 'route'],\n      buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5],\n      registers: [this.registry]\n    }))\n    \n    // Raid Metrics\n    this.metrics.set('raids_total', new Counter({\n      name: 'nubi_raids_total',\n      help: 'Total number of raids',\n      labelNames: ['status', 'platform'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('raid_participants', new Histogram({\n      name: 'nubi_raid_participants',\n      help: 'Number of participants per raid',\n      labelNames: ['platform'],\n      buckets: [1, 5, 10, 25, 50, 100, 200, 500],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('raid_duration', new Histogram({\n      name: 'nubi_raid_duration_seconds',\n      help: 'Raid duration in seconds',\n      labelNames: ['platform'],\n      buckets: [60, 300, 600, 1800, 3600, 7200],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('raid_effectiveness', new Histogram({\n      name: 'nubi_raid_effectiveness_score',\n      help: 'Raid effectiveness score (0-1)',\n      buckets: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n      registers: [this.registry]\n    }))\n    \n    // User Engagement Metrics\n    this.metrics.set('active_users', new Gauge({\n      name: 'nubi_active_users',\n      help: 'Number of active users',\n      labelNames: ['timeframe'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('user_actions_total', new Counter({\n      name: 'nubi_user_actions_total',\n      help: 'Total user actions',\n      labelNames: ['action_type', 'platform'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('engagement_quality', new Histogram({\n      name: 'nubi_engagement_quality_score',\n      help: 'Engagement quality score (0-1)',\n      labelNames: ['platform'],\n      buckets: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n      registers: [this.registry]\n    }))\n    \n    // WebSocket Metrics\n    this.metrics.set('websocket_connections', new Gauge({\n      name: 'nubi_websocket_connections',\n      help: 'Current WebSocket connections',\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('websocket_messages_total', new Counter({\n      name: 'nubi_websocket_messages_total',\n      help: 'Total WebSocket messages',\n      labelNames: ['direction', 'event_type'],\n      registers: [this.registry]\n    }))\n    \n    // Database Metrics\n    this.metrics.set('database_queries_total', new Counter({\n      name: 'nubi_database_queries_total',\n      help: 'Total database queries',\n      labelNames: ['operation', 'table'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('database_query_duration', new Histogram({\n      name: 'nubi_database_query_duration_seconds',\n      help: 'Database query duration',\n      labelNames: ['operation', 'table'],\n      buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('database_pool_size', new Gauge({\n      name: 'nubi_database_pool_size',\n      help: 'Database connection pool size',\n      labelNames: ['state'],\n      registers: [this.registry]\n    }))\n    \n    // Cache Metrics\n    this.metrics.set('cache_operations_total', new Counter({\n      name: 'nubi_cache_operations_total',\n      help: 'Total cache operations',\n      labelNames: ['operation', 'result'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('cache_hit_ratio', new Gauge({\n      name: 'nubi_cache_hit_ratio',\n      help: 'Cache hit ratio',\n      labelNames: ['cache_type'],\n      registers: [this.registry]\n    }))\n    \n    // AI Service Metrics\n    this.metrics.set('ai_requests_total', new Counter({\n      name: 'nubi_ai_requests_total',\n      help: 'Total AI service requests',\n      labelNames: ['provider', 'model', 'status'],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('ai_request_duration', new Histogram({\n      name: 'nubi_ai_request_duration_seconds',\n      help: 'AI request duration',\n      labelNames: ['provider', 'model'],\n      buckets: [0.1, 0.5, 1, 2, 5, 10, 20, 30],\n      registers: [this.registry]\n    }))\n    \n    this.metrics.set('ai_token_usage', new Counter({\n      name: 'nubi_ai_token_usage_total',\n      help: 'Total AI tokens used',\n      labelNames: ['provider', 'model', 'type'],\n      registers: [this.registry]\n    }))\n  }\n  \n  // Metric recording methods\n  recordHttpRequest(method: string, route: string, statusCode: number, duration: number): void {\n    this.metrics.get('http_requests_total').inc({ method, route, status_code: statusCode })\n    this.metrics.get('http_request_duration').observe({ method, route }, duration)\n  }\n  \n  recordRaidCreated(platform: string, participants: number): void {\n    this.metrics.get('raids_total').inc({ status: 'created', platform })\n    this.metrics.get('raid_participants').observe({ platform }, participants)\n  }\n  \n  recordRaidCompleted(platform: string, duration: number, effectiveness: number): void {\n    this.metrics.get('raids_total').inc({ status: 'completed', platform })\n    this.metrics.get('raid_duration').observe({ platform }, duration)\n    this.metrics.get('raid_effectiveness').observe({}, effectiveness)\n  }\n  \n  updateActiveUsers(timeframe: string, count: number): void {\n    this.metrics.get('active_users').set({ timeframe }, count)\n  }\n  \n  recordUserAction(actionType: string, platform: string): void {\n    this.metrics.get('user_actions_total').inc({ action_type: actionType, platform })\n  }\n  \n  recordEngagementQuality(platform: string, quality: number): void {\n    this.metrics.get('engagement_quality').observe({ platform }, quality)\n  }\n  \n  updateWebSocketConnections(count: number): void {\n    this.metrics.get('websocket_connections').set(count)\n  }\n  \n  recordWebSocketMessage(direction: 'in' | 'out', eventType: string): void {\n    this.metrics.get('websocket_messages_total').inc({ direction, event_type: eventType })\n  }\n  \n  recordDatabaseQuery(operation: string, table: string, duration: number): void {\n    this.metrics.get('database_queries_total').inc({ operation, table })\n    this.metrics.get('database_query_duration').observe({ operation, table }, duration)\n  }\n  \n  updateDatabasePoolSize(available: number, used: number, idle: number): void {\n    this.metrics.get('database_pool_size').set({ state: 'available' }, available)\n    this.metrics.get('database_pool_size').set({ state: 'used' }, used)\n    this.metrics.get('database_pool_size').set({ state: 'idle' }, idle)\n  }\n  \n  recordCacheOperation(operation: string, result: 'hit' | 'miss'): void {\n    this.metrics.get('cache_operations_total').inc({ operation, result })\n  }\n  \n  updateCacheHitRatio(cacheType: string, ratio: number): void {\n    this.metrics.get('cache_hit_ratio').set({ cache_type: cacheType }, ratio)\n  }\n  \n  recordAIRequest(provider: string, model: string, status: string, duration: number, tokens: number): void {\n    this.metrics.get('ai_requests_total').inc({ provider, model, status })\n    this.metrics.get('ai_request_duration').observe({ provider, model }, duration)\n    this.metrics.get('ai_token_usage').inc({ provider, model, type: 'total' }, tokens)\n  }\n  \n  getMetrics(): Promise\u003Cstring> {\n    return this.registry.metrics()\n  }\n  \n  getRegistry(): Registry {\n    return this.registry\n  }\n}\n\nexport const metricsCollector = new NubiMetricsCollector()\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Metrics Middleware\">\n```typescript\n// src/monitoring/metrics-middleware.ts\nimport { Request, Response, NextFunction } from 'express'\nimport { metricsCollector } from './metrics-collector'\nimport { performance } from 'perf_hooks'\n\nexport const metricsMiddleware = (req: Request, res: Response, next: NextFunction): void => {\n  const startTime = performance.now()\n  \n  // Track request start\n  const originalSend = res.send\n  \n  res.send = function(body: any) {\n    const endTime = performance.now()\n    const duration = (endTime - startTime) / 1000 // Convert to seconds\n    \n    // Record metrics\n    metricsCollector.recordHttpRequest(\n      req.method,\n      req.route?.path || req.path,\n      res.statusCode,\n      duration\n    )\n    \n    return originalSend.call(this, body)\n  }\n  \n  next()\n}\n\n// Database query metrics middleware\nexport const databaseMetricsMiddleware = {\n  beforeQuery: (sql: string, params?: any[]) => {\n    const startTime = performance.now()\n    const operation = sql.split(' ')[0].toLowerCase()\n    const table = extractTableName(sql)\n    \n    return {\n      startTime,\n      operation,\n      table\n    }\n  },\n  \n  afterQuery: (context: any) => {\n    const endTime = performance.now()\n    const duration = (endTime - context.startTime) / 1000\n    \n    metricsCollector.recordDatabaseQuery(\n      context.operation,\n      context.table,\n      duration\n    )\n  }\n}\n\nfunction extractTableName(sql: string): string {\n  const match = sql.match(/(?:from|into|update|join)\\s+([`\"]?)(\\w+)\\1/i)\n  return match ? match[2] : 'unknown'\n}\n\n// WebSocket metrics middleware\nexport const webSocketMetricsMiddleware = (socket: any) => {\n  // Update connection count\n  metricsCollector.updateWebSocketConnections(socket.engine.clientsCount)\n  \n  // Track incoming messages\n  socket.onAny((eventName: string, ...args: any[]) => {\n    metricsCollector.recordWebSocketMessage('in', eventName)\n  })\n  \n  // Track outgoing messages\n  const originalEmit = socket.emit\n  socket.emit = function(eventName: string, ...args: any[]) {\n    metricsCollector.recordWebSocketMessage('out', eventName)\n    return originalEmit.apply(this, arguments)\n  }\n  \n  socket.on('disconnect', () => {\n    metricsCollector.updateWebSocketConnections(socket.engine.clientsCount - 1)\n  })\n}\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Health Checks\">\n```typescript\n// src/monitoring/health-checker.ts\nimport { DatabaseConnectionManager } from '../core/database-connection-manager'\nimport { MessageBusService } from '../messaging/message-bus'\nimport { logger } from '@elizaos/core'\n\ninterface HealthCheckResult {\n  status: 'healthy' | 'unhealthy' | 'degraded'\n  checks: {\n    [service: string]: {\n      status: 'up' | 'down' | 'slow'\n      responseTime?: number\n      error?: string\n      details?: any\n    }\n  }\n  timestamp: string\n  uptime: number\n}\n\nclass HealthChecker {\n  private startTime: number = Date.now()\n  \n  async performHealthCheck(): Promise\u003CHealthCheckResult> {\n    const checks: any = {}\n    \n    // Database health check\n    checks.database = await this.checkDatabase()\n    \n    // Redis health check\n    checks.redis = await this.checkRedis()\n    \n    // External services health check\n    checks.telegram = await this.checkTelegram()\n    checks.discord = await this.checkDiscord()\n    checks.twitter = await this.checkTwitter()\n    \n    // AI services health check\n    checks.openai = await this.checkOpenAI()\n    \n    // Memory check\n    checks.memory = this.checkMemory()\n    \n    // Disk space check\n    checks.disk = await this.checkDiskSpace()\n    \n    // Determine overall status\n    const overallStatus = this.determineOverallStatus(checks)\n    \n    return {\n      status: overallStatus,\n      checks,\n      timestamp: new Date().toISOString(),\n      uptime: Date.now() - this.startTime\n    }\n  }\n  \n  private async checkDatabase(): Promise\u003Cany> {\n    const startTime = performance.now()\n    \n    try {\n      const dbManager = DatabaseConnectionManager.getInstance()\n      await dbManager.query('SELECT 1 as health_check')\n      \n      const responseTime = performance.now() - startTime\n      \n      return {\n        status: responseTime > 1000 ? 'slow' : 'up',\n        responseTime,\n        details: {\n          poolSize: dbManager.getPoolSize(),\n          activeConnections: dbManager.getActiveConnections()\n        }\n      }\n    } catch (error) {\n      return {\n        status: 'down',\n        error: error.message,\n        responseTime: performance.now() - startTime\n      }\n    }\n  }\n  \n  private async checkRedis(): Promise\u003Cany> {\n    const startTime = performance.now()\n    \n    try {\n      // Assuming Redis client is available\n      const redis = this.getRedisClient()\n      await redis.ping()\n      \n      const responseTime = performance.now() - startTime\n      \n      return {\n        status: responseTime > 500 ? 'slow' : 'up',\n        responseTime,\n        details: {\n          memory: await redis.memory('usage'),\n          connections: await redis.info('clients')\n        }\n      }\n    } catch (error) {\n      return {\n        status: 'down',\n        error: error.message,\n        responseTime: performance.now() - startTime\n      }\n    }\n  }\n  \n  private async checkTelegram(): Promise\u003Cany> {\n    const startTime = performance.now()\n    \n    try {\n      if (!process.env.TELEGRAM_BOT_TOKEN) {\n        return { status: 'down', error: 'Telegram bot token not configured' }\n      }\n      \n      // Check Telegram API\n      const response = await fetch(\n        `https://api.telegram.org/bot${process.env.TELEGRAM_BOT_TOKEN}/getMe`,\n        { signal: AbortSignal.timeout(5000) }\n      )\n      \n      const responseTime = performance.now() - startTime\n      \n      if (response.ok) {\n        const data = await response.json()\n        return {\n          status: responseTime > 2000 ? 'slow' : 'up',\n          responseTime,\n          details: data.result\n        }\n      } else {\n        return {\n          status: 'down',\n          error: `HTTP ${response.status}`,\n          responseTime\n        }\n      }\n    } catch (error) {\n      return {\n        status: 'down',\n        error: error.message,\n        responseTime: performance.now() - startTime\n      }\n    }\n  }\n  \n  private checkMemory(): any {\n    const memUsage = process.memoryUsage()\n    const totalMem = require('os').totalmem()\n    const freeMem = require('os').freemem()\n    const usedMem = totalMem - freeMem\n    const memoryUsagePercent = (usedMem / totalMem) * 100\n    \n    return {\n      status: memoryUsagePercent > 90 ? 'down' : memoryUsagePercent > 80 ? 'slow' : 'up',\n      details: {\n        heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),\n        heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),\n        external: Math.round(memUsage.external / 1024 / 1024),\n        systemMemoryUsage: Math.round(memoryUsagePercent),\n        systemMemoryFree: Math.round(freeMem / 1024 / 1024),\n        systemMemoryTotal: Math.round(totalMem / 1024 / 1024)\n      }\n    }\n  }\n  \n  private async checkDiskSpace(): Promise\u003Cany> {\n    try {\n      const { execAsync } = require('child_process')\n      const { promisify } = require('util')\n      const exec = promisify(execAsync)\n      \n      const { stdout } = await exec('df -h /')\n      const lines = stdout.split('\\n')\n      const data = lines[1].split(/\\s+/)\n      const usage = parseInt(data[4])\n      \n      return {\n        status: usage > 90 ? 'down' : usage > 80 ? 'slow' : 'up',\n        details: {\n          filesystem: data[0],\n          size: data[1],\n          used: data[2],\n          available: data[3],\n          usage: `${usage}%`,\n          mountPoint: data[5]\n        }\n      }\n    } catch (error) {\n      return {\n        status: 'down',\n        error: error.message\n      }\n    }\n  }\n  \n  private determineOverallStatus(checks: any): 'healthy' | 'unhealthy' | 'degraded' {\n    const statuses = Object.values(checks).map((check: any) => check.status)\n    \n    if (statuses.every(status => status === 'up')) {\n      return 'healthy'\n    }\n    \n    if (statuses.some(status => status === 'down')) {\n      return 'unhealthy'\n    }\n    \n    return 'degraded'\n  }\n  \n  private getRedisClient(): any {\n    // Implementation depends on Redis client setup\n    // Return configured Redis client instance\n    return null\n  }\n}\n\nexport const healthChecker = new HealthChecker()\n\n// Express route for health check\nexport const healthCheckRoute = async (req: any, res: any) => {\n  try {\n    const healthResult = await healthChecker.performHealthCheck()\n    \n    const statusCode = {\n      'healthy': 200,\n      'degraded': 200,\n      'unhealthy': 503\n    }[healthResult.status]\n    \n    res.status(statusCode).json(healthResult)\n  } catch (error) {\n    logger.error('Health check failed:', error)\n    res.status(503).json({\n      status: 'unhealthy',\n      error: 'Health check failed',\n      timestamp: new Date().toISOString()\n    })\n  }\n}\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Logging Strategy\n\n### Structured Logging Implementation\n\nComprehensive logging strategy with structured logs for easy searching and analysis:\n\n\u003CTabs>\n  \u003CTabItem label=\"Winston Logger Setup\">\n```typescript\n// src/monitoring/logger.ts\nimport winston from 'winston'\nimport 'winston-daily-rotate-file'\n\ninterface LogContext {\n  userId?: string\n  raidId?: string\n  platform?: string\n  action?: string\n  metadata?: any\n}\n\nclass NubiLogger {\n  private logger: winston.Logger\n  \n  constructor() {\n    this.logger = winston.createLogger({\n      level: process.env.LOG_LEVEL || 'info',\n      format: winston.format.combine(\n        winston.format.timestamp(),\n        winston.format.errors({ stack: true }),\n        winston.format.json(),\n        winston.format.printf((info) => {\n          const { timestamp, level, message, ...rest } = info\n          return JSON.stringify({\n            timestamp,\n            level,\n            message,\n            service: 'nubi',\n            environment: process.env.NODE_ENV,\n            version: process.env.APP_VERSION,\n            ...rest\n          })\n        })\n      ),\n      defaultMeta: {\n        service: 'nubi',\n        environment: process.env.NODE_ENV,\n        version: process.env.APP_VERSION\n      },\n      transports: this.createTransports()\n    })\n  }\n  \n  private createTransports(): winston.transport[] {\n    const transports: winston.transport[] = []\n    \n    // Console transport (always enabled)\n    transports.push(new winston.transports.Console({\n      format: process.env.NODE_ENV === 'development' \n        ? winston.format.combine(\n            winston.format.colorize(),\n            winston.format.simple()\n          )\n        : winston.format.json()\n    }))\n    \n    // File transports (production)\n    if (process.env.NODE_ENV === 'production') {\n      // Combined log file\n      transports.push(new winston.transports.DailyRotateFile({\n        filename: 'logs/nubi-%DATE%.log',\n        datePattern: 'YYYY-MM-DD',\n        maxSize: '100m',\n        maxFiles: '30d',\n        level: 'info'\n      }))\n      \n      // Error log file\n      transports.push(new winston.transports.DailyRotateFile({\n        filename: 'logs/nubi-error-%DATE%.log',\n        datePattern: 'YYYY-MM-DD',\n        maxSize: '100m',\n        maxFiles: '90d',\n        level: 'error'\n      }))\n      \n      // Audit log file\n      transports.push(new winston.transports.DailyRotateFile({\n        filename: 'logs/nubi-audit-%DATE%.log',\n        datePattern: 'YYYY-MM-DD',\n        maxSize: '100m',\n        maxFiles: '365d',\n        level: 'info',\n        format: winston.format.combine(\n          winston.format.timestamp(),\n          winston.format.json()\n        )\n      }))\n    }\n    \n    return transports\n  }\n  \n  // Structured logging methods\n  info(message: string, context?: LogContext): void {\n    this.logger.info(message, context)\n  }\n  \n  warn(message: string, context?: LogContext): void {\n    this.logger.warn(message, context)\n  }\n  \n  error(message: string, error?: Error, context?: LogContext): void {\n    this.logger.error(message, {\n      ...context,\n      error: error ? {\n        name: error.name,\n        message: error.message,\n        stack: error.stack\n      } : undefined\n    })\n  }\n  \n  debug(message: string, context?: LogContext): void {\n    this.logger.debug(message, context)\n  }\n  \n  // Specialized logging methods\n  logRaidAction(action: string, raidId: string, userId: string, metadata?: any): void {\n    this.info(`Raid ${action}`, {\n      action: `raid_${action}`,\n      raidId,\n      userId,\n      metadata\n    })\n  }\n  \n  logUserAction(action: string, userId: string, platform?: string, metadata?: any): void {\n    this.info(`User ${action}`, {\n      action: `user_${action}`,\n      userId,\n      platform,\n      metadata\n    })\n  }\n  \n  logAPICall(method: string, path: string, statusCode: number, duration: number, userId?: string): void {\n    this.info('API call', {\n      action: 'api_call',\n      method,\n      path,\n      statusCode,\n      duration,\n      userId\n    })\n  }\n  \n  logSecurityEvent(event: string, userId?: string, ip?: string, metadata?: any): void {\n    this.warn(`Security event: ${event}`, {\n      action: 'security_event',\n      event,\n      userId,\n      ip,\n      metadata\n    })\n  }\n  \n  logPerformanceIssue(issue: string, duration: number, context?: any): void {\n    this.warn(`Performance issue: ${issue}`, {\n      action: 'performance_issue',\n      issue,\n      duration,\n      context\n    })\n  }\n  \n  logSystemEvent(event: string, level: 'info' | 'warn' | 'error', metadata?: any): void {\n    this.logger.log(level, `System event: ${event}`, {\n      action: 'system_event',\n      event,\n      metadata\n    })\n  }\n}\n\nexport const nubiLogger = new NubiLogger()\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Loki Configuration\">\n```yaml\n# monitoring/loki/loki.yml\nauth_enabled: false\n\nserver:\n  http_listen_port: 3100\n  grpc_listen_port: 9096\n\ncommon:\n  path_prefix: /loki\n  storage:\n    filesystem:\n      chunks_directory: /loki/chunks\n      rules_directory: /loki/rules\n  replication_factor: 1\n  ring:\n    instance_addr: 127.0.0.1\n    kvstore:\n      store: inmemory\n\nquery_scheduler:\n  max_outstanding_requests_per_tenant: 2048\n\nfrontend:\n  max_outstanding_per_tenant: 2048\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: index_\n        period: 24h\n\nruler:\n  alertmanager_url: http://alertmanager:9093\n\nanalytics:\n  reporting_enabled: false\n\nlimits_config:\n  enforce_metric_name: false\n  reject_old_samples: true\n  reject_old_samples_max_age: 168h\n  max_cache_freshness_per_query: 10m\n  split_queries_by_interval: 15m\n  max_query_parallelism: 32\n  max_query_series: 1000000\n  max_streams_per_user: 0\n  max_line_size: 256000\n  max_entries_limit_per_query: 5000\n  max_global_streams_per_user: 5000\n  unordered_writes: true\n  max_chunks_per_query: 2000000\n  max_query_length: 721h\n\nchunk_store_config:\n  max_look_back_period: 0s\n\ntable_manager:\n  retention_deletes_enabled: true\n  retention_period: 744h\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Promtail Configuration\">\n```yaml\n# monitoring/promtail/promtail.yml\nserver:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /tmp/positions.yaml\n\nclients:\n  - url: http://loki:3100/loki/api/v1/push\n    tenant_id: nubi\n\nscrape_configs:\n  # NUBI application logs\n  - job_name: nubi-app\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: nubi-app\n          service: nubi\n          environment: production\n          __path__: /var/log/nubi/nubi-*.log\n\n    pipeline_stages:\n      # Parse JSON logs\n      - json:\n          expressions:\n            timestamp: timestamp\n            level: level\n            message: message\n            service: service\n            userId: userId\n            raidId: raidId\n            platform: platform\n            action: action\n      \n      # Set timestamp\n      - timestamp:\n          source: timestamp\n          format: RFC3339\n      \n      # Add labels\n      - labels:\n          level:\n          service:\n          platform:\n          action:\n      \n      # Output structured log\n      - output:\n          source: message\n\n  # NUBI error logs\n  - job_name: nubi-errors\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: nubi-errors\n          service: nubi\n          log_type: error\n          __path__: /var/log/nubi/nubi-error-*.log\n\n    pipeline_stages:\n      - json:\n          expressions:\n            timestamp: timestamp\n            level: level\n            message: message\n            error: error\n            stack: error.stack\n      \n      - timestamp:\n          source: timestamp\n          format: RFC3339\n      \n      - labels:\n          level:\n          service:\n\n  # Docker container logs\n  - job_name: docker-containers\n    docker_sd_configs:\n      - host: unix:///var/run/docker.sock\n        refresh_interval: 5s\n    \n    relabel_configs:\n      - source_labels: [__meta_docker_container_name]\n        regex: '/nubi-(.*)'\n        target_label: container\n      \n      - source_labels: [__meta_docker_container_label_com_docker_compose_service]\n        target_label: service\n    \n    pipeline_stages:\n      - docker: {}\n      \n      - multiline:\n          firstline: '^\\d{4}-\\d{2}-\\d{2}'\n          max_wait_time: 3s\n      \n      - json:\n          expressions:\n            level: level\n            message: message\n            timestamp: timestamp\n      \n      - labels:\n          level:\n          service:\n\n  # System logs\n  - job_name: system\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: system\n          service: system\n          __path__: /var/log/syslog\n\n    pipeline_stages:\n      - regex:\n          expression: '^(?P\u003Ctimestamp>\\S+\\s+\\d+\\s+\\d+:\\d+:\\d+)\\s+(?P\u003Chostname>\\S+)\\s+(?P\u003Cservice>\\S+)(?:\\[(?P\u003Cpid>\\d+)\\])?\\s*:\\s*(?P\u003Cmessage>.*)'\n      \n      - timestamp:\n          source: timestamp\n          format: 'Jan _2 15:04:05'\n      \n      - labels:\n          service:\n          hostname:\n\n  # Nginx access logs\n  - job_name: nginx-access\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: nginx-access\n          service: nginx\n          log_type: access\n          __path__: /var/log/nginx/access.log\n\n    pipeline_stages:\n      - regex:\n          expression: '^(?P\u003Cremote_addr>\\S+)\\s+-\\s+(?P\u003Cremote_user>\\S+)\\s+\\[(?P\u003Ctime_local>[^\\]]+)\\]\\s+\"(?P\u003Cmethod>\\S+)\\s+(?P\u003Crequest_uri>[^\"]*)\\s+HTTP/[^\"]*\"\\s+(?P\u003Cstatus>\\d+)\\s+(?P\u003Cbody_bytes_sent>\\d+)\\s+\"(?P\u003Chttp_referer>[^\"]*)\"\\s+\"(?P\u003Chttp_user_agent>[^\"]*)\"'\n      \n      - timestamp:\n          source: time_local\n          format: '02/Jan/2006:15:04:05 -0700'\n      \n      - labels:\n          method:\n          status:\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Alerting Configuration\n\n### Prometheus Alerting Rules\n\nComprehensive alerting rules for proactive monitoring:\n\n\u003CTabs>\n  \u003CTabItem label=\"Alert Rules\">\n```yaml\n# monitoring/prometheus/rules/nubi-alerts.yml\ngroups:\n  - name: nubi.high_priority\n    interval: 30s\n    rules:\n      # Application Health\n      - alert: NubiServiceDown\n        expr: up{job=\"nubi-app\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          service: nubi\n        annotations:\n          summary: \"NUBI service is down\"\n          description: \"NUBI service {{ $labels.instance }} has been down for more than 1 minute\"\n          runbook_url: \"https://wiki.company.com/nubi/alerts/service-down\"\n\n      - alert: NubiHighErrorRate\n        expr: rate(nubi_http_requests_total{status_code=~\"5..\"}[5m]) / rate(nubi_http_requests_total[5m]) > 0.1\n        for: 5m\n        labels:\n          severity: critical\n          service: nubi\n        annotations:\n          summary: \"High error rate in NUBI\"\n          description: \"NUBI error rate is {{ $value | humanizePercentage }} over the last 5 minutes\"\n\n      - alert: NubiSlowResponse\n        expr: histogram_quantile(0.95, rate(nubi_http_request_duration_seconds_bucket[5m])) > 5\n        for: 5m\n        labels:\n          severity: warning\n          service: nubi\n        annotations:\n          summary: \"NUBI response time is slow\"\n          description: \"95th percentile response time is {{ $value }}s over the last 5 minutes\"\n\n      # Database Alerts\n      - alert: DatabaseConnectionPoolExhausted\n        expr: nubi_database_pool_size{state=\"available\"} / nubi_database_pool_size{state=\"total\"} \u003C 0.1\n        for: 2m\n        labels:\n          severity: critical\n          service: database\n        annotations:\n          summary: \"Database connection pool exhausted\"\n          description: \"Less than 10% of database connections are available\"\n\n      - alert: DatabaseSlowQueries\n        expr: histogram_quantile(0.95, rate(nubi_database_query_duration_seconds_bucket[5m])) > 2\n        for: 5m\n        labels:\n          severity: warning\n          service: database\n        annotations:\n          summary: \"Database queries are slow\"\n          description: \"95th percentile query time is {{ $value }}s\"\n\n      # Memory and CPU\n      - alert: HighMemoryUsage\n        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9\n        for: 5m\n        labels:\n          severity: critical\n          service: system\n        annotations:\n          summary: \"High memory usage\"\n          description: \"Memory usage is {{ $value | humanizePercentage }}\"\n\n      - alert: HighCPUUsage\n        expr: 100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) > 80\n        for: 10m\n        labels:\n          severity: warning\n          service: system\n        annotations:\n          summary: \"High CPU usage\"\n          description: \"CPU usage is {{ $value }}%\"\n\n  - name: nubi.business_metrics\n    interval: 1m\n    rules:\n      # Raid Metrics\n      - alert: LowRaidParticipation\n        expr: avg_over_time(nubi_raid_participants[1h]) \u003C 5\n        for: 30m\n        labels:\n          severity: warning\n          service: raids\n        annotations:\n          summary: \"Low raid participation\"\n          description: \"Average raid participation over the last hour is {{ $value }}\"\n\n      - alert: RaidFailureRate\n        expr: rate(nubi_raids_total{status=\"failed\"}[1h]) / rate(nubi_raids_total[1h]) > 0.2\n        for: 15m\n        labels:\n          severity: warning\n          service: raids\n        annotations:\n          summary: \"High raid failure rate\"\n          description: \"Raid failure rate is {{ $value | humanizePercentage }} over the last hour\"\n\n      - alert: LowEngagementQuality\n        expr: avg_over_time(nubi_engagement_quality_score[30m]) \u003C 0.6\n        for: 30m\n        labels:\n          severity: warning\n          service: engagement\n        annotations:\n          summary: \"Low engagement quality\"\n          description: \"Average engagement quality is {{ $value }} over the last 30 minutes\"\n\n      # User Activity\n      - alert: LowUserActivity\n        expr: nubi_active_users{timeframe=\"1h\"} \u003C 10\n        for: 30m\n        labels:\n          severity: warning\n          service: users\n        annotations:\n          summary: \"Low user activity\"\n          description: \"Only {{ $value }} active users in the last hour\"\n\n      - alert: UserActivityDrop\n        expr: (nubi_active_users{timeframe=\"1h\"} / nubi_active_users{timeframe=\"1h\"} offset 24h - 1) \u003C -0.3\n        for: 15m\n        labels:\n          severity: warning\n          service: users\n        annotations:\n          summary: \"Significant drop in user activity\"\n          description: \"User activity dropped by {{ $value | humanizePercentage }} compared to same time yesterday\"\n\n  - name: nubi.external_services\n    interval: 2m\n    rules:\n      # Platform Integration\n      - alert: TelegramAPIDown\n        expr: up{job=\"telegram-health-check\"} == 0\n        for: 3m\n        labels:\n          severity: critical\n          service: telegram\n        annotations:\n          summary: \"Telegram API is down\"\n          description: \"Cannot connect to Telegram API\"\n\n      - alert: DiscordAPIDown\n        expr: up{job=\"discord-health-check\"} == 0\n        for: 3m\n        labels:\n          severity: critical\n          service: discord\n        annotations:\n          summary: \"Discord API is down\"\n          description: \"Cannot connect to Discord API\"\n\n      # AI Services\n      - alert: AIServiceHighLatency\n        expr: histogram_quantile(0.95, rate(nubi_ai_request_duration_seconds_bucket[5m])) > 30\n        for: 10m\n        labels:\n          severity: warning\n          service: ai\n        annotations:\n          summary: \"AI service high latency\"\n          description: \"95th percentile AI request time is {{ $value }}s\"\n\n      - alert: AIServiceHighErrorRate\n        expr: rate(nubi_ai_requests_total{status=\"error\"}[10m]) / rate(nubi_ai_requests_total[10m]) > 0.1\n        for: 5m\n        labels:\n          severity: warning\n          service: ai\n        annotations:\n          summary: \"High AI service error rate\"\n          description: \"AI service error rate is {{ $value | humanizePercentage }}\"\n\n  - name: nubi.security\n    interval: 1m\n    rules:\n      # Security Events\n      - alert: SuspiciousActivity\n        expr: rate(nubi_security_events_total[5m]) > 5\n        for: 2m\n        labels:\n          severity: warning\n          service: security\n        annotations:\n          summary: \"Unusual security events\"\n          description: \"{{ $value }} security events per second over the last 5 minutes\"\n\n      - alert: RateLimitExceeded\n        expr: rate(nubi_rate_limit_exceeded_total[5m]) > 10\n        for: 5m\n        labels:\n          severity: warning\n          service: security\n        annotations:\n          summary: \"Rate limit frequently exceeded\"\n          description: \"Rate limit exceeded {{ $value }} times per second\"\n\n      - alert: FailedLogins\n        expr: rate(nubi_auth_failures_total[10m]) > 2\n        for: 5m\n        labels:\n          severity: warning\n          service: auth\n        annotations:\n          summary: \"High failed login rate\"\n          description: \"{{ $value }} failed logins per second over the last 10 minutes\"\n```\n  \u003C/TabItem>\n  \n  \u003CTabItem label=\"Alertmanager Config\">\n```yaml\n# monitoring/alertmanager/alertmanager.yml\nglobal:\n  smtp_smarthost: 'localhost:587'\n  smtp_from: 'alerts@anubis.chat'\n  smtp_auth_username: 'alerts@anubis.chat'\n  smtp_auth_password: 'smtp-password'\n\n# Alert routing tree\nroute:\n  group_by: ['alertname', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: 'default'\n  \n  routes:\n    # Critical alerts go to PagerDuty and Slack immediately\n    - match:\n        severity: critical\n      receiver: 'critical-alerts'\n      group_wait: 0s\n      repeat_interval: 15m\n    \n    # Warning alerts go to Slack only\n    - match:\n        severity: warning\n      receiver: 'warning-alerts'\n      group_wait: 30s\n      repeat_interval: 4h\n    \n    # Business metrics alerts\n    - match:\n        service: raids\n      receiver: 'business-alerts'\n    \n    # Security alerts\n    - match:\n        service: security\n      receiver: 'security-alerts'\n\n# Alert receivers\nreceivers:\n  - name: 'default'\n    email_configs:\n      - to: 'ops@anubis.chat'\n        subject: '[NUBI] {{ .GroupLabels.alertname }}'\n        body: |\n          {{ range .Alerts }}\n          Alert: {{ .Annotations.summary }}\n          Description: {{ .Annotations.description }}\n          Details: {{ range .Labels.SortedPairs }}{{ .Name }}: {{ .Value }}{{ end }}\n          {{ end }}\n\n  - name: 'critical-alerts'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n        channel: '#alerts-critical'\n        title: '🚨 CRITICAL: {{ .GroupLabels.alertname }}'\n        text: |\n          {{ range .Alerts }}\n          *{{ .Annotations.summary }}*\n          {{ .Annotations.description }}\n          \n          *Labels:* {{ range .Labels.SortedPairs }}`{{ .Name }}`: {{ .Value }} {{ end }}\n          {{ if .Annotations.runbook_url }}*Runbook:* \u003C{{ .Annotations.runbook_url }}|View Runbook>{{ end }}\n          {{ end }}\n        send_resolved: true\n    \n    pagerduty_configs:\n      - routing_key: 'your-pagerduty-integration-key'\n        description: '{{ .GroupLabels.alertname }}: {{ .GroupLabels.service }}'\n        severity: 'critical'\n\n  - name: 'warning-alerts'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n        channel: '#alerts-warning'\n        title: '⚠️ WARNING: {{ .GroupLabels.alertname }}'\n        text: |\n          {{ range .Alerts }}\n          {{ .Annotations.summary }}\n          {{ .Annotations.description }}\n          {{ end }}\n        send_resolved: true\n\n  - name: 'business-alerts'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n        channel: '#business-metrics'\n        title: '📊 Business Metric Alert: {{ .GroupLabels.alertname }}'\n        text: |\n          {{ range .Alerts }}\n          {{ .Annotations.summary }}\n          {{ .Annotations.description }}\n          {{ end }}\n\n  - name: 'security-alerts'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n        channel: '#security-alerts'\n        title: '🔒 Security Alert: {{ .GroupLabels.alertname }}'\n        text: |\n          {{ range .Alerts }}\n          *{{ .Annotations.summary }}*\n          {{ .Annotations.description }}\n          {{ end }}\n    \n    email_configs:\n      - to: 'security@anubis.chat'\n        subject: '[SECURITY] NUBI Alert: {{ .GroupLabels.alertname }}'\n\n# Inhibit rules to prevent alert spam\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'service']\n\n  - source_match:\n      alertname: 'NubiServiceDown'\n    target_match_re:\n      alertname: 'Nubi.*'\n    equal: ['instance']\n```\n  \u003C/TabItem>\n\u003C/Tabs>\n\nThis comprehensive monitoring and observability setup provides enterprise-grade visibility into your NUBI deployment, enabling proactive issue detection, rapid troubleshooting, and continuous performance optimization.","src/content/docs/deployment/monitoring.mdx","91a9761b2af81569","deployment/monitoring.mdx"]